[["index.html", "Probabilidades Prólogo", " Probabilidades Prof: Oswaldo Bello (oswaldobelloc@gmail.com) Universidad de Oriente, Venezuela Viernes, 18 de marzo de 2022 (01:58:19 a.m.) Prólogo Este libro es una guía para la enseñanza de la asignatura Probabilidades, esencialmente pretende ser un curso de Probabilidades Discretas aplicado con el lenguaje R. El contenido de este texto ha sido escrito en R-Markdown empleando el paquete bookdown y está disponible en el repositorio Github: probabilidades. Este repositorio es público, por lo que cualquier persona puede acceder al código fuente y hacer comentarios en aras de mejorar ediciones futuras del libro. Para generar el libro (compilar) puede ser recomendable instalar la última versión de RStudio y la versión de desarrollo de bookdown disponible en Github. "],["nt1.html", "Núcleo Temático 1 Técnicas de Conteo 1.1 Pricipio de la Adición 1.2 Principio de la Multiplicación 1.3 Permutación 1.4 Combinación 1.5 Variación 1.6 Ejercicios de Técnicas de Conteo 1.7 Información de Sesión", " Núcleo Temático 1 Técnicas de Conteo En este núcleo temático se describen de manera teórica algunos métodos de conteo, tales como: Principio de la Adición (Sección 1.1) Principio de la Multiplicación (Sección 1.2) Diagrama de Árbol (Sección 1.2.1) Permutación (Sección 1.3) Permutación Sin Repetición (Sección 1.3.1) Permutación Con Repetición (Sección 1.3.2) Combinación (Sección 1.4) Combinación Sin Repetición (Sección 1.4.1) Combinación Con Repetición (Sección 1.4.2) Variación (Sección 1.5) Variación Sin Repetición (Sección 1.5.1) Variación Con Repetición (Sección 1.5.2) Una vez descrita estas técnicas de conteo, se procede mediante ejemplos, a la implementación en R de las mismas. El siguiente bloque de código permite instalar y cargar los paquetes usados para implementar estas pruebas en R. De estos paquetes, los que contiene funciones relacionadas con la teoría de conteo son: combinat, gtools y prob. packages &lt;- c( &quot;bookdown&quot;, &quot;bookdownplus&quot;, &quot;magrittr&quot;, &quot;kableExtra&quot;, &quot;DT&quot;, &quot;devtools&quot;, &quot;tidyverse&quot;, &quot;htmltools&quot;, &quot;htmlwidgets&quot;, &quot;utf8&quot;, &quot;stringr&quot;, &quot;gtools&quot;, &quot;prob&quot;, &quot;combinat&quot; ) package.check &lt;- lapply(packages, FUN = function(x) { if (!require(x, character.only = TRUE)) { install.packages(x, dependencies = TRUE) library(x, character.only = TRUE) } }) 1.1 Pricipio de la Adición Definición 1.1 (Pricipio de la Adición) Si hay \\(k\\) procedimientos, tal que, el procedimiento 1 puede ocurrir de \\(n_1\\) manera, el procedimiento 2 puede ocurrir de \\(n_2\\) maneras, \\(\\dotsc\\), y el procedimiento \\(k\\) puede ocurrir de \\(n_k\\) maneras. Entonces, el número de maneras como podemos hacer el procedimiento 1, o el procedimiento 2, \\(\\dotsc\\), o el procedimiento \\(k\\) es \\[ n{}_1 + n{}_2 + \\cdots + n{}_k. \\] Suponiendo que los procedimientos no se pueden realizar en forma conjunta. Ejemplo 1.1 (Pricipio de la Adición) Supongamos que planeamos un viaje y debemos decidir entre transportarnos por autobús, por avión o por tren. Si hay tres rutas para el autobús, dos para el avión y una para el tren, entonces hay \\(n{}_1 + n{}_2 + n{}_3= 3 + 2 + 1 =6\\) rutas disponibles para el viaje. El resultado anterior puede conseguirse, mediante el siguiente script. n1 &lt;- 3 n2 &lt;- 2 n3 &lt;- 1 (nm &lt;- n1 + n2 + n3) #&gt; [1] 6 Ejemplo 1.2 (Pricipio de la Adición) Suponga que en una biblioteca hay 3 novelas de misterio diferentes, 5 novelas de romance diferentes, 4 novelas de ficción diferentes y 2 novelas de aventura diferentes. Entonces hay \\[n_1 + n_2 + n_3 + n_4= 3 + 5 + 4 + 2 =14\\] formas para escoger una de las novelas. El siguiente fragmento de código, muestra el cálculo anterior. n1 &lt;- 3 n2 &lt;- 5 n3 &lt;- 4 n4 &lt;- 2 (nm &lt;- n1 + n2 + n3 + n4) #&gt; [1] 14 1.2 Principio de la Multiplicación Definición 1.2 (Pricipio de la Multiplicación) Si hay \\(k\\) procedimientos, tal que, el procedimiento 1 se puede hacer de \\(n_1\\) manera, el procedimiento 2 se puede hacer de \\(n_2\\) maneras, \\(\\dotsc\\), y el procedimiento \\(k\\) se puede hacer de \\(n_k\\) maneras. Entonces, el número de maneras como podemos realizar el procedimiento 1, seguido del procedimiento 2, \\(\\dotsc\\) , seguido del procedimiento \\(k\\) es \\[ n{}_1\\,n{}_2\\cdots\\,n{}_k. \\] Ejemplo 1.3 (Pricipio de la Multiplicación) Un artículo manufacturado debe pasar por tres controles. En cada uno de ellos se inspecciona una característica particular del artículo y se le marca de conformidad. En el primer control hay tres mediciones posibles, mientras que en cada uno de los últimos controles hay cuatro mediciones posibles. Por lo tanto, hay \\(n_1 \\, n_2 \\, n_3= 3 · 4 · 4 = 48\\) maneras de marcar el artículo. En R, este resultado puede ser obtenido con el siguiente script. n1 &lt;- 3 n2 &lt;- 4 n3 &lt;- 4 (nm &lt;- n1 * n2 * n3) #&gt; [1] 48 Ejemplo 1.4 (Pricipio de la Multiplicación) Juan va a armar una computadora por sí mismo. Tiene la opción de comprar los chips entre dos marcas, un disco duro de cuatro marcas, la memoria de tres marcas y un conjunto de accesorios en cinco tiendas locales. ¿De cuántas formas diferentes puede Juan armar la computadora? Juan puede armar la computadora de \\(n{}_1 \\, n{}_2 \\, n{}_3 \\, n{}_4 = 2 \\cdot 4 \\cdot 3 \\cdot 5 = 120\\). El siguiente trozo de código, muestra el resultado anterior. n1 &lt;- 2 n2 &lt;- 4 n3 &lt;- 3 n4 &lt;- 5 (nm &lt;- n1 * n2 * n3 * n4) #&gt; [1] 120 Ejemplo 1.5 (Pricipio de la Multiplicación) ¿Cuántos números pares de cuatro dígitos se pueden formar con los dígitos 0, 1, 2, 5, 6 y 9, si cada dígito se puede usar sólo una vez? Como el número es par, tenemos sólo \\(n_1 = 3\\) elecciones para la posición de las unidades. Sin embargo, para un número de cuatro dígitos la posición de las unidades de mil no puede ser cero. Por lo tanto, consideramos la posición de las unidades en dos partes: 0 o diferentes de 0. Si la posición de las unidades es 0 (es decir, \\(n_1 = 1\\)), tenemos \\(n_2 = 5\\) elecciones para la posición de las unidades de mil, \\(n_3 = 4\\) para la posición de las centenas y \\(n_4 = 3\\) para la posición de las decenas. Por lo tanto, formamos un total de \\[ n_1 \\: n_2 \\: n_3 \\: n_4 = 1 \\cdot 5 \\cdot 4 \\cdot 3 = 60 \\] números pares de cuatro dígitos. Por otro lado, si la posición de las unidades no es 0 (es decir, \\(n_1= 2\\)), tenemos \\(n_2 = 4\\) elecciones para la posición de los unidades de mil, \\(n_3 = 4\\) para la posición de las centenas y \\(n_4 = 3\\) para la posición de las decenas. En esta situación tenemos un total de \\[ n_1 \\: n_2 \\: n_3 \\: n_4 = 2 \\cdot 4 \\cdot 4 \\cdot 3 = 96 \\] números pares de cuatro dígitos. Como los dos casos no pueden ocurrir al mismo tiempo, por el principio aditivo, el número total de números pares de cuatro dígitos es \\(60 + 96 = 156\\). El resultado anterior puede obtenerse en R con el siguiente bloque de código. n11 &lt;- 1 n12 &lt;- 5 n13 &lt;- 4 n14 &lt;- 3 (nm1 &lt;- n11 * n12 * n13 * n14) n21 &lt;- 2 n22 &lt;- 4 n23 &lt;- 4 n24 &lt;- 3 (nm2 &lt;- n21 * n22 * n23 * n24) (nm &lt;- nm1 + nm2) #&gt; [1] 60 #&gt; [1] 96 #&gt; [1] 156 1.2.1 Diagrama de Árbol Definición 1.3 (Diagrama de Árbol) Un diagrama de árbol es un gráfico utilizado para enumerar todos los resultados posibles de una secuencia de procedimientos donde cada procedimiento puede ocurrir en un número finito de maneras. El diagrama de árbol se construye de izquierda a derecha y el número de ramas en cada punto corresponde al número de manera en que se puede realizar el procedimiento siguiente. Ejemplo 1.6 (Diagrama de Árbol) Supóngase que un servicio de pruebas de productos evalúa el funcionamiento de una podadora de césped como fácil de operar, de dificultad mediana o difícil; como barata o cara; como de reparación barata, regular o costosa. ¿De cuántas maneras diferentes puede clasificarse una podadora de césped por dicho servicio? Sea: F1: la podadora de césped es fácil de operar F2: la podadora de césped es medianamente fácil de operar F3: la podadora de césped es difícil de operar P1: la podadora de césped es barata P2: la podadora de césped es cara C1: la podadora de césped es barata de reparar C2: la podadora de césped es de costo regular de reparación C3: la podadora de césped es costosa de reparar La figura 1.1 muestra el diagrama de árbol para las diferentes maneras en que se puede clasificar la podadora de césped. knitr::include_graphics(path = &quot;figuras/diagrama_arbol.png&quot;) Figura 1.1: Diagrama de árbol para la clasificación de la podadora de césped Ejemplo 1.7 (Diagrama de Árbol) Mario y Eduardo van a jugar un torneo de tenis. La primera persona que gane 2 juegos seguidos o quien gane un total de 3 juegos gana el torneo. Encuentre el número de formas como puede desarrollarse el torneo. El diagrama de árbol que muestra los resultados posibles del torneo aparece en la figura 1.2. knitr::include_graphics(path = &quot;figuras/diagrama_arbol2.png&quot;) Figura 1.2: Diagrama de árbol para el número de formas como puede desarrollarse el torneo 1.3 Permutación Definición 1.4 (Permutación) Se define como cualquier arreglo, secuencias u ordenamiento de un conjunto de \\(n\\) objetos. 1.3.1 Permutación Sin Repetición Definición 1.4 (Permutación Sin Repetición) Dados \\(n\\) objetos distintos, el número de permutaciones de éstos viene dado por: \\[ \\begin{equation} P_n=n!=n(n-1)(n-2)\\cdots2\\cdot1. \\tag{1.1} \\end{equation} \\] Por definición \\(0!=1\\). \\[3!=3\\cdot2\\cdot1=6\\] \\[5!=5\\cdot4\\cdot3\\cdot2\\cdot1=120\\] Ejemplo 1.8 (Permutación Sin Repetición) ¿Cuántas permutaciones se pueden hacer con las letras \\(a\\), \\(b\\) y \\(c\\)? Los posibles casos son: \\[ \\begin{Bmatrix} (a,b,c);(a,c,b);(b,a,c);(b,c,a);(c,a,b);(c,b,a) \\end{Bmatrix}. \\] Usando la ecuación (1.1), el número de permutaciones sin repeticiones que se pueden obtener con las letras \\(a\\), \\(b\\) y \\(c\\) es \\[ P_3=3\\cdot2\\cdot1=6. \\] En R, este resultado se puede mostrar con el siguiente código. Note que en este bloque de código, el resultado anterior se ha calculado de dos manera, la primera, usando la función factorial de la distribución base de R, y la otra, usando la función nsamp del paquete prob. factorial(3) nsamp(n = 3, k = 3, replace = FALSE, ordered = TRUE) #&gt; [1] 6 #&gt; [1] 6 La lista de premutaciones sin reemplazo se puede obtener con la función urnsamples del paquete prob. urnsamples( c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), size = 3, replace = F, ordered = T ) #&gt; X1 X2 X3 #&gt; 1 a b c #&gt; 2 a c b #&gt; 3 c a b #&gt; 4 c b a #&gt; 5 b c a #&gt; 6 b a c La función permutations del paquete gtools también lista estas permutaciones, como se muestra en el siguiente código. gtools::permutations( n = 3, r = 3, v = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), set = T, repeats.allowed = F ) #&gt; [,1] [,2] [,3] #&gt; [1,] &quot;a&quot; &quot;b&quot; &quot;c&quot; #&gt; [2,] &quot;a&quot; &quot;c&quot; &quot;b&quot; #&gt; [3,] &quot;b&quot; &quot;a&quot; &quot;c&quot; #&gt; [4,] &quot;b&quot; &quot;c&quot; &quot;a&quot; #&gt; [5,] &quot;c&quot; &quot;a&quot; &quot;b&quot; #&gt; [6,] &quot;c&quot; &quot;b&quot; &quot;a&quot; Ejemplo 1.9 (Permutación Sin repetición) ¿Cuántas permutaciones se pueden hacer con las letras \\(a\\), \\(b\\), \\(c\\), \\(d\\)? La lista de permutaciones sin repetición que se pueden obtener es: \\[ \\begin{Bmatrix} (a,b,c,d);&amp;(a,b,d,c);&amp;(a,c,b,d);&amp;(a,c,d,b);&amp;(a,d,b,c);\\\\(a,d,c,b);&amp;(b,a,c,d);&amp;(b,a,d,c);&amp;(b,c,a,d);&amp; (b,c,d,a);\\\\(b,d,a,c);&amp;(b,d,c,a);&amp;(c,a,b,d);&amp;(c,a,d,b);&amp;(c,b,a,d);\\\\(c,b,d,a);&amp;(c,d,a,b);&amp;(c,d,b,a);&amp; (d,a,b,c);&amp;(d,a,c,b);\\\\(d,b,a,c);&amp;(d,b,c,a);&amp;(d,c,a,b);&amp;(d,c,b,a) \\end{Bmatrix}. \\] Usando la ecuación (1.1), el número de permutaciones sin repeticiones que se pueden obtener con las letras \\(a\\), \\(b\\), \\(c\\) y \\(d\\) es: \\[ P_4=4\\cdot3\\cdot2\\cdot1=24. \\] El resultado anterior, se puede mostrar con el siguiente código. Aquí, como en el ejemplo 1.8, se han usado las funciones factorial y nsamp para determinar el número de permutaciones sin repetición. factorial(4) nsamp(n = 4, k = 4, replace = FALSE, ordered = TRUE) #&gt; [1] 24 #&gt; [1] 24 La lista de permutaciones, en este caso, se muestra con el siguiente código. urnsamples(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), size = 4, replace = F, ordered = T) #&gt; X1 X2 X3 X4 #&gt; 1 a b c d #&gt; 2 a b d c #&gt; 3 a d b c #&gt; 4 d a b c #&gt; 5 d a c b #&gt; 6 a d c b #&gt; 7 a c d b #&gt; 8 a c b d #&gt; 9 c a b d #&gt; 10 c a d b #&gt; 11 c d a b #&gt; 12 d c a b #&gt; 13 d c b a #&gt; 14 c d b a #&gt; 15 c b d a #&gt; 16 c b a d #&gt; 17 b c a d #&gt; 18 b c d a #&gt; 19 b d c a #&gt; 20 d b c a #&gt; 21 d b a c #&gt; 22 b d a c #&gt; 23 b a d c #&gt; 24 b a c d Ejemplo 1.10 (Permutación Sin repetición) En una carrera de caballos en la cual participan 12. ¿De cuántas maneras pueden llegar los caballos a la meta, si no es posible que se den empates? Usando la ecuación (1.1), el número de resultados posibles es: \\[P_{12}=12!=12\\cdot11\\cdot10\\cdot9\\cdot8\\cdot7\\cdot6\\cdot5\\cdot4\\cdot3\\cdot2\\cdot1=479.001.600.\\] Usando R, este resultado puede obtenerse mediante el siguiente script. factorial(12) nsamp(n = 12, k = 12, replace = FALSE, ordered = TRUE) #&gt; [1] 479001600 #&gt; [1] 479001600 Abvertencia: La lista de posibles resultado de la carrera se puede generar con la instrucción urnsamples(1:12, size = 12, replace = F, ordered = T), pero no la ejecute porque la lista es muy grande y es posible que tarde mucho tiempo en generarse, además, consumiría mucho espacio en memoria. 1.3.2 Permutación Con Repetición Definición 1.5 (Permutación Con Repetición) Dados \\(n\\) objetos, de los cuales \\(n_1\\) son de una clase, \\(n_2\\) de una segunda clase, \\(\\dotsc\\) y \\(n_k\\) de una \\(k\\)-ésima clase; entonces el número de permutaciones distintas que se pueden formar con éstos n objetos viene dada por: \\[ \\begin{equation} PR_{n}^{n_1, n_2, \\dotsc, n_k}=\\frac{n!}{n_1!\\,n_2!\\, \\cdots \\,n_k},\\:con\\: n=n_1+n_2+\\cdots+n_k. \\tag{1.2} \\end{equation} \\] Este tipo de permutaciones también se conocen como Permutaciones de Objetos Indistinguibles. Ejemplo 1.11 (Permutación Con repetición) Retomando el ejemplo 1.8, en el cual se calculó el número de permutaciones diferentes que se pueden formar con las letras \\(a\\), \\(b\\) y \\(c\\); supongamos que las letras \\(b\\) y \\(c\\) son iguales a \\(x\\), entonces los arreglos quedan definidos de la siguiente manera: \\[ \\begin{Bmatrix} (a,x,x); (a,x,x); (x,a,x); (x,x,a); (x,a,x); (x,x,a) \\end{Bmatrix}. \\] Eliminando los casos idénticos, el número de permutaciones diferentes son: \\[ \\begin{Bmatrix} (a,x,x);(x,a,x);(x,x,a) \\end{Bmatrix}. \\] Usando la ecuación (1.2), el número de permutaciones con repetciones en este caso será: \\[ PR_{3}^{1, 2}=\\frac{3!}{1!\\,2!}=3. \\] En R, este cálculo se consigue con la siguiente instrucción. Pr &lt;- factorial(3) / (factorial(1) * factorial(2)) paste(&quot;El número de permutaciones con repeticiones es &quot;, Pr) #&gt; [1] &quot;El número de permutaciones con repeticiones es 3&quot; La siguiente función facilita el cálculo de las permutaciones con repeticiones. PR &lt;- function(n, k) { if (n == sum(k)) { PR &lt;- factorial(n) / prod(factorial(k)) } else { PR &lt;- &quot;NAN&quot; } return(PR) } paste( &quot;El número de permutaciones con repeticiones es &quot;, PR(n = 3, k = c(1, 2)) ) #&gt; [1] &quot;El número de permutaciones con repeticiones es 3&quot; La lista de premutaciones con repeticiones se puede obtener con el siguiente script. Note que el script lista todas las permutaciones sin repeticiones del vector c(\"a\", \"x\", \"x\") y luego elimina las que se repiten. urnsamples( c(&quot;a&quot;, &quot;x&quot;, &quot;x&quot;), size = 3, replace = F, ordered = T ) %&gt;% distinct() #&gt; X1 X2 X3 #&gt; 1 a x x #&gt; 2 x a x #&gt; 3 x x a Ejemplo 1.12 (Permutación Con repetición) Ahora, retomando el ejemplo 1.9, donde calculamos el número de permutaciones diferentes que se pueden formar con las letras \\(a\\), \\(b\\), \\(c\\) y \\(d\\); supongamos que las letras \\(a\\), \\(b\\) son iguales a \\(x\\) y las letras \\(c\\) y \\(d\\) son iguales a \\(y\\). Es decir, \\[ \\begin{Bmatrix} (x,x,y,y);&amp;(x,x,y,y);&amp;(x,y,x,y);&amp;(x,y,x,y);&amp;(x,y,x,y); \\\\(x,y,y,x);&amp;(x,x,y,y);&amp;(x,x,y,y);&amp;(x,y,x,y);&amp; (x,y,y,x); \\\\(x,y,x,y);&amp;(x,y,y,x);&amp;(y,x,x,y);&amp;(y,x,y,x);&amp;(y,x,x,y); \\\\(y,x,y,x);&amp;(y,y,x,x);&amp;(y,y,x,x);&amp; (y,x,x,y);&amp;(y,x,y,x); \\\\(y,x,x,y);&amp;(y,x,y,x);&amp;(y,y,x,x);&amp;(y,y,x,x) \\end{Bmatrix}. \\] Eliminando los casos que se repiten obtenemos el número de permutaciones diferentes, las cuales son: \\[ \\begin{Bmatrix} (x,x,y,y); (x,y,x,y);(x,y,y,x);(y,x,x,y);(y,x,y,x);(y,y,x,x) \\end{Bmatrix}. \\] Usando la ecuación (1.2), el número de permutaciones con repetciones en este caso será: \\[ PR_{4}^{2, 2}=\\frac{4!}{2!\\,2!}=\\frac{4(3)(2!)}{2!\\,2!}=\\frac{12}{2}=6. \\] El cálculo del número de permutaciones, en este ejemplo, se puede conseguir con el siguiente script. paste( &quot;El número de permutaciones con repeticiones es &quot;, PR(n = 4, k = c(2, 2)) ) #&gt; [1] &quot;El número de permutaciones con repeticiones es 6&quot; La lista de premutaciones con repeticiones se puede obtener con el siguiente script. Note que el script lista todas las permutaciones sin repeticiones del vector c(\"x\", \"x\", \"y\", \"y\") y luego elimina las que se repiten. urnsamples( c(&quot;x&quot;, &quot;x&quot;, &quot;y&quot;, &quot;y&quot;), size = 4, replace = F, ordered = T ) %&gt;% distinct() #&gt; X1 X2 X3 X4 #&gt; 1 x x y y #&gt; 2 x y x y #&gt; 3 y x x y #&gt; 4 y x y x #&gt; 5 x y y x #&gt; 6 y y x x Ejemplo 1.13 (Permutación Con Repetición) Durante un entrenamiento del equipo de fútbol americano de la universidad, el coordinador defensivo necesita tener a 10 jugadores parados en una fila. Entre estos 10 jugadores, hay 1 de primer año, 2 de segundo año, 4 de tercer año y 3 de cuarto año, respectivamente. ¿De cuántas formas diferentes se pueden arreglar en una fila, si sólo se distingue su nivel de clase? Si sólo se distingue su nivel de clase, la fila se puede arreglar de \\[ PR_{4}^{2, 2}=\\frac{10!}{1!\\,2!\\,4!\\,3!}=\\frac{4(3)(2!)}{2!\\,2!}=\\frac{10(9)(8)(7)(6)(5)(4!)}{2\\,(4!)(6)}=1.26\\times 10^{4}. \\] maneras diferentes. Con R, este resultado se puede ostrar con el siguiente bloque de código. paste( &quot;El número de permutaciones con repeticiones es &quot;, formato(PR(n = 10, k = c(1, 2, 4, 3))) ) #&gt; [1] &quot;El número de permutaciones con repeticiones es 12.600&quot; 1.4 Combinación Definición 1.6 (Combinación) Se define como cualquier selección de \\(r\\) objetos tomados de \\(n\\) objetos distintos, sin importar el orden. 1.4.1 Combinación Sin Repetición Definición 1.7 (Conbinación Sin Repetición) Dados \\(n\\) objetos distintos, el número de combinaciones que se pueden formar con \\(r\\) de estos objetos viene dado por: \\[ \\begin{equation} C_{n,r}=\\binom{n}{r}=\\frac{n!}{r!\\left ( n-r \\right )!}=\\frac{n\\left ( n-1 \\right )\\left ( n-2 \\right )\\,\\cdots\\,\\left ( n-r+1 \\right )}{r!}, con \\,r\\leq n. \\tag{1.3} \\end{equation} \\] Ejemplo 1.14 (Combinación Sin Repetición) Hay 12 estudiantes elegibles para asistir a la reunión anual de la Asociación Nacional de Estudiantes. Encuentre el número de formas como puede conformarse una delegación de 3 estudiantes, de los 12 estudiantes elegibles. Esto se relaciona con combinación, no con permutaciones, puesto que el orden no cuenta en una delegación. En consecuencia, el número de formas en que puede formarse la delegación, según la ecuación (1.3) es: \\[ C_{12,3}=\\binom{12}{3}=\\frac{12!}{3!\\left ( 12-3 \\right )!}=\\frac{12\\left ( 11 \\right )\\left ( 10 \\right )\\left ( 9! \\right )}{3!\\left ( 9! \\right )}=\\frac{12\\left ( 11 \\right )\\left ( 10 \\right )}{3\\left ( 2 \\right )\\left ( 1 \\right )}=220. \\] La función nsamp del paquete prob, también ejecuta el cálculo anterior. Como se muestra en el siguiente bloque de código. c1 &lt;- nsamp(n = 12, k = 3, replace = F, ordered = F) paste(&quot;Se pueden formar&quot;, c1,&quot;delegaciones&quot;) #&gt; [1] &quot;Se pueden formar 220 delegaciones&quot; Ejemplo 1.15 (Conbinación Sin Repetición) ¿De cuántas maneras se pueden colocar dos anillos idénticos en la misma mano, de modo que no estén en el mismo dedo? Los anillos se pueden colocar, según la ecuación (1.3), de \\[ C_{5,2}=\\binom{5}{2}=\\frac{5!}{2!\\left ( 5-2 \\right )!}=\\frac{5\\left ( 4 \\right )\\left ( 3! \\right )}{2!\\left ( 3! \\right )}=\\frac{5\\left ( 4 \\right )}{\\left ( 2 \\right )\\left ( 1 \\right )}=10 \\] maneras. Usando la función nsamp, al igual que en el ejemplo 1.14, el resultado anterior puede ser obtenido con el siguiente script. c2 &lt;- nsamp(n = 5, k = 2, replace = F, ordered = F) paste(&quot;Los anillos se pueden colocar de&quot;, c2,&quot;maneras&quot;) #&gt; [1] &quot;Los anillos se pueden colocar de 10 maneras&quot; El siguiente script lista el número de maneras diferentes en que se pueden colocar los anillos en dos dedos diferentes de una mano. urnsamples( 1:5, size = 2, replace = F, ordered = F ) #&gt; X1 X2 #&gt; 1 1 2 #&gt; 2 1 3 #&gt; 3 1 4 #&gt; 4 1 5 #&gt; 5 2 3 #&gt; 6 2 4 #&gt; 7 2 5 #&gt; 8 3 4 #&gt; 9 3 5 #&gt; 10 4 5 El resultado anterior, también se puede obtener con la función combinations del paquete gtools. combinations( n = 5, r = 2, v = 1:5, set = T, repeats.allowed = F ) #&gt; [,1] [,2] #&gt; [1,] 1 2 #&gt; [2,] 1 3 #&gt; [3,] 1 4 #&gt; [4,] 1 5 #&gt; [5,] 2 3 #&gt; [6,] 2 4 #&gt; [7,] 2 5 #&gt; [8,] 3 4 #&gt; [9,] 3 5 #&gt; [10,] 4 5 1.4.2 Combinación Con Repetición Definición 1.8 (Combinación Con Repetición) Dados \\(n\\) objetos distintos, el número de combinaciones que se pueden formar con \\(r\\) de estos objetos, pudiendo haber objetos repetidos viene dado por: \\[ \\begin{equation} CR_{n,r}=\\binom{n+r-1}{n-1}=\\binom{n+r-1}{r}=\\frac{\\left ( n+r-1 \\right )!}{r!\\left ( n-1 \\right )!}=\\frac{\\left ( n+r-1 \\right )\\left ( n+r-2 \\right )\\cdots\\left ( n+1 \\right )n}{r!}. \\tag{1.4} \\end{equation} \\] Ejemplo 1.16 (Combinación Con Repetición) En un avión hay argentinos, peruanos, españoles y venezolanos. Se entrevista al azar a 10 de ellos. ¿De cuántas formas diferentes pueden resultar las nacionalidades? En este ejemplo se tiene \\(n=4\\) nacionalidades distintas y se toma una muestra de \\(r=10\\) personas, note que en la muestra es posible que estén varios pasajeros de la misma nacionalidad. De la ecuación (1.4), el número de formas diferentes en que puede resultar la nacionalidad es: \\[ CR_{4,10}=\\binom{4+10-1}{4-1}=\\binom{13}{3}=\\frac{\\left ( 13 \\right )\\left ( 12 \\right )\\left ( 11 \\right )}{3!}=286. \\] La función nsamp del paquete prob, también ejecuta el cálculo anterior. Como se muestra en el siguiente bloque de código. c1 &lt;- nsamp(n = 4, k = 10, replace = T, ordered = F) paste(&quot;Pueden resultar&quot;, c1,&quot;nacionalidades distintas&quot;) #&gt; [1] &quot;Pueden resultar 286 nacionalidades distintas&quot; Ejemplo 1.17 (Combinación Con Repetición) ¿Cuántas fichas tiene el juego del dominó? Una ficha de dominó es un rectángulo en el que hay dos partes, en cada una de ellas hay una serie de puntos que indican la puntuación de esa parte. Estas puntuaciones van de blanca (0 puntos) a 6. Tenemos pares de puntuaciones de 0 a 6. El total de fichas en el dominó, de acuerdo con la ecuación (1.4), serán: \\[ CR_{7,2}=\\binom{7+2-1}{7-1}=\\binom{8}{6}=\\binom{8}{2}=\\frac{\\left ( 8 \\right )\\left ( 7 \\right )}{2!}=28. \\] Haciendo uso de la función nsamp del paquete prob, el resultado anterior puede ser replicado con el siguiente script. c1 &lt;- nsamp(n = 7, k = 2, replace = T, ordered = F) paste(&quot;Pueden resultar&quot;, c1,&quot;nacionalidades distintas&quot;) #&gt; [1] &quot;Pueden resultar 28 nacionalidades distintas&quot; Las piezas del dominó se pueden listar con el siguiente script. combinations( n = 7, r = 2, v = 0:6, set = T, repeats.allowed = T ) #&gt; [,1] [,2] #&gt; [1,] 0 0 #&gt; [2,] 0 1 #&gt; [3,] 0 2 #&gt; [4,] 0 3 #&gt; [5,] 0 4 #&gt; [6,] 0 5 #&gt; [7,] 0 6 #&gt; [8,] 1 1 #&gt; [9,] 1 2 #&gt; [10,] 1 3 #&gt; [11,] 1 4 #&gt; [12,] 1 5 #&gt; [13,] 1 6 #&gt; [14,] 2 2 #&gt; [15,] 2 3 #&gt; [16,] 2 4 #&gt; [17,] 2 5 #&gt; [18,] 2 6 #&gt; [19,] 3 3 #&gt; [20,] 3 4 #&gt; [21,] 3 5 #&gt; [22,] 3 6 #&gt; [23,] 4 4 #&gt; [24,] 4 5 #&gt; [25,] 4 6 #&gt; [26,] 5 5 #&gt; [27,] 5 6 #&gt; [28,] 6 6 Igual resultado se consigue con el siguiente fragmento de código. urnsamples( 0:6, size = 2, replace = T, ordered = F ) #&gt; X1 X2 #&gt; 1 0 0 #&gt; 2 0 1 #&gt; 3 0 2 #&gt; 4 0 3 #&gt; 5 0 4 #&gt; 6 0 5 #&gt; 7 0 6 #&gt; 8 1 1 #&gt; 9 1 2 #&gt; 10 1 3 #&gt; 11 1 4 #&gt; 12 1 5 #&gt; 13 1 6 #&gt; 14 2 2 #&gt; 15 2 3 #&gt; 16 2 4 #&gt; 17 2 5 #&gt; 18 2 6 #&gt; 19 3 3 #&gt; 20 3 4 #&gt; 21 3 5 #&gt; 22 3 6 #&gt; 23 4 4 #&gt; 24 4 5 #&gt; 25 4 6 #&gt; 26 5 5 #&gt; 27 5 6 #&gt; 28 6 6 1.5 Variación Definición 1.9 (Variación) Se define como cualquier arreglo, secuencias u ordenación de \\(r\\) objetos tomados de \\(n\\) objetos. 1.5.1 Variación Sin Repetición Definición 1.10 (Variación Sin Repetición) Dados \\(n\\) objetos diferente, el número de arreglos que se pueden formar con \\(r\\) de estos objetos viene dado por: \\[ \\begin{equation} V_{n,r}=\\frac{n!}{\\left( n-r\\right)!}=n\\,(n-1)\\,(n-2)\\cdots(n-r+1),\\:con\\: r\\leq n. \\tag{1.5} \\end{equation} \\] Ejemplo 1.14 (Variación Sin Repetición) En un año se otorgarán tres premios (a la investigación, la enseñanza y el servicio) en un grupo de 25 estudiantes de posgrado del departamento de estadística. Si cada estudiante puede recibir un premio como máximo, ¿cuántas selecciones posibles habría? Como los premios son distinguibles, se trata de un problema de variación. Por lo tanto, aplicando la ecuación (1.5), el número total de posibilidades es \\[ V_{25,3}=\\frac{25!}{\\left( 25-3\\right)!}=25\\,(24)\\,(23)=13.800. \\] Con la función nsamp del paquete prob, este resultado se obtiene con el siguiente trozo de código. c1 &lt;- nsamp(n = 25, k = 3, replace = F, ordered = T) paste(&quot;Se pueden hacer&quot;, formato(c1),&quot;selecciones&quot;) #&gt; [1] &quot;Se pueden hacer 13.800 selecciones&quot; Ejemplo 1.15 (Variación Sin Repetición) ¿De cuántas maneras se pueden colocar dos anillos diferentes en la misma mano, de modo que no estén en el mismo dedo? Dado que los anillos son diferentes, en contraposición con el ejemplo 1.15, el orden en que se coloquen en los dedo hace diferencia, por lo tanto se trata de un caso de variación sin repetición. Por lo tanto, el número de formas diferentes en que se pueden colocar los anillos en dos dedos diferentes de la mano, según la ecuación (1.5) es: \\[ V_{5,2}=\\frac{5!}{\\left( 5-3\\right)!}=\\frac{5!}{ 2!}=5\\,(4)=20. \\] Este resultado, se puede obtener con el siguiente script. c2 &lt;- nsamp(n = 5, k = 2, replace = F, ordered = T) paste(&quot;Los anillos se pueden colocar de&quot;, c2,&quot;maneras&quot;) #&gt; [1] &quot;Los anillos se pueden colocar de 20 maneras&quot; La lista de todas las posibles variaciones se puede obtener con el siguiente bloque de código. urnsamples( 1:5, size = 2, replace = F, ordered = T ) #&gt; X1 X2 #&gt; 1 1 2 #&gt; 2 2 1 #&gt; 3 1 3 #&gt; 4 3 1 #&gt; 5 1 4 #&gt; 6 4 1 #&gt; 7 1 5 #&gt; 8 5 1 #&gt; 9 2 3 #&gt; 10 3 2 #&gt; 11 2 4 #&gt; 12 4 2 #&gt; 13 2 5 #&gt; 14 5 2 #&gt; 15 3 4 #&gt; 16 4 3 #&gt; 17 3 5 #&gt; 18 5 3 #&gt; 19 4 5 #&gt; 20 5 4 El resultado anterior, también se puede obtener con la función permutations del paquete gtools. permutations( n = 5, r = 2, v = 1:5, set = TRUE, repeats.allowed = FALSE ) #&gt; [,1] [,2] #&gt; [1,] 1 2 #&gt; [2,] 1 3 #&gt; [3,] 1 4 #&gt; [4,] 1 5 #&gt; [5,] 2 1 #&gt; [6,] 2 3 #&gt; [7,] 2 4 #&gt; [8,] 2 5 #&gt; [9,] 3 1 #&gt; [10,] 3 2 #&gt; [11,] 3 4 #&gt; [12,] 3 5 #&gt; [13,] 4 1 #&gt; [14,] 4 2 #&gt; [15,] 4 3 #&gt; [16,] 4 5 #&gt; [17,] 5 1 #&gt; [18,] 5 2 #&gt; [19,] 5 3 #&gt; [20,] 5 4 1.5.2 Variación Con Repetición Definición 1.11 (Variación Con Repetición) Dados \\(n\\) objetos diferentes, el número de arreglos que se pueden formar con \\(r\\) de estos objetos, pudiendo ocurrir que un mismo objeto aparezca más de una vez en el arreglo, viene dado por: \\[ \\begin{equation} VR_{n,r}=n^r,\\:con\\: r\\leq n. \\tag{1.6} \\end{equation} \\] Ejemplo 1.18 (Variación Con Repetición) ¿Cuántos arreglos se pueden formar con las letras \\(a\\), \\(b\\), \\(c\\) y \\(d\\); tomando dos de ellas y suponiendo que las letras se pueden repetir. El número de arreglos posibles es el siguiente: \\[ \\begin{Bmatrix} (a,a);&amp;(a,b);&amp;(a,c);&amp;(a,d);\\\\(b,a);&amp;(b,b);&amp;(b,c);&amp;(b,d);\\\\(c,a);&amp;(c,b);&amp;(c,c);&amp;(c,d);\\\\(d,a);&amp;(d,b) ;&amp;(d,c);&amp;(d,d) \\end{Bmatrix}. \\] El número de arreglos diferentes que se pueden formar sin necesidad de listarlos, de acuerdo con la ecuación (1.6) es: \\[ VR_{4,2}=4^2=16. \\] La función nsamp del paquete prob ejecuta el cálculo anterior, por medio del siguiente bloque de código. c1 &lt;- nsamp(n = 4, k = 2, replace = T, ordered = T) paste(&quot;Se pueden formar&quot;, formato(c1),&quot;arreglos&quot;) #&gt; [1] &quot;Se pueden formar 16 arreglos&quot; La lista de arreglos, usando R, se puede obtener con la siguiente instrucción. urnsamples( c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), size = 2, replace = T, ordered = T ) #&gt; X1 X2 #&gt; 1 a a #&gt; 2 b a #&gt; 3 c a #&gt; 4 d a #&gt; 5 a b #&gt; 6 b b #&gt; 7 c b #&gt; 8 d b #&gt; 9 a c #&gt; 10 b c #&gt; 11 c c #&gt; 12 d c #&gt; 13 a d #&gt; 14 b d #&gt; 15 c d #&gt; 16 d d 1.6 Ejercicios de Técnicas de Conteo Se va a despachar una flotilla de nueve taxis a tres aeropuertos, de modo que tres irán al aeropuerto A, cinco al aeropuerto B y uno al aeropuerto C. ¿De cuántas maneras distintas puede llevarse a cabo la tarea? ¿Cuántos números telefónicos distintos de siete dígitos pueden se pueden formar si el primero no puede ser cero? Un lujoso restaurante ofrece un menú especial o fixe prix, en el que por el precio de una comida puede elegir entre cuatro clases de aperitivos, tres de ensaladas, cuatro de guisados y cinco de postres. ¿Cuántos tipos de menú se ofrecen si cualquiera de ellos consta de aperitivo, ensalada, guisado y postre? Una mujer de negocios de Margarita desea prepara un itinerario para visitar seis ciudades importantes de Venezuela. La distancia del viaje y, por consiguiente, su costo depende del orden en que planifique su ruta. ¿Cuántos itinerarios diferentes (y costos de viaje) son posibles? Se llevó a cavo un estudio en la Universidad de Oriente Núcleo de Nueva Esparta para determinar la efectividad de cierta estrategia pedagógica. Para ello se tomó una muestra de 20 docentes de la institución. Si en la UDONE laboran 200 docentes. ¿Cuántas muestras diferentes pueden seleccionarse? Si de éstos 200 docentes el 40% son mujeres. ¿Cuántas muestras diferentes pueden obtenerse si el 40% de la muestra debe estar conformada por mujeres? Un grupo de amigos y amigas se encuentran y se dan un beso para saludarse. Si se han dado en total 21 besos. ¿Cuántas personas había? Lola tiene 25 bolitas (10 rojas, 8 azules y 7 blancas) para hacer un collar. Engarzando las 25 bolitas en un hilo, ¿cuántos collares distintos podrá realizar? Una fábrica de helados dispone de cinco sabores distintos (vainilla, chocolate, nata, fresa y cola) y quiere hacer helados de dos sabores. ¿cuántos tipos de helados podría fabricar? ¿De cuántas formas pueden cubrirse los cargos de presidente, vicepresidente, secretario y tesorero de un club deportivo sabiendo que hay 14 candidatos? En una carrera de 500 metros participan doce corredores. ¿De cuántas maneras pueden adjudicarse la medalla de oro, plata y bronce; suponiendo que no es posible de que ocurran empates? ¿Cuántas palabras distintas, con o sin sentido, podremos formar con las letras de la palabra educación? ¿y con la palabra vacaciones? ¿Cuántos números de seis cifras existen que estén formados por cuatro números dos y por dos números tres? ¿cuántos números de tres cifras se pueden formar con los dígitos 0, 1, 2, 3, 4, 5, 6 , 7, 8, 9 si ninguno se puede repetir? Con los números 1, 2, 3, 4, 5 y 6: ¿Cuántos números distintos de siete cifras podríamos formar? ¿Podremos numerar a los 3.224.564 habitantes de una ciudad con esos números? 1.7 Información de Sesión as_tibble(devtools::session_info()$packages) %&gt;% dplyr::select( package, loadedversion, source ) %&gt;% dplyr::filter( package %in% packages ) %&gt;% DT::datatable( rownames = FALSE, colnames = c(&quot;Paquete&quot;, &quot;Versión&quot;, &quot;Fuente&quot;), caption = &quot;Información de sesión&quot;, filter = &quot;top&quot;, selection = &quot;multiple&quot;, class = &quot;cell-border stripe&quot; ) "],["nt2.html", "Núcleo Temático 2 Princípios Básicos de Probabilidades 2.1 Introducción a los Conjuntos 2.2 Operaciones Entre Conjuntos 2.3 Introducción a la Probabilidad", " Núcleo Temático 2 Princípios Básicos de Probabilidades En este Núcleo Temático se definen algunos conceptos que servirán de soporte para comprender el concepto de probabilidad. Para ello, en la primera sección, se hace una introducción a los conjuntos, lo cual es necesario para entender la definición clásica de la probabilidad. Luego, en la segunda sección, se definen algunas operaciones con conjuntos. Por último, la tercera sección, constituye una introducción a la probabilidad. El siguiente bloque de código permite instalar y cargar los paquetes de R que se usaran en esta sección. packages &lt;- c( &quot;ggplot2&quot;, &quot;ggstatsplot&quot;, &quot;ggVennDiagram&quot;, &quot;eulerr&quot;, &quot;venneuler&quot;, &quot;VennDiagram&quot; ) package.check &lt;- lapply(packages, FUN = function(x) { if (!require(x, character.only = TRUE)) { install.packages(x, dependencies = TRUE) library(x, character.only = TRUE) } }) 2.1 Introducción a los Conjuntos En esta sección se definen algunos conceptos relacionados a la teoría de conjuntos. Estos conceptos son necesarios para entender el enfoque clásico de la probabilidad, el cual se describe en la sección 2.3.4.1. 2.1.1 Conjunto Definición 2.1 (Conjunto) Un conjunto es una colección bien definida de objetos, los cuales se denominan elementos o miembros del conjunto. Generalmente se utilizan letras mayúsculas, como \\(A\\), \\(B\\), \\(X\\), \\(Y\\), \\(\\dotsc\\) para designar los conjuntos, y letras minúsculas, como \\(a\\), \\(b\\), \\(x\\), \\(y\\), \\(\\dotsc\\) para designar los elementos de los conjuntos. Las palabras clase, colección y familia son sinónimos de conjunto. Para decir que un elemento \\(a\\) pertenece a un conjunto \\(A\\) se escribe \\(a \\in A\\). (Donde el símbolo \\(\\in\\) significa es un elemento de). También se escribe \\(a,b \\in A\\) cuando \\(a\\) y \\(b\\) pertenecen a A. 2.1.1.1 Formulación de Conjuntos por Extensión Definición 2.2 (Formulación de Conjuntos por Extensión) Consiste en formular el conjunto listando todos los elementos del conjunto. Por ejemplo, \\[A=\\left\\{1,2,3 ,5,7,9\\right\\}\\] significa que \\(A\\) es el conjunto que comprende los números \\(1, 2, 3 ,5, 7 \\:y\\: 9\\). Observe que los elementos del conjunto están separados por comas y encerrados en corchetes\\(\\{\\:\\:\\}\\). 2.1.1.2 Formulación de Conjuntos por Comprensión Definición 2.3 (Formulación de Conjuntos por Comprensión) Consiste en formular el conjunto a través de propiedades que caracterizan los elementos en el conjunto, es decir, las propiedades que tienen los miembros del conjunto y que no tienen los no miembros. Por ejemplo: \\[A=\\left\\{x:x \\:es\\: \\:un\\: número\\: impar, \\,x&lt;10\\right\\}.\\] En muchos casos es inviable formular un conjunto por extensión, en tal caso se hace necesario formularlo por comprensión. 2.1.1.3 Tamaño de un Conjunto Definición 2.4 (Tamaño de un Conjunto) El tamaño de un conjunto \\(S\\) (también, cardinalidad o cardinal del conjunto) es el número de elementos del conjunto y se denota por \\(n(S)\\). El tamaño del conjunto vacío es cero, es decir, \\(n(\\emptyset)=0\\). 2.1.1.4 Conjunto Finito Definición 2.5 (Conjunto Finito) Un conjunto \\(S\\) es finito si \\(S\\) es vacío o si el tamaño de \\(S\\) es exactamente un número \\(m\\) entero positivo \\(\\left(n(S) = m \\in \\mathbb{ N } \\right)\\); de otra manera es infinito. 2.1.1.5 Conjunto Contable Definición 2.6 (Conjunto Contable) Un conjunto \\(S\\) es contable si \\(S\\) es finito o si los elementos de \\(S\\) pueden ser colocados en forma de sucesión, en cuyo caso se dice que \\(S\\) es infinito contable. Un conjunto es incontable si este no es contable. Considere los siguientes ejemplos: Sea \\(A\\) el conjunto de las letras del alfabeto y sea \\(D\\) los días de la semana, es decir, \\(A=\\left\\{a,b,\\dotsc,y,z\\right\\}\\) y \\(D=\\left\\{lunes,martes,\\dotsc,domingo \\right\\}\\). Entonces \\(A\\) y \\(D\\) son conjuntos finitos. Específicamente el tamaño de \\(A\\) es 27 \\(\\left(n(A)=27 \\right)\\) y el tamaño de \\(D\\) es 7 \\(\\left(n(D)=7\\right)\\). Sea \\(R=\\left\\{x:x \\textit{ es un río de la tierra} \\right\\}\\). Aunque puede ser difícil contar el número de ríos sobre la tierra, \\(R\\) continúa siendo un conjunto finito. Sea \\(E\\) el conjunto de los enteros positivos pares y sea \\(I\\) el intervalo unidad; es decir, \\(E=\\left\\{2,4,6,\\dotsc\\right\\}\\) e \\(I=[0,1]=\\left\\{x:0x1\\right\\}\\). Entonces, ambos conjuntos son infinitos. De manera particular \\(E\\) es infinito contable e \\(I\\) es infinito incontable. 2.1.2 Subconjunto Definición 2.7 (Subconjunto) Sean \\(A\\), \\(B\\) dos conjuntos; se dice que \\(A\\) es un subconjunto de \\(B\\), o se dice también que \\(A\\) está contenido en \\(B\\), si todos los elemento del conjunto \\(A\\) también pertenecen al conjunto \\(B\\), y se escribe como \\(A \\subseteq B\\) o \\(B \\supseteq A\\). La afirmación \\(A \\subseteq B\\) no excluye la posibilidad de que \\(A=B\\). Sin embargo, si \\(A \\subseteq B\\) y \\(A\\neq B\\), entonces se dice que \\(A\\) es un subconjunto propio de \\(B\\) (escrito algunas veces \\(A \\subset B\\)). 2.1.3 Conjuntos Iguales Definición 2.8 (Conjunto Iguales) Dos conjuntos \\(A\\), \\(B\\) son iguales si ambos contienen exactamente los mismos elementos o, en forma equivalente, si cada uno está contenido en el otro. Es decir, \\(A = B\\) si y sólo si \\(A \\subseteq B\\) y \\(B \\supseteq A\\). Esto implica que si cualquier elemento \\(a \\in A\\), entonces \\(a \\in B\\). Las negaciones de \\(a \\in A, A \\subseteq B, B \\supseteq A, \\:y\\: A=B\\) se escriben \\(a \\notin A\\), \\(A \\nsubseteq B, B \\nsupseteq A, \\:y\\: A \\neq B\\). Teorema 2.1 Sean \\(A\\), \\(B\\), \\(C\\) cualquier conjunto. Entonces: \\(A \\subseteq A\\) Si \\(A \\subseteq B\\) y \\(B \\supseteq A\\), entonces \\(A=B\\) Si \\(A \\subseteq B\\) y \\(B \\subseteq C\\), entonces \\(A \\subseteq C\\). 2.1.4 Conjuntos Universal Definición 2.9 (Conjunto Universal) Es cualquier conjunto \\(\\mathbb{U}\\) que contiene a todos los conjuntos bajo investigación en cualquier aplicación de una teoría de conjuntos. Por ejemplo en geometría de planos, el conjunto universal comprende todos los puntos en el plano; en los estudios de población humana, el conjunto universal consiste de todas las personas del mundo. 2.1.5 Conjuntos Vacio o Conjunto Nulo Definición 2.10 (Conjunto Vacio) Un conjunto vacío es aquel que no tiene elementos y se representa por \\(\\emptyset\\). Por ejemplo, el conjunto \\(S=\\left\\{x:x \\textit{ es un entero positivo},x^2=3 \\right\\}\\) es un conjunto vacío, puesto que ningún entero positivo tiene la propiedad requerida. Teorema 2.2 Para cualquier conjunto \\(A\\), se tiene \\(\\emptyset \\subseteq A \\subseteq \\mathbb{U}\\). 2.1.6 Conjuntos Disyuntos o Mutuamente Excluyentes o Ajenos Definición 2.11 (Conjuntos Disyuntos o Mutuamente excluyentes o Ajenos) Se dice que dos conjuntos \\(A\\), \\(B\\) son disyuntos si estos no tienen elementos en común. Consideremos, por ejemplo, los conjuntos \\[A=\\left\\{1,2\\right\\}; B=\\left\\{2,4,6\\right\\}; C=\\left\\{4,5,6,7\\right\\}.\\] Observe que \\(A\\) y \\(B\\) no son disyuntos porque cada uno tiene el elemento 2, y \\(B\\) y \\(C\\) no son disyuntos puesto que cada uno contiene el elemento 4, entre otros. Por otra parte, \\(A\\) y \\(C\\) son disyuntos dado que estos no tienen elementos en común. Se observa que si dos conjuntos son disyuntos, entonces ninguno es subconjunto del otro (a menos que uno sea el conjunto vacio). 2.1.7 Conjunto Solapados o Traslapados Definición 2.11 (Conjunto Solapados o Traslapados) Se dice que dos conjuntos \\(A\\), \\(B\\) son solapados si estos tienen por lo menos un elemento en común. Consideremos, por ejemplo, los conjuntos \\[A=\\left\\{1,2\\right\\}; B=\\left\\{2,4,6\\right\\}; C=\\left\\{4,5,6,7\\right\\}.\\] Observe que \\(A\\) y \\(B\\) son solapados porque cada uno tiene el elemento 2, y B y C son solapados puesto que cada uno contiene el elemento 4, entre otros. 2.1.8 Diagrama de Venn Definición 2.12 (Diagrama de Venn) Un diagrama de Venn es una representación en dibujo de conjuntos, donde estos están representados por áreas encerradas en el plano. El conjunto universal \\(\\mathbb{U}\\) está representado por los puntos en un rectángulo y los demás conjuntos están representados por círculos, elipses o óvalos, generalmente; que se encuentran dentro de los rectángulos. La figura 2.1 ilustra por medio de diagramas de Venn diferentes relaciones entre los conjuntos \\(A\\) y \\(B\\). knitr::include_graphics(path = &quot;figuras/diagrama_venn.png&quot;) Figura 2.1: Diagramas de Venn 2.1.9 Partición Definición 2.13 (Partición) Sea \\(S\\) un conjunto no vacío. Una partición de \\(S\\) es una colección \\(\\left\\{A_i \\right\\}\\) de subconjuntos no vacíos de \\(S\\) tales que: Cada \\(a\\) en \\(S\\) pertenece a uno de los subconjuntos \\(A_i\\). Los conjuntos de \\(\\left\\{A_i \\right\\}\\) son mutuamente excluyentes; es decir, si \\[A_iA_j, \\textit{entonces } A_i \\cap A_j= \\emptyset.\\] Los subconjuntos de una partición se denominan células. La figura 2.2 muestra la partición de un conjunto rectangular \\(S\\) de puntos, en cinco células, \\(A_1\\), \\(A_2\\), \\(A_3\\), \\(A_4\\), \\(A_5\\). knitr::include_graphics(path = &quot;figuras/particion.png&quot;) Figura 2.2: Diagrama de Venn de la partición de un conjunto rectangular \\(S\\) 2.2 Operaciones Entre Conjuntos En esta sección se definen las operaciones básicas entre conjuntos, tales como: intersección, unión, complemento, diferencia y diferencia simétrica. Destacando las propiedades de estas operaciones. 2.2.1 Intersección Definición 2.14 (Intersepción) La intersección de dos conjuntos \\(A\\) y \\(B\\), representada por \\(A \\cap B\\), es el conjunto de todos los elementos que pertenecen tanto al conjunto \\(A\\) como al conjunto $B, es decir, \\[A \\cap B=\\left\\{x:x \\in A \\:y\\: x \\in B \\right\\}\\]. La figura 2.3 muestra diagramas de Venn que ilustran la intersección de los conjunto \\(A\\) y \\(B\\). knitr::include_graphics(path = &quot;figuras/interseccion.png&quot;) Figura 2.3: Diagrama de Venn para la intersección 2.2.1.1 Propiedades de la Intersección \\(A \\cap \\emptyset=\\). \\(A \\cap \\mathbb{U}=A\\). \\(A \\cap A=A\\). (Idempotencia) \\(A \\cap B=B \\cap A\\). (Conmutativa) \\(A \\cap B \\cap C=(A \\cap B) \\cap C=A \\cap (B \\cap C)=\\left(A \\cap C \\right) \\cap B\\). (Asociativa) \\((A \\cap B) \\subseteq A\\). \\((A \\cap B)\\subseteq B\\). Ejemplo 2.1 (Intersección) Sea \\(A=\\left\\{ a, b, c, d, e, f , g, h \\right\\}\\) y \\(B=\\left\\{ f, g, h, i, j, k, l \\right\\}\\). Determine \\(A \\cap B\\). De acuerdo con la definición 2.14, la intersección de los conjuntos \\(A\\) y \\(B\\) es \\[A \\cap B = \\left\\{ f , g, h \\right\\}.\\] El resultado anterior, se puede obtener con el siguiente script, usando la función intersect de la distribución base de R. A &lt;- letters[1:8] B &lt;- letters[6:12] (AyB &lt;- intersect(A, B)) #&gt; [1] &quot;f&quot; &quot;g&quot; &quot;h&quot; El diagrama de Venn para este ejemplo se muestra con la función ggVennDiagram del paquete ggVennDiagram. El resultado de la ejecución de esta función es la figura 2.4. # Lista de vectores x &lt;- list(A , B) # Diagrama de Venn con borde personalizado ggVennDiagram( x, color = &quot;black&quot;, lwd = 0.8, lty = 1, category.names = c(&quot;A&quot;, &quot;B&quot;), ) + scale_fill_gradient(low = &quot;#F4FAFE&quot;, high = &quot;#4981BF&quot;) Figura 2.4: Diagrama de Venn para el ejemplo 1 de la intersección Ejemplo 2.2 (Intersección) Dados los conjuntos \\(A=\\left\\{ 1, 2, 3, 4, 5 \\right\\}\\), \\(B=\\left\\{ 2, 3, 4, 5, 6, 7 \\right\\}\\) y \\(C=\\left\\{ 5, 6, 7, 8, 9, 10 \\right\\}\\). Determine \\(A \\cap B \\cap C\\). Extendiendo la definición 2.14 para tres conjuntos, la intersección de los conjuntos \\(A\\), \\(B\\) y \\(C\\) son los elementos que se repiten en los tres conjuntos, es decir: \\[A \\cap B \\cap C = \\left\\{5 \\right\\}.\\] El resultado anterior, se puede obtener con el siguiente script, usando la función intersect de la distribución base de R. A &lt;- 1:5 B &lt;- 2:7 C &lt;- 5:10 (AyByC &lt;- intersect(intersect(A,B), C)) #&gt; [1] 5 El Diagrama de Venn para este ejemplo se muestra en la figura 2.5. # Lista de vectores x &lt;- list(A , B , C) # Diagrama de Venn con borde personalizado ggVennDiagram( x, color = &quot;black&quot;, lwd = 0.8, lty = 1, category.names = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), ) + scale_fill_gradient(low = &quot;#F4FAFE&quot;, high = &quot;#4981BF&quot;) Figura 2.5: Diagrama de Venn para el ejemplo 2 de la intersección 2.2.2 Unión Definición 2.15 (Unión) La unión de dos conjuntos \\(A\\) y \\(B\\), representada por \\(A \\cup B\\), es el conjunto de todos los elementos que pertenecen al conjunto \\(A\\) o al conjunto \\(B\\) o a ambos, es decir, \\[AB=\\left\\{x:x \\in A \\textit{ o } x \\in B\\right\\}.\\] La figura 2.6 muestra diagramas de Venn que ilustran la unión de los conjunto \\(A\\) y \\(B\\). knitr::include_graphics(path = &quot;figuras/union.png&quot;) Figura 2.6: Diagrama de Venn para la Unión 2.2.2.1 Propiedades de la Unión \\(A \\cup =A\\). \\(A \\cup \\mathbb{U}=\\mathbb{U}\\). \\(A \\cup A=A\\). (Idempotencia) \\(A \\cup B=B \\cup A\\). (Conmutativa) \\(A \\cup B \\cup C=(A \\cup B) \\cup C=A \\cup (B \\cup C)=\\left(A \\cup C \\right) \\cup B\\). (Asociativa) \\(A \\subseteq (A \\cup B)\\). \\(B\\subseteq(A \\cup B)\\). \\(A \\cap (B \\cup C)=(A \\cap B) \\cup (A \\cap C)\\). (Distributiva de la intersección) \\(A \\cup (B \\cap C)=(A \\cup B) \\cap (A \\cup C)\\). (Distributiva de la unión) Ejemplo 2.3 (Unión) Dados los conjuntos \\(A\\), \\(B\\), especificados en el ejemplo 2.1, determine \\(A \\cup B\\). De acuerdo con la definición 2.15, la unión de los conjuntos \\(A\\) y \\(B\\) es \\[A \\cup B = \\left\\{a , b, c, d, e, f, g, h, i, j, k, l \\right\\}.\\] El resultado anterior, se puede obtener con el siguiente script, usando la función union de la distribución base de R. A &lt;- letters[1:8] B &lt;- letters[6:12] (AoB &lt;- union(A, B)) #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; Ejemplo 2.4 (Unión) Dados los conjuntos \\(A\\), \\(B\\), \\(C\\), especificados en el ejemplo 2.2, determine \\(A \\cup B \\cup C\\). De acuerdo con la definición 2.15, la unión de los conjuntos \\(A\\) y \\(B\\) es \\[A \\cup B \\cup C= \\left\\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10 \\right\\}.\\] El resultado anterior, se puede obtener con el siguiente script, usando la función union de la distribución base de R. A &lt;- 1:5 B &lt;- 2:7 C &lt;- 5:10 (AoBoC &lt;- union(union(A,B), C)) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 2.2.3 Complemento Definición 2.16 (Complemeto) El complemento absoluto o, simplemente, el complemento de un conjunto \\(A\\), representado por \\(A^c\\), es el conjunto de elementos que pertenecen a \\(\\mathbb{U}\\) pero que no pertenecen a \\(A\\), es decir, \\[A^c=\\left\\{x:x\\mathbb{U},x \\notin A\\right\\}.\\] Algunos textos representan el complemento de \\(A\\) mediante \\(A&#39;\\) o \\(\\bar{A}\\). La figura 2.7 muestra el diagramas de Venn para \\(A^c\\). La zona coloreada en azul representa el conjunto \\(A^c\\). knitr::include_graphics(path = &quot;figuras/complemento.png&quot;) Figura 2.7: Diagrama de Venn para el complemento 2.2.3.1 Propiedades del Complemento \\(\\left(A^c \\right)^c=A\\). (Propiedad Involutiva) \\(A \\cup A^c = \\mathbb{U}\\) \\(A \\cap A^c=\\emptyset\\) \\(\\mathbb{U}^c=\\emptyset\\) \\(\\emptyset^c=\\mathbb{U}\\) 2.2.3.2 Leyes de Morgan \\(\\left(A \\cup B \\right)^c=A^c \\cap B^c\\) \\(\\left(A \\cap B \\right)^c=A^c \\cup B^c\\) Ejemplo 2.5 (Complemento) Dado el conjunto universal \\(\\mathbb{U}\\), el cual representa el alfabeto inglés (no contiene la letra ñ). Dado el conjunto \\[A= \\left\\{l, w, z, f, s, m, y, v, c, p, q, x, k, b, j \\right\\}.\\] Determine el complemento de A \\(\\left(A^c \\right)\\). De acuerdo con la definición 2.16, el complemento de \\(A\\) es: \\[A^c = \\left\\{a, d, e, g, h, i, n, o, r, t, u \\right\\}.\\] El resultado anterior, se puede obtener con el siguiente script, usando la función setdiff de la distribución base de R. A &lt;- c( &quot;l&quot;, &quot;w&quot;, &quot;z&quot;, &quot;f&quot;, &quot;s&quot;, &quot;m&quot;, &quot;y&quot;, &quot;v&quot;, &quot;c&quot;, &quot;p&quot;, &quot;q&quot;, &quot;x&quot;, &quot;k&quot;, &quot;b&quot;, &quot;j&quot; ) U &lt;- letters (Ac &lt;- setdiff(U, A)) #&gt; [1] &quot;a&quot; &quot;d&quot; &quot;e&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;n&quot; &quot;o&quot; &quot;r&quot; &quot;t&quot; &quot;u&quot; Con el siguiente trozo de código se verifican las propiedades del complemento, dadas en la sección 2.2.3.1, para el ejemplo en cuestión. Acc &lt;- setdiff(U, Ac) CV &lt;- as.character(c()) (a &lt;- setequal(Acc, A)) (b &lt;- setequal(union(A, Ac), U)) (c &lt;- setequal(intersect(A, Ac), CV)) (d &lt;- setequal(setdiff(U, U), CV)) 2.2.4 Diferencia Definición 2.17 (Diferencia) El complemento relativo de un conjunto \\(B\\) con respecto a un conjunto \\(A\\), o, simplemente, la diferencia entre \\(A\\) y \\(B\\), representado por \\(A \\setminus B\\), es el conjunto de elementos que pertenecen a \\(A\\) pero que no pertenecen a \\(B\\), es decir, \\[A \\setminus B=\\left\\{x:x \\in A,x \\notin B \\right\\}.\\] El conjunto \\(A \\setminus B\\) se lee \\(A\\) menos \\(B\\). Algunos textos representan \\(A \\setminus B\\) mediante \\(A-B\\) o \\(A \\sim B\\). La figura 2.8 muestra el diagramas de Venn para \\(A \\setminus B\\). knitr::include_graphics(path = &quot;figuras/diferencia.png&quot;) Figura 2.8: Diagrama de Venn para la diferencia 2.2.4.1 Propiedades de la Diferencia \\(A \\setminus B \\neq B \\setminus A\\) (la diferencia no es conmutativa). \\(A \\setminus B= A \\cap B^c \\:o\\: BA=B \\cap A^c\\). \\(\\mathbb{U} \\setminus A=A^c\\) \\((A \\setminus B) \\cap (B \\setminus A )=\\emptyset\\) \\(A \\setminus B \\subseteq A\\) Ejemplo 2.6 (Diferencia) Se tiene el conjunto universal \\(\\mathbb{U}\\) representado por el alfabeto inglés. Por otro lado, se tienen los conjunto \\(A= \\left\\{d, s, l, y, h, t, b, u, f, n \\right\\}\\) y \\(B= \\left\\{p, y, u, m, k, f, r, j, h, n \\right\\}\\). Determine \\(A \\setminus B\\) y \\(B \\setminus A\\). De acuerdo con la definición 2.17, \\(A\\) menos \\(B\\) es: \\[A \\setminus B = \\left\\{d, s, l, t, b \\right\\}.\\] Mientras que \\(B\\) menos \\(A\\) es: \\[B \\setminus A = \\left\\{p, m, k, r, j \\right\\}.\\] El resultado anterior se puede obtener con el siguiente script, usando la función setdiff de la distribución base de R. U &lt;- letters A &lt;- c(&quot;d&quot;, &quot;s&quot;, &quot;l&quot;, &quot;y&quot;, &quot;h&quot;, &quot;t&quot;, &quot;b&quot;, &quot;u&quot;, &quot;f&quot;, &quot;n&quot; ) B &lt;- c(&quot;p&quot;, &quot;y&quot;, &quot;u&quot;, &quot;m&quot;, &quot;k&quot;, &quot;f&quot;, &quot;r&quot;, &quot;j&quot;, &quot;h&quot;, &quot;n&quot;) (AmenosB &lt;- setdiff(A, B)) (BmenosA &lt;- setdiff(B, A)) #&gt; [1] &quot;d&quot; &quot;s&quot; &quot;l&quot; &quot;t&quot; &quot;b&quot; #&gt; [1] &quot;p&quot; &quot;m&quot; &quot;k&quot; &quot;r&quot; &quot;j&quot; Las propiedades de la diferencia descritas en la sección 2.2.1.1 se pueden verificar en este ejercicio por medio del siguiente script. (a &lt;- setequal(AmenosB, BmenosA)) (b &lt;- setequal(AmenosB, intersect(A, setdiff(U, B)))) (c &lt;- setequal(setdiff(U, A), setdiff(U, A))) (d &lt;- setequal(intersect(AmenosB,BmenosA), CV)) #&gt; [1] FALSE #&gt; [1] TRUE #&gt; [1] TRUE #&gt; [1] TRUE 2.2.5 Diferencia Simétrica Definición 2.18 (Diferencia simétrica) La diferencia simétrica de los conjuntos \\(A\\) y \\(B\\), representado por \\(A \\oplus B\\), es el conjunto de elementos que pertenecen \\(A\\) o a \\(B\\), pero no a ambos. Es decir, \\(A \\oplus B=(A \\cup B) \\setminus (A \\cap B)\\) o \\(A \\oplus B=(A \\setminus B) \\cup (B \\setminus A)\\). Algunos textos representan \\(A \\oplus B\\) mediante \\(A \\triangleright B\\). La figura 2.9 muestra el diagramas de Venn para \\(A \\oplus B\\). El Área coloreada representa el conjunto \\(A \\oplus B\\). knitr::include_graphics(path = &quot;figuras/diferenciasimetrica.png&quot;) Figura 2.9: Diagrama de Venn para la diferencia simétrica 2.2.5.1 Propiedades de la Diferencia Simétrica \\(A \\oplus B=B \\oplus A\\) (conmutativa) \\(A \\oplus B \\oplus C=(A \\oplus B) \\oplus C=A \\oplus (B \\oplus C)=(A \\oplus C) \\oplus B\\) (asociativa) Ejemplo 2.7 (Diferencia Simétrica) Dados los conjuntos \\(A\\), \\(B\\), especificados en el ejemplo 2.6, determine \\(A \\oplus B\\) y \\(B \\oplus A\\) y verifique la propiedad conmutativa de la diferencia simétrica. De acuerdo con la definición 2.18 \\[A \\oplus B= \\left\\{d, s, l, t, b, p, m, k, r, j \\right\\}\\], mientras que \\[B \\oplus A= \\left\\{p, m, k, r, j, d, s, l, t, b \\right\\}.\\] Note que \\(A \\oplus B = B \\oplus A\\), dado que ambos conjuntos contienen los mismos elementos. (Revise la definición 2.8). El resultado anterior, se puede obtener con el siguiente script. A &lt;- c(&quot;d&quot;, &quot;s&quot;, &quot;l&quot;, &quot;y&quot;, &quot;h&quot;, &quot;t&quot;, &quot;b&quot;, &quot;u&quot;, &quot;f&quot;, &quot;n&quot; ) B &lt;- c(&quot;p&quot;, &quot;y&quot;, &quot;u&quot;, &quot;m&quot;, &quot;k&quot;, &quot;f&quot;, &quot;r&quot;, &quot;j&quot;, &quot;h&quot;, &quot;n&quot;) AmenosB &lt;- setdiff(A, B) BmenosA &lt;- setdiff(B, A) (AomasB &lt;- setdiff(union(A, B), intersect(A, B))) (BomasA &lt;- setdiff(union(B, A), intersect(B, A))) setequal(AomasB, BomasA) # Otra forma de obtener la diferencia simétrica (AomasB_2 &lt;- union(AmenosB, BmenosA)) (BomasA_2 &lt;- union(BmenosA, AmenosB)) setequal(AomasB_2, BomasA_2) #&gt; [1] &quot;d&quot; &quot;s&quot; &quot;l&quot; &quot;t&quot; &quot;b&quot; &quot;p&quot; &quot;m&quot; &quot;k&quot; &quot;r&quot; &quot;j&quot; #&gt; [1] &quot;p&quot; &quot;m&quot; &quot;k&quot; &quot;r&quot; &quot;j&quot; &quot;d&quot; &quot;s&quot; &quot;l&quot; &quot;t&quot; &quot;b&quot; #&gt; [1] TRUE #&gt; [1] &quot;d&quot; &quot;s&quot; &quot;l&quot; &quot;t&quot; &quot;b&quot; &quot;p&quot; &quot;m&quot; &quot;k&quot; &quot;r&quot; &quot;j&quot; #&gt; [1] &quot;p&quot; &quot;m&quot; &quot;k&quot; &quot;r&quot; &quot;j&quot; &quot;d&quot; &quot;s&quot; &quot;l&quot; &quot;t&quot; &quot;b&quot; #&gt; [1] TRUE 2.2.6 Principios para Determinar el Tamaño de un Conjunto Sean \\(A\\) y \\(B\\) conjuntos finitos disyuntos. Entonces \\(A \\cup B\\) es finito y \\[ \\begin{equation} n \\left(A \\cup B \\right) = n\\left(A \\right) + n\\left(B \\right). \\tag{2.1} \\end{equation} \\] Sean \\(A\\) y \\(B\\) conjuntos finitos. Entonces \\[ \\begin{equation} n \\left(A \\setminus B \\right)=n(A) - n(A \\cap B). \\tag{2.2} \\end{equation} \\] Suponiendo que \\(A\\) es un subconjunto del conjunto Universal \\(\\mathbb{U}\\). Entonces \\[ \\begin{equation} n \\left(A^c \\right)=n \\left(\\mathbb{U} \\right)-n \\left(A \\right). \\tag{2.3} \\end{equation} \\] Principio de Inclusión-Exclusión Sean \\(A\\) y \\(B\\) conjuntos finitos. Entonces \\(AB\\) y \\(AB\\) son finitos y \\[ \\begin{equation} n \\left( A \\cup B \\right)=n \\left(A \\right) + n \\left(B \\right) - n \\left(A \\cap B \\right). \\tag{2.4} \\end{equation} \\] Es decir, el número de elementos que están en \\(A\\) o en \\(B\\) (o ambos) se encuentran sumando primero \\(n \\left(A \\right)\\) y \\(n \\left(B \\right)\\) (inclusión) y luego restando \\(n \\left(A \\cap B \\right)\\) (exclusión), puesto que sus elementos fueron contados dos veces. Fíjese que si los conjuntos \\(A\\) y \\(B\\) son disyuntos, entonces \\[ n \\left(A \\cup B \\right)=n\\left(A \\right)+n \\left(B \\right), \\] dado que \\(A \\cap B = \\emptyset\\). Este resultado se puede extender para tres conjuntos de la siguiente manera: Supongamos que \\(A\\), \\(B\\), \\(C\\) son tres conjuntos finitos. Entonces \\(A \\cup B \\cup C\\) es finito y \\[ \\begin{align*} n \\left(A \\cup B \\cup C \\right) = \\:\\: &amp; n \\left(A \\right) + n \\left(B \\right) + n \\left(C \\right) - n \\left(A \\cap B \\right) - n \\left(A \\cap C \\right)\\\\ &amp;- n \\left(B \\cap C \\right) + n \\left(A \\cap B \\cap C \\right). \\tag{2.5} \\end{align*} \\] Sean \\(A\\) y \\(B\\) conjuntos finitos. Entonces \\(A \\oplus B\\) es finito y \\[ \\begin{equation} n \\left(A \\oplus B \\right)=n \\left(A \\right) + n \\left(B \\right) - 2n \\left(A \\cap B \\right). \\tag{2.6} \\end{equation} \\] Se excluyen dos veces el número de elementos en \\(\\left(A \\cap B \\right)\\) ya que estos están contenidos en \\(A\\) y en \\(B\\). El principio anterior se puede extender a tres conjuntos de la siguiente manera: Supongamos que \\(A\\), \\(B\\), \\(C\\) son tres conjuntos finitos. Entonces \\(ABC\\) es finito y \\[ \\begin{align*} n \\left( A \\oplus B \\oplus C \\right) =\\:\\: &amp; n \\left(A \\right)+n\\left(B \\right)+n \\left(C \\right)-2n \\left(A \\cap B \\right)-2n \\left(A \\cap C \\right)\\\\ &amp;-2n \\left(B \\cap C \\right)+4n \\left(A \\cap B \\cap C \\right). \\tag{2.6} \\end{align*} \\] Supongamos que \\(A\\), \\(B\\), \\(C\\) son tres conjuntos finitos. Entonces el número de elementos que están en dos de los tres conjuntos queda determinado por \\[ \\begin{align*} n \\left[ \\left(A \\cup B \\cup C \\right) \\setminus A \\oplus B \\oplus C \\right] = \\:\\: &amp; n \\left(A \\cap B \\right) + n \\left(A \\cap C \\right) + n \\left(B \\cap C \\right)\\\\ &amp;- 3n \\left(A \\cap B \\cap C \\right). \\tag{2.7} \\end{align*} \\] Supongamos que \\(A\\), \\(B\\), \\(C\\) son tres conjuntos finitos. Entonces el número de elementos que están exactamente en uno de los tres conjuntos queda determinado por \\[ \\begin{align*} n \\left[ \\left(A \\oplus B \\oplus C \\right) \\setminus \\left(A \\cap B \\cap C \\right) \\right] = \\:\\: &amp; n\\left(A \\right)+n \\left(B \\right)+n \\left(C \\right)-2n \\left(A \\cap B \\right)-2n \\left(A \\cap C \\right)\\\\ &amp;-2n \\left(B \\cap C \\right)+n \\left(A \\cap B \\cap C \\right), \\tag{2.8} \\end{align*} \\] Ejemplo 2.8 (Tamaño de un Conjunto) Los estudiantes de Licenciatura en Estadísticas deben aprobar las asignaturas Matemáticas II y Probabilidades. Se les aplicó una encuesta a 50 estudiantes que cursan la carrera carrera para ver si ellos habían cursado estas materias y se obtuvo la siguientes respuesta: 25 estudiantes aprobaron Matemáticas II, 20 estudiantes aprobaron Probabilidades y cinco estudiantes aprobaron ambas asignaturas. Encuentre el número de estudiantes que: a) aprobaron Probabilidades solamente, b) no aprobaron Probabilidades, c) aprobaron Matemáticas II o Probabilidades (o ambas), d) no aprobaron ninguna de las dos asignaturas y e) aprobaron una de las asignaturas. Sea \\(\\mathbb{U}\\) el conjunto universal formado por los 50 alumnos encuestados, \\(M\\) el conjunto de los alumnos que aprobaron Matemáticas II y \\(P\\) los alumnos que aprobaron probabilidades. Entonces los datos anteriores se pueden expresar de la siguiente manera: \\(\\mathbb{U} = 50\\), \\(M = 25\\), \\(P = 20\\) y \\(M \\cap P = 5\\). El número de estudiantes que aprobaron probabilidades solamente es: \\[ \\begin{align*} n \\left(P \\setminus M \\right) &amp; = n\\left(P \\right) - n\\left ( P \\cap M \\right )\\\\ &amp; = 20 - 5 \\\\ &amp; = 15. \\end{align*} \\] El número de estudiantes que no aprobaron Probabilidades es: \\[ \\begin{align*} n \\left( P^c \\right) &amp; = n\\left (\\mathbb{U} \\right ) - n\\left( P \\right )\\\\ &amp; =50 - 20 \\\\ &amp; = 30. \\end{align*} \\] El número de estudiantes que aprobaron Matemáticas II o Probabilidades (o ambas) es: \\[ \\begin{align*} n \\left(M \\cup P \\right) &amp; = n\\left (M \\right ) + n\\left( P \\right ) - n\\left (M \\cap P \\right )\\\\ &amp; =25 + 20 - 5 \\\\ &amp; = 40. \\end{align*} \\] El número de estudiantes que no aprobaron ninguna de las dos asignaturas es: \\[ \\begin{align*} n \\left(M^c \\cap P^c \\right) &amp; = n\\left ( \\left (M \\cup P \\right )^c \\right )= n\\left( \\mathbb{U} \\right ) - n\\left (M \\cup P \\right )\\\\ &amp; =50 - 40 \\\\ &amp; = 10. \\end{align*} \\] El número de estudiantes que aprobaron una de las asignaturas: \\[ \\begin{align*} n \\left(M \\oplus P \\right) &amp; = n\\left (M \\right ) + n\\left( P \\right ) - 2n\\left (M \\cap P \\right )\\\\ &amp; =25 + 20 - 2(5) \\\\ &amp; = 35. \\end{align*} \\] Los resultados anteriores se resumen en el siguiente diagrama de Venn, el cual se muestra en la figura 2.10 . Este diagrama se ha generado con la función ggVennDiagra del paquete ggVennDiagra. ggVennDiagram( x = list(M = 1:25, P = 21:40), color = &quot;black&quot;, lwd = 0.8, lty = 1, category.names = c(&quot;P&quot;, &quot;M&quot;), ) + scale_fill_gradient(low = &quot;#F4FAFE&quot;, high = &quot;#4981BF&quot;) Figura 2.10: Diagrama de Venn del Ejemplo 2.8 Ejemplo 2.9 (Tamaño de un Conjunto) De 140 alumnos de un centro de idiomas se sabe que: 62 estudian inglés, 52 estudian francés, 54 estudian alemán, 18 estudian inglés y francés, 20 estudian francés y alemán, 17 solo estudian alemán y 8 estudian los tres idiomas ¿Cuántos alumnos estudian otros idiomas? Sea \\(\\mathbb{U}\\) el conjunto universal formado por los 140 alumnos, \\(I\\) el conjunto de los alumnos que estudian inglés, \\(F\\) el conjunto de los alumnos que estudian francés y \\(A\\) el conjuntos de los alumnos que estudian alemán. Entonces, los datos anteriores se pueden reescribir de la siguiente manera: \\(n \\left(I \\right) = 62\\), \\(n \\left(F \\right) = 52\\), \\(n \\left(A \\right) = 54\\), \\(n \\left(I \\cap F \\right) = 18\\), \\(n \\left(F \\cap A \\right) = 20\\), \\(n \\left(A \\setminus \\left(I \\cup F \\right) \\right) = 17\\) y \\(\\left(I \\cap F \\cap A \\right) = 8\\). Los alumnos que estudian otros idiomas son \\[ n \\left( \\left(I \\cup F \\cup A \\right)^c \\right)= n \\left( \\mathbb{U} \\right) - n \\left(I \\cup F \\cup A \\right). \\] Note que para hallar \\(n \\left(I \\cup F \\cup A \\right)\\) es necesario hallar \\(n \\left(I \\cap A \\right)\\). Pero, \\[ \\begin{align*} n \\left(A \\setminus \\left(I \\cup F \\right) \\right) &amp; = n \\left(A \\right) - n \\left(A \\cap \\left(I \\cup F \\right) \\right) \\\\ &amp; = n \\left(A \\right) - n \\left( \\left(A \\cap I \\right) \\cup \\left(A \\cap F \\right) \\right) \\\\ &amp; = n \\left(A \\right)-\\left[ n \\left(A \\cap I \\right) + n \\left(A \\cap F \\right) - n \\left( \\left(A \\cap I \\right) \\cap \\left(A \\cap F \\right) \\right) \\right] \\\\ &amp; = n \\left(A \\right) - n\\left(A \\cap I \\right)- n\\left(A \\cap F \\right) + n\\left(I \\cap F \\cap A \\right) \\\\ 17&amp; = 54 - n\\left(A \\cap I \\right) -20 + 8. \\end{align*} \\] De donde se obtiene que \\(n\\left(I \\cap A \\right)=25\\). Luego, \\[ \\begin{align*} n \\left(I \\cup F \\cup A \\right) &amp; = n\\left ( I \\right ) + n\\left ( F \\right ) + n\\left ( A \\right ) - n\\left ( I \\cap F \\right ) - n\\left ( I \\cap A \\right ) - n\\left ( F \\cap A \\right ) + n\\left ( I \\cap F \\cap A \\right )\\\\ &amp; =62 + 52 + 54 -18 - 25 -30 -20 + 8 \\\\ &amp; = 113. \\end{align*} \\] Por último, \\[ \\begin{align*} n \\left( \\left(I \\cup F \\cup A \\right)^c \\right) &amp; = n \\left( \\mathbb{U} \\right) - n \\left(I \\cup F \\cup A \\right)\\\\ &amp; = 140 - 113\\\\ &amp; = 27. \\end{align*} \\] Los resultados anteriores se resumen en el siguiente diagrama de Venn, el cual se muestra en la figura 2.11 . Este diagrama se ha generado con la función draw.triple.venn del paquete VennDiagram. ej2_car &lt;- draw.triple.venn( area1 = 62, area2 = 52, area3 = 54, n12 = 18, n23 = 20, n13 = 25, n123 = 8, category = c(&quot;Inglés&quot;, &quot;Frances&quot;, &quot;Alemán&quot;), rotation = 1, reverse = FALSE, euler.d = TRUE, scaled = TRUE, lwd = rep(1, 3), lty = rep(&quot;dashed&quot;, 3), col = rep(&quot;red&quot;, 3), fill = c(&quot;pink&quot;, &quot;green&quot;, &quot;orange&quot;), alpha = rep(0.5, 3), label.col = rep(&quot;black&quot;, 7), cex = rep(1, 7), fontface = rep(&quot;plain&quot;, 7), fontfamily = rep(&quot;serif&quot;, 7), cat.pos = c(-40, 40, 180), cat.dist = c(0.05, 0.05, 0.025), cat.col = c(&quot;pink&quot;, &quot;green&quot;, &quot;orange&quot;), cat.cex = rep(1, 3), cat.fontface = rep(&quot;plain&quot;, 3), cat.fontfamily = rep(&quot;serif&quot;, 3), cat.just = list(c(0.5, 1), c(0.5, 1), c(0.5, 0)), cat.default.pos = &quot;outer&quot;, cat.prompts = FALSE, rotation.degree = 0, rotation.centre = c(0.5, 0.5), ind = TRUE, sep.dist = 0.05, offset = 0, cex.prop = NULL, print.mode = c(&quot;raw&quot;,&quot;percent&quot;), sigdigs = 3, direct.area = FALSE, area.vector = 0, output = TRUE, filename = NULL ) grid.draw(ej2_car) Figura 2.11: Diagrama de Venn del Ejemplo 2.9 2.3 Introducción a la Probabilidad En esta sección se introducen algunas definiciones que permiten entender el concepto de probabilidad, así como también, se define de manera axiomática la probabilidad de un evento. Por otro lado, se definen algunos enfoques para la asignación y cálculo de probabilidades de eventos. También, se define la probabilidad condicional y el teorema de Bayes para hacer cálculo de probabilidades de eventos dependientes e independientes. 2.3.1 Experimento Determinístico Definición 2.19 (Experimento Determinístico) Es un experimento en el cual se puede predecir el resultado. Ejemplo: Supóngase que se deja caer desde una altura \\(h\\) un objeto y se anota el tiempo que tarde el objeto en chocar con el suelo. 2.3.2 Experimento Aleatorio o Experiencia Aleatoria Definición 2.20 (Experimento Aleatorio) Es un experimento en el cual no se puede predecir el resultado o en otras palabras el resultado está regido por el azar. Ejemplo: Supóngase que se lanza un dado y se anota el número que aparece. 2.3.3 Espacio Muestral Definición 2.21 (Espacio Muestral) Es el conjunto que consta de todos los resultados posibles de un experimento aleatorio y se denotará con la letra \\(S\\). A cada uno de los resultados posibles de un experimento aleatorio se denomina punto muestral. Algunos textos representa el espacio muestral con \\(\\Omega\\) o \\(E\\). Ejemplo: En el experimento de lanzar un dado y anotar el número que aparece, el espacio muestral es \\[ S=\\left\\{1,2,3,4,5,6 \\right\\}; \\] y los puntos muestrales son \\(1,2,3,4,5,6\\). 2.3.3.1 Espacio Muestral Finito Definición 2.22 (Espacio Muestral Finito) Un espacio muestral \\(S\\) es finito si el número de puntos muestrales de \\(S\\) \\(\\left(n \\left(S \\right) \\right)\\) es un número \\(m\\) entero positivo; es decir \\[ n(S)=m, \\:donde\\: m \\in \\mathbb{ N }. \\] Ejemplo: En el experimento de lanzar un dado el espacio muestral es finito, ya que \\(n \\left(S \\right)=6\\). 2.3.3.2 Espacio Muestral Infinito Contable Definición 2.23 (Espacio Muestral Infinito Contable) Un espacio muestral \\(S\\) es infinito contable (o numerable) si se puede establecer una correspondencia uno a uno (biunívoca) entre cada uno de los puntos muestrales de \\(S\\) y los números naturales \\(\\mathbb{ N }\\). Ejemplo: Supóngase el experimento que consiste en anotar el número de veces en que se lanza una moneda hasta que salga una cara, entonces el espacio muestral definido sobre este experimento aleatorio es \\[ S=\\left\\{c,sc,ssc,sssc,ssssc,\\dotsc \\right\\}. \\] Como se puede notar \\(S\\) es infinito numerable. 2.3.3.3 Evento o Suceso Definición 2.24 (Evento) Es cualquier subconjunto del espacio muestral \\(S\\), cuyos elementos tienen características comunes. Sea \\(A\\) un evento, se dice que el evento \\(A\\) ocurrió si el resultado del experimento es un elemento de \\(A\\). Ejemplo: En el experimento aleatorio de lanzar un dado y anotar el número que sale, los siguientes conjuntos son eventos: \\[ A=\\left\\{1 \\right\\}; B=\\left\\{6 \\right\\}; C=\\left\\{1,3,5 \\right\\}; D=\\left\\{2,4,6 \\right\\}. \\] Como se puede notar \\(S\\) es infinito numerable. 2.3.3.4 Evento Simple o Evento Elemental Definición 2.25 (Evento Simple) Es el evento constituido por un solo punto muestral. Ejemplo: En el experimento aleatorio de lanzar un dado y anotar el número que sale, los siguientes eventos constituyen eventos elementales: \\[ A=\\left\\{1 \\right\\}; B=\\left\\{2 \\right\\}; C=\\left\\{3 \\right\\}; D=\\left\\{4 \\right\\};E=\\left\\{5 \\right\\}; F=\\left\\{6 \\right\\}. \\] 2.3.3.5 Evento Compuesto Definición 2.26 (Evento Compuesto) Es el evento constituido por más de un punto muestral. Ejemplo: En el experimento aleatorio de lanzar un dado y anotar el número que sale, los siguientes eventos constituyen eventos compuestos: \\[ A=\\left\\{1,2 \\right\\}; B=\\left\\{1,3,5\\right\\};C=\\left\\{1,3,5,6 \\right\\}; D=\\left\\{1,2,3,4,5,6 \\right\\}. \\] 2.3.3.6 Evento Imposible Definición 2.27 (Evento Imposible) Es el evento que nunca ocurre, es decir, el evento que contiene a ningún resultado posible del espacio muestral. En otras palabras, el conjunto vació \\((\\emptyset)\\). 2.3.3.7 Evento Seguro o Cierto Definición 2.28 (Evento Seguro) Es el evento que siempre ocurre, es decir, el evento que contiene a todos los resultados posibles del espacio muestral. En otras palabras, el espacio muestral \\(\\left(S \\right)\\). 2.3.3.8 Eventos Mutuamente Excluyentes o Incompatibles Definición 2.29 (Eventos Mutuamente Excluyentes) Dos eventos \\(A\\), \\(B\\) son mutuamente excluyentes si la ocurrencia de uno implica la no ocurrencia del otro. En otras palabras, se puede decir que dos sucesos son mutuamente excluyentes si ninguno de los puntos muestrales que conforman uno están contenido en el otro; por lo que \\[ A \\cap B=\\emptyset. \\] 2.3.3.9 Eventos Compatibles o Solapados Definición 2.30 (Eventos Compatibles) Dos eventos \\(A\\), \\(B\\) se dice que son compatibles, o que no son mutuamente excluyentes o que son solapados, cuando la ocurrencia de uno no impide la ocurrencia del otro. En otros términos, los eventos comparte por lo menos un punto muestral; por lo que \\[ A \\cap B \\neq \\emptyset. \\] Nota:. Como se ha podido observar los eventos son conjunto por lo tanto toda la teoría de conjunto es aplicable a los eventos. 2.3.4 Probabilidad Definición 2.31 (Probabilidad) Es una medida de la incertidumbre sobre la ocurrencia de un evento en particular en un experimento aleatorio. 2.3.4.1 Enfoque Clásico (o de Laplace o a Priori) de la Probabilidad Definición 2.32 (Enfoque Clásico de la Probabilidad) Si un experimento aleatorio puede ocurrir de \\(N\\) maneras diferentes \\(\\left(n \\left(S \\right) = N \\right)\\) igualmente probables y mutuamente excluyentes, y un evento \\(A\\) puede ocurrir de \\(n\\) maneras diferentes \\(\\left(n \\left(A \\right) = n \\right)\\). Entonces la probabilidad de que ocurra el evento \\(A\\) viene dada por \\[ \\begin{equation} P\\left(A \\right)=\\frac{n\\left(A \\right)}{n \\left(S \\right)} =\\frac{n}{N}. \\tag{2.9} \\end{equation} \\] Ejemplo: Supongamos que queremos conocer la probabilidad de que ocurra cara en el lanzamiento sencillo de una moneda. Dado que hay dos maneras igualmente probables como puede caer la moneda, a saber: cara o sello (suponiendo que no se pierda o caiga de canto), y de esas dos maneras puede aparecer cara de una sola forma. Sea \\(A\\) el evento la meoneda cae cara, entonces la probabilidad de que ocurra cara es \\[ P \\left(A \\right)=\\frac{1}{2}=0,5. \\] Para llegar a este resultado suponemos que la moneda es balanceada. 2.3.4.2 Enfoque Frecuentista (Empírico o a Posteriori) de la Probabilidad Definición 2.33 (Enfoque Frecuentista de la Probabilidad) Si un experimento se repite \\(N\\) veces bajo las mismas condiciones y en \\(n\\) de los resultados ocurre un evento \\(A\\). Entonces, la probabilidad de que ocurra el evento \\(A\\) tiende a \\(n/N\\), conforme \\(N\\) tiende a infinito. Es decir, \\[ \\begin{equation} P\\left(A \\right) = \\lim_{N \\to \\infty} \\frac{n}{N}. \\tag{2.10} \\end{equation} \\] Ejemplo: Se realiza un experimento bajo ciertas condiciones, el cual consiste en agregar un antibiótico a una cepa de bacterias. Una hora después de realizar el experimento encontramos que de 7.627 bacterias 4.036 murieron en 1 hora o antes. ¿Cuál es la probabilidad que tiene una bacteria de morir en una hora o antes? Sea \\(A\\): la bacteria muere en una hora o antes, entonces la probabilidad de que ocurra \\(A\\), según la ecuación (2.10), es: \\[P\\left(A \\right) =\\frac{4.036}{7.627}=0,5292.\\] 2.3.4.3 Enfoque Subjetivo (o personal) de la Probabilidad Definición 2.34 (Enfoque Subjetivo de la Probabilidad) Es el grado de creencia o de convicción que se tiene con respecto a la ocurrencia de un evento. Ejemplo: A una persona se le pregunta sobre la probabilidad de que llueva, la persona mira hacia el cielo y al percatarse que el cielo está nublado dice la probabilidad de que llueva es de un 80%. 2.3.4.4 Axiomas de la Probabilidad Sea \\(S\\) cualquier espacio muestral y \\(A\\) cualquier evento de éste. Se llamará función de probabilidad sobre el espacio muestral \\(S\\) a \\(P\\left(A \\right)\\) si satisface los siguientes axiomas: \\(P\\left(A \\right) \\geq 0\\) (toda probabilidad es no negativa). \\(P\\left(S \\right)=1\\) (la probabilidad del espacio muestral es uno). Si \\(A_1, A_2, A_3, \\dotsc\\) es una sucesión de eventos mutuamente excluyente; es decir \\(A_i \\cap A_j = \\emptyset\\) para todo \\(i \\ne j\\). Entonces \\[ P(A_1 \\cup A_2 \\cup A_3 \\cup \\cdots)=P(A_1 )+P(A_2 )+P(A_3 )+ \\cdots \\] De estos tres axiomas se desprenden los siguientes teoremas: Teorema 2.3 La probabilidad de que ocurra el evento imposible es cero. Es decir, \\[ \\begin{equation} P(\\emptyset)=0. \\tag{2.11} \\end{equation} \\] Demostración. \\(S \\cup \\emptyset=S\\) y \\(S \\cap \\emptyset=\\emptyset\\). Por el axioma 3, \\(P \\left(S \\cup \\emptyset \\right)=P \\left(S \\right)+P \\left( \\emptyset \\right)\\); pero por el axioma 2, \\(P \\left(S \\right)=1\\), y de esta manera \\(P(\\emptyset)=0\\). Teorema 2.4 Para cualquier evento \\(A \\subseteq S\\), se cumple que \\[ \\begin{equation} 0 \\le P \\left(A \\right) \\le 1. \\tag{2.12} \\end{equation} \\] Demostración. Por el axioma 1 \\(P(A) \\ge 0\\); de aquí que solo es necesario probar que \\(P(A) \\le 1\\). \\(A \\cup A^c = S\\) y \\(A \\cap A^c = \\emptyset\\). Por los axiomas 2 y 3, \\(P \\left(A \\cup A^c \\right)=P \\left(A \\right)+P \\left(A^c \\right)=P \\left(S \\right)=1\\); Dado que \\(P \\left(A^c \\right) \\ge 0\\), entonces \\[ P \\left(A \\right) \\le 1. \\] Teorema 2.5 (Regla del Complemento) Para cualquier evento \\(A\\), se tiene \\[ \\begin{equation} P\\left(A^c \\right)=1-P \\left(A \\right). \\tag{2.13} \\end{equation} \\] Demostración. Como \\(A \\cup A^c = S\\) y \\(A \\cap A^c= \\emptyset\\). Por los axiomas 2 y 3, \\(P \\left(A \\cup A^c \\right)=P \\left(A \\right)+P \\left(A^c \\right)=P \\left(S \\right)=1\\); De aquí que \\[ P \\left(A^c \\right)=1-P \\left(A \\right). \\] Teorema 2.6 (Regla de la Diferencia) Para dos eventos cualesquiera \\(A\\) y \\(B\\) del espacio muestral \\(S\\), se cumple que \\[ \\begin{equation} P\\left(A \\setminus B \\right)=P \\left(A \\right)-P\\left(A \\cap B^{c} \\right). \\tag{2.14} \\end{equation} \\] Demostración. Como se muestra en la figura 2.12, \\(A=\\left(A\\setminus B \\right) \\cup \\left(A \\cap B \\right)\\) donde \\(A \\setminus B\\) y \\(A \\cap B\\) son mutuamente excluyentes. En consecuencia, por el tercer axioma de la probabilidad definido en la sección 2.3.4.4, \\[ P \\left(A\\right)=P \\left(A \\setminus B \\right)+P\\left(A \\cap B \\right). \\] De donde se obtiene, \\[ P \\left(A \\setminus B \\right)=P \\left(A\\right)-P\\left(A \\cap B \\right). \\] knitr::include_graphics( path = &quot;figuras/regla_diferencia.png&quot; ) Figura 2.12: Diegrama de Venn para la regla de la diferencia Teorema 2.7 (Regla de la Adición) Para dos eventos cualesquiera \\(A\\) y \\(B\\) del espacio muestral \\(S\\), se cumple que \\[ \\begin{equation} P\\left(A \\cup B \\right)=P \\left(A \\right)+P \\left(B \\right)-P\\left(A \\cap B \\right). \\tag{2.15} \\end{equation} \\] Demostración. Como se muestra en la figura 2.13, \\(A\\cup B = \\left(A \\setminus B \\right) \\cup B\\) donde \\(A \\setminus B\\) y \\(B\\) son conjuntos mutuamente excluyentes. En consecuencia, por el tercer axioma de la probabilidad definido en la sección 2.3.4.4, \\[ P \\left(A \\cup B\\right)=P \\left(A \\setminus B \\right)+P\\left( B \\right). \\] De donde se obtiene, por la regla de la diferencia 2.6 \\[ \\begin{align*} P \\left(A \\cup B\\right)&amp;=P \\left(A \\right)- P\\left(A \\cap B \\right)+P\\left( B \\right)\\\\ &amp;=P \\left(A \\right)+P\\left( B \\right)- P\\left(A \\cap B \\right). \\end{align*} \\] knitr::include_graphics( path = &quot;figuras/regla_adicion.png&quot; ) Figura 2.13: Diegrama de Venn para la regla de la adición Teorema 2.8 (Regla de la Adición para Tres Eventos) Si \\(A\\), \\(B\\) y \\(C\\) son tres eventos cualesquiera del espacio muestral \\(S\\), entonces \\[ \\begin{align*} P\\left(A \\cup B \\cup C \\right)=&amp;P \\left(A \\right)+P \\left(B \\right)+P \\left(C \\right)-P\\left(A \\cap B \\right)\\\\ &amp;-P\\left(A \\cap C \\right) -P\\left(B \\cap C \\right)+P\\left(A \\cup B \\cup C \\right). \\tag{2.16} \\end{align*} \\] Demostración. Al escribir \\(A \\cup B \\cup C\\) como \\(A \\cup \\left(B \\cup C \\right)\\), por la propiedad asociativa de la unión 2.2.2.1, y utilizando la regla de la adición 2.7 dos veces, una vez para \\(P \\left[A \\cup \\left(B \\cup C \\right) \\right]\\) y una para \\(P \\left( B \\cup C\\right)\\) se obtiene \\[ \\begin{align*} P \\left(A \\cup B \\cup C \\right)&amp;=P \\left[A \\cup \\left(B \\cup C \\right) \\right]\\\\ &amp;=P \\left(A \\right)+P \\left(B \\cup C \\right)-P \\left[A \\cap \\left(B \\cup C \\right) \\right]\\\\ &amp;=P \\left(A \\right)+P \\left(B \\right)+P \\left(C \\right)-P \\left(B \\cap C \\right)-P \\left[A \\cap \\left(B \\cup C \\right) \\right]\\\\. \\end{align*} \\] De la propiedad distributiva de la intersección descrita en 2.2.2.1, se sigue que \\[ \\begin{align*} P \\left[A \\cap \\left(B \\cup C \\right) \\right]&amp;=P \\left[ \\left(A \\cap B \\right) \\cup \\left(A \\cap C \\right) \\right]\\\\ &amp;=P\\left(A \\cap B \\right) + P\\left(A \\cap C \\right)-P \\left[ \\left(A \\cap B \\right) \\cap \\left(B \\cap C \\right) \\right]\\\\ &amp;=P\\left(A \\cap B \\right) + P\\left(A \\cap C \\right)-P\\left(A \\cap B \\cap C \\right) \\end{align*} \\] y por tanto, que \\[ \\begin{align*} P \\left(A \\cup B \\cup C \\right)=&amp;P \\left(A \\right)+P \\left(B \\right)+P \\left(C \\right)-P \\left(B \\cap C \\right)\\\\ &amp;-\\left[P\\left(A \\cap B \\right) + P\\left(A \\cap C \\right)-P\\left(A \\cap B \\cap C \\right) \\right]\\\\ =&amp;P \\left(A \\right)+P \\left(B \\right)+P \\left(C \\right)-P \\left(A \\cap B \\right)-P \\left(A \\cap C \\right)\\\\ &amp;-P \\left(C \\cap B \\right)+P\\left(A \\cap B \\cap C \\right) \\end{align*} \\] Teorema 2.8 (Regla de la Adición para \\(k\\) Eventos) Sean \\(A_1, A_2, \\dotsc, A_k\\) \\(k\\) sucesos cualesquiera del espacio muestral \\(S\\). Entonces \\[ \\begin{align*} P\\left ( \\bigcup_{i=1}^{k} A_{i} \\right )=&amp;\\sum_{i=1}^{k}P\\left ( A_{i} \\right )-\\sum_{i&lt; j=2}^{k}P\\left ( A_{i} \\cap A_{j} \\right )+\\sum_{i&lt; j&lt; r=3}^{k}P\\left ( A_{i} \\cap A_{j} \\cap A_{r} \\right )\\\\ &amp;+\\cdots +\\left ( -1 \\right )^{k-1}P\\left ( \\bigcap_{i=1}^{k} A_{i} \\right). \\tag{2.17} \\end{align*} \\] 2.3.4.5 Probabilidad Condicional Definición 2.35 (Probabilidad Condicional) Suponga que \\(B\\) es un evento en un espacio muestral \\(S\\), tal que \\(P \\left(B \\right) &gt; 0\\), es decir \\(B \\neq \\emptyset\\). La probabilidad de que ocurra un evento \\(A\\) una vez que \\(B\\) ha ocurrido o, en otras palabras, la la probabilidad condicional de \\(A\\) dado \\(B\\), escrita \\(P \\left( A \\mid B \\right)\\), se define así: \\[ \\begin{equation} P \\left( A \\mid B \\right)=\\frac{P \\left( A \\cap B \\right)}{P \\left( B \\right)}. \\tag{2.18} \\end{equation} \\] Como se ilustra en el diagrama de Venn en la figura 2.14, \\(P \\left( A \\mid B \\right)\\) mide, en cierto sentido, la probabilidad relativa de \\(A\\) con respecto al espacio reducido \\(B\\). knitr::include_graphics(path = &quot;figuras/probabilidad_condicional.png&quot;) Figura 2.14: Probabilidad Condicional Ahora, suponga que \\(S\\) es un espacio equiprobable y sea \\(n\\left(A\\right)\\) el número de elementos en el evento \\(A\\). Entonces, \\[ P \\left( A \\cap B \\right)=\\frac{n\\left(A \\cap B \\right)}{n\\left(S \\right)} \\; y \\; P \\left( B \\right)=\\frac{n\\left( B \\right)}{n\\left(S \\right)}. \\] Luego, sustituyendo en la ecuación (2.18) se obtiene que: \\[ \\begin{equation} P \\left( A \\cap B \\right)=\\frac{n\\left(A \\cap B \\right)}{n\\left(B \\right)}. \\tag{2.19} \\end{equation} \\] Ejemplo 2.10 (Probabilidad Condicional) Se lanza un par de dados equilibrados. Encuentre la probabilidad de que uno de los dados sea 2 si la suma es 6. Dado que cada dado puede caer de 6 formas diferentes, entonces el número de formas diferentes en que pueden caer los dos dados, es decir, el número de elementos del espacio muestral \\(S\\), por el principio de la multiplicación 1.2, es \\(6 \\cdot 6=36\\). En tal sentido, el espacio muestral \\(S\\) viene determinado por: \\[ S=\\begin{Bmatrix} (1,1);&amp;(1,2);&amp;(1,3);&amp;(1,4);&amp;(1,5);&amp;(1,6);\\\\ (2,1);&amp;(2,2);&amp;(2,3);&amp;(2,4);&amp;(2,5);&amp;(2,6);\\\\ (3,1);&amp;(3,2);&amp;(3,3);&amp;(3,4);&amp;(3,5);&amp;(3,6);\\\\ (4,1);&amp;(4,2);&amp;(4,3);&amp;(4,4);&amp;(4,5);&amp;(4,6);\\\\ (5,1);&amp;(5,2);&amp;(5,3);&amp;(5,4);&amp;(5,5);&amp;(5,6);\\\\ (6,1);&amp;(6,2);&amp;(6,3);&amp;(6,4);&amp;(6,5);&amp;(6,6)\\\\ \\end{Bmatrix}. \\] Sea \\(A\\) el evento en el cual uno de los dados es 2, el cual viene dado por: \\[ A=\\begin{Bmatrix} (2,1);&amp;(2,2);&amp;(2,3);&amp;(2,4);&amp;(2,5);&amp;(2,6);\\\\ (1,2);&amp;(3,2);&amp;(4,2);&amp;(5,2);&amp;(6,2)\\\\ \\end{Bmatrix}. \\] Y \\(B\\) el evento en el cual la suma es 6, representado por: \\[ B = \\begin{Bmatrix} (1,5);&amp;(2,4);&amp;(3,3);&amp;(4,2);&amp;(5,1)\\\\ \\end{Bmatrix}. \\] Entonces el evento en el cual uno de los dos dados es 2 y cuya suma es 6, es decir, \\(A \\cap B\\), viene dado por: \\[ A \\cap B=\\begin{Bmatrix} (2,4);&amp;(4,2)\\\\ \\end{Bmatrix}. \\] De lo anterior se obtiene que, \\[ P \\left( A \\cap B \\right)=\\frac{n\\left(A \\cap B \\right)}{n\\left(S \\right)}=\\frac{2}{36} \\; y \\; P \\left( B \\right)=\\frac{n\\left( B \\right)}{n\\left(S \\right)}=\\frac{5}{36}. \\] Luego, sustituyendo el resultado anterior en la ecuación (2.18) se obtiene que la probabilidad de que uno de los dados sea 2 si la suma es 6 es: \\[ P \\left( A \\mid B \\right)=\\frac{P \\left( A \\cap B \\right)}{P \\left( B \\right)}=\\frac{\\frac{2}{36}}{\\frac{5}{36}}=\\frac{2}{5}=0,4. \\] El espacio muestral \\(S\\) para este ejemplo se puede listar con el siguiente script de R. Note que en la tabla 2.1 las filas en color azul representa el evento \\(B\\). dados &lt;- urnsamples( 1:6, size = 2, replace = T, ordered = T ) %&gt;% as_tibble() %&gt;% mutate( suma = X1 + X2 ) kableExtra::kbl( dados, col.names = c(&quot;Dado 1&quot;, &quot;Dado 2&quot;, &quot;Suma&quot;), format.args = list(decimal.mark = &quot;,&quot;, big.mark = &quot;.&quot;), booktabs = TRUE, caption = &quot;\\\\label{tab2:dados}Lanzamiento de dos dados&quot;, escape = FALSE ) %&gt;% kable_styling( bootstrap_options = &quot;striped&quot;, full_width = FALSE, fixed_thead = T ) %&gt;% row_spec( which(dados$suma == &quot;6&quot;), color = &quot;blue&quot;, strikeout = F ) %&gt;% kable_classic_2() %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;400px&quot;) Tabla 2.1: Lanzamiento de dos dados Dado 1 Dado 2 Suma 1 1 2 2 1 3 3 1 4 4 1 5 5 1 6 6 1 7 1 2 3 2 2 4 3 2 5 4 2 6 5 2 7 6 2 8 1 3 4 2 3 5 3 3 6 4 3 7 5 3 8 6 3 9 1 4 5 2 4 6 3 4 7 4 4 8 5 4 9 6 4 10 1 5 6 2 5 7 3 5 8 4 5 9 5 5 10 6 5 11 1 6 7 2 6 8 3 6 9 4 6 10 5 6 11 6 6 12 2.3.4.6 Teorema de la Multiplicación Teorema 2.9 (Teorema de la Multiplicación para Dos Eventos) Si \\(A\\) y \\(B\\) son dos eventos cualesquiera de un espacio muestral \\(S\\) y \\(P\\left(A \\right) \\neq 0\\), entonces \\[ \\begin{equation} P\\left(A \\cap B \\right)=P \\left(A \\right) \\cdot P \\left( B \\mid A \\right). \\tag{2.20} \\end{equation} \\] En forma alternativa, si \\(P\\left(B \\right) \\neq 0\\), entonces \\[ \\begin{equation} P\\left(A \\cap B \\right)=P \\left(B \\right) \\cdot P \\left( A \\mid B \\right). \\tag{2.21} \\end{equation} \\] Teorema 2.10 (Teorema de la Multiplicación para Tres Eventos) Si \\(A\\), \\(B\\) y \\(C\\) son tres eventos cualesquiera de un espacio muestral \\(S\\), tal que \\(P\\left(A \\right) \\neq 0\\) y \\(P\\left(A \\cap B \\right) \\neq 0\\), entonces \\[ \\begin{equation} P\\left(A \\cap B \\cap C \\right)=P \\left(A \\right) \\cdot P \\left( B \\mid A \\right) \\cdot P \\left( C \\mid A \\cap B \\right). \\tag{2.22} \\end{equation} \\] Demostración. Al escribir \\(A \\cap B \\cap C\\) como \\(\\left(A \\cap B \\right) \\cap C\\) y utilizando la fórmula del teorema 2.9 dos veces, se obtiene \\[ \\begin{align*} P \\left(A \\cap B \\cap C \\right) &amp; = P \\left[ \\left(A \\cap B \\right) \\cap C \\right] \\\\ &amp; = P \\left(A \\cap B \\right) \\cdot P \\left(C \\mid A \\cap B \\right) \\\\ &amp; = P \\left(A \\right) \\cdot P \\left( B \\mid A \\right) \\cdot P \\left( C \\mid A \\cap B \\right). \\end{align*} \\] Teorema 2.11 (Teorema de la Multiplicación para \\(k\\) Eventos) Si \\(A{}_1, A{}_2, \\dotsc, A{}_k\\) son \\(k\\) eventos cualesquiera de un espacio muestral \\(S\\), tal que \\(P\\left(A{}_1 \\cap A{}_2 \\cap \\cdots \\cap A{}_{k-1} \\right) \\neq 0\\) , entonces \\[ \\begin{align*} P\\left(A_1 \\cap A_2 \\cap \\cdots \\cap A_k \\right) = &amp; P \\left(A_1 \\right) \\cdot P \\left( A_2 \\mid A_1 \\right) \\cdot P \\left( A_3 \\mid A_1 \\cap A_2 \\right)\\\\ &amp; \\cdots P \\left( A_k \\mid A_1 \\cap A_2 \\cap \\cdots \\cap A_{k-1} \\right). \\tag{2.23} \\end{align*} \\] Ejemplo 2.11 (Teorema de la Multiplicación para Dos Eventos) Determine la probabilidad de tomar de manera aleatoria o al azar en sucesión dos ases de un un mazo de cartas españolas a) si las cartas se toman sin reemplazo y b) si las cartas se toman con reemplazo. Si \\(A\\) es el evento de que la primera carta es un as y \\(B\\) el evento de que la segunda carta es otro as. Entonces, la probabilidad de que las dos cartas sean ases, si el muestreo se realiza sin reemplazo, viene dado por \\[ P\\left(A \\cap B \\right)=P \\left(A \\right) \\cdot P \\left( B \\mid A \\right)=\\frac{4}{40} \\cdot \\frac{3}{39}=\\frac{1}{130}\\approx 0,0077. \\] Si el muestreo se realiza con reemplazo la probabilidad de seleccionar dos ases es, \\[ P\\left(A \\cap B \\right)=P \\left(A \\right) \\cdot P \\left( B \\mid A \\right)=\\frac{4}{40} \\cdot \\frac{4}{40}=\\frac{1}{100}=0,01. \\] Ejemplo 2.12 (Teorema de la Multiplicación para Tres Eventos) Una caja de bombillos contiene 100 unidades, de los cuales 5 están defectuosos. Si se seleccionan al azar tres bombillos y se sacan de la caja en sucesión sin reemplazo, ¿cuál es la probabilidad de que los tres bombillos sean defectuosos. Sea \\(A\\) el evento de que el primer bombillo es defectuosos, \\(B\\) el evento de que el segundo bobillo es defectuosos y \\(C\\) el evento de que el tercer bombillo es defectuosos. Entonces, la probabilidad de que los tres bombillos sean defectuosos, según ecuación (2.22) dada en el teorema 2.10 es \\[ \\begin{align*} P\\left(A \\cap B \\cap C \\right) &amp; = P \\left(A \\right) \\cdot P \\left( B \\mid A \\right) \\cdot P \\left( C \\mid A \\cap B \\right) \\\\ &amp;=\\frac{5}{100} \\cdot \\frac{4}{99}\\cdot \\frac{3}{98}\\\\ &amp;=\\frac{1}{16.170} \\approx 0,00006. \\end{align*} \\] 2.3.4.7 Eventos Independientes En términos informales, se dice que dos eventos \\(A\\) y \\(B\\) son independientes si la ocurrencia de uno no afecta la ocurrencia del otro. Por ejemplo, si se lanzan dos monedas es de esperarse que la ocurrencia de un resultado en una moneda no afecte el resultado en la otra moneda. Del mismo modo, si se considera el inciso b) del ejemplo 2.11 se puede ver que la ocurrencia de un as en la primera carta no afecta la ocurrencia de un as en la segunda carta, en tal sentido los eventos \\(A\\) y \\(B\\) son independientes. En contraste con lo anterior, el inciso a) muestra que los eventos \\(A\\) y \\(B\\) son dependientes dado que la ocurrencia de un as en la primera carta \\(\\left(P\\left(A \\right)=4/40 \\right)\\) afecta la ocurrencia de un as en la segunda carta \\(\\left(P\\left(B \\right)=3/40 \\right)\\). Simbólicamente, dos eventos \\(A\\) y \\(B\\) son independientes si \\(P \\left( A \\mid B \\right)=P \\left( A \\right)\\) y \\(P \\left( B \\mid A \\right) = P \\left(B \\right)\\) y puede demostrarse que una u otra de estas igualdades implican a la otra cuando existen las dos probabilidades condicionales, es decir, cuando ni \\(P \\left( A \\right)\\) ni \\(P \\left( B \\right)\\) es igual a cero. Ahora bien, si se sustituye \\(P \\left(B \\right)\\) por \\(P \\left( B \\mid A \\right)\\) en la formula del teorema 2.9 se obtiene \\[ \\begin{align*} P\\left(A \\cap B\\right) &amp; =P\\left(A \\right) \\cdot P \\left( B \\mid A \\right)\\\\ &amp; = P\\left(A \\right) \\cdot P\\left(B \\right). \\end{align*} \\] De manera análoga, \\[ \\begin{align*} P\\left(A \\cap B\\right) = P\\left(B \\cap A \\right)&amp; =P\\left(B \\right) \\cdot P \\left(A \\mid B \\right)\\\\ &amp; = P\\left(B \\right) \\cdot P \\left(A \\right)\\\\ &amp; = P\\left(A \\right) \\cdot P \\left(B \\right). \\end{align*} \\] De donde se concluye que los eventos \\(A\\) y \\(B\\) son independientes si \\[ P\\left(A \\cap B \\right)=P \\left(A \\right) \\cdot P \\left( B \\right). \\] Definición 2.36 (Independencia de Dos Eventos) Dos eventos \\(A\\) y \\(B\\) cualesquiera de un espacio muestral \\(S\\) son independientes si y sólo si \\[ \\begin{equation} P\\left(A \\cap B \\right)=P \\left(A \\right) \\cdot P \\left( B \\right). \\tag{2.24} \\end{equation} \\] De lo contrario, es decir, si \\[ P\\left(A \\cap B \\right) \\neq P \\left(A \\right) \\cdot P \\left( B \\right), \\] se dice que los eventos \\(A\\) y \\(B\\) son dependientes. Definición 2.37 (Independencia de Tres Eventos) Tres eventos \\(A\\), \\(B\\) y \\(C\\) cualesquiera de un espacio muestral \\(S\\) son independientes si se cumplen las dos condiciones siguientes: Son independientes por pares, es decir \\[ \\begin{align*} &amp; P\\left(A \\cap B \\right)=P \\left(A \\right) \\cdot P \\left(B \\right)\\\\ &amp; P\\left(A \\cap C \\right)=P \\left(A \\right) \\cdot P \\left(C \\right)\\\\ &amp; P\\left(B \\cap C \\right)=P \\left(B \\right) \\cdot P \\left(C \\right). \\tag{2.25} \\end{align*} \\] La probabilidad de la intersección de los tres eventos es igual a el producto de sus probabilidades, es decir \\[ \\begin{equation} P\\left(A \\cap B \\cap C \\right) =P \\left(A \\right) \\cdot P \\left(B \\right) \\cdot P \\left(C \\right) \\tag{2.26} \\end{equation} \\] Definición 2.37 (Independencia de \\(k\\) Eventos) Los eventos \\(A{}_1, A{}_2, \\dots, \\;\\textrm{y}\\; A{}_k\\) son independientes si y sólo si la probabilidad de la intersección de \\(2, 3, \\dots, \\;\\textrm{o}\\; k\\) de estos eventos es igual al producto de sus respectivas probabilidades. Teorema 2.12 Si los eventos \\(A\\) y \\(B\\) son independientes, entonces también lo son: \\(a)\\; A \\;\\textrm{y}\\; B^c\\), \\(b)\\; A^c \\;\\textrm{y}\\; B^c\\). Es decir, \\[ \\begin{align*} a)\\: &amp; P\\left ( A \\cap B^{c} \\right )= P\\left ( A \\right )\\cdot P\\left ( B^{c} \\right )\\\\ b)\\: &amp; P\\left ( A^{c} \\cap B^{c} \\right )= P\\left ( A^{c} \\right )\\cdot P\\left ( B^{c} \\right ). \\tag{2.27} \\end{align*} \\] Demostración. Como \\(A=\\left(A \\cap B \\right) \\cup \\left(A \\cap B^c \\right)\\) y \\(A \\cap B\\) y \\(A \\cap B^c\\) son mutuamente excluyentes, se tiene que \\[ \\begin{align*} P\\left(A \\right) &amp; = P\\left[ \\left(A \\cap B \\right) \\cup \\left(A \\cap B^c \\right) \\right]\\\\ &amp; = P \\left(A \\cap B \\right) + P \\left(A \\cap B^c \\right). \\end{align*} \\] Por otro lado, como \\(A\\) y \\(B\\) son independientes, \\[ P\\left(A \\right)=P\\left(A \\right) \\cdot P\\left(B \\right) + P \\left(A \\cap B^c \\right). \\] Despejando \\(P \\left(A \\cap B^c \\right)\\) de la ecuación anterior, se obtiene que \\[ \\begin{align*} P \\left(A \\cap B^c \\right) &amp; = P\\left(A \\right) - P\\left(A \\right) \\cdot P\\left(B \\right)\\\\ &amp; = P\\left(A \\right) \\cdot \\left[1- P\\left(A \\right) \\right]\\\\ &amp; = P\\left(A \\right) \\cdot P\\left(B^c \\right) \\end{align*} \\] y, por tanto, \\(A\\) y \\(B^c\\) son independientes. Por las leyes de Morgan 2.2.3.1 \\(A^c \\cap B^c=\\left(A \\cup B\\right)^c\\). Por tanto, \\[ P\\left ( A^{c} \\cap B^{c} \\right )=P \\left[ \\left(A \\cup B\\right)^c \\right]. \\] Luego, por la regla del complemento 2.5 \\[ P\\left ( A^{c} \\cap B^{c} \\right )=1-P\\left ( A \\cup B \\right ). \\] Por la regla de la unión de dos conjunto 2.7 \\[ \\begin{align*} P\\left ( A^{c} \\cap B^{c} \\right )&amp;=1-\\left[P\\left ( A \\right )+P\\left ( B \\right )-P\\left ( A \\cap B \\right ) \\right]\\\\ &amp;=1-P\\left ( A \\right )-P\\left ( B \\right )+P\\left ( A \\cap B \\right ). \\end{align*} \\] Como \\(A \\;y\\;B\\) son independientes, entonces \\[ P\\left ( A^{c} \\cap B^{c} \\right )=1-P\\left ( A \\right )-P\\left ( B \\right )+P\\left ( A \\right ) \\cdot P\\left ( B \\right ). \\] Operando algebraicamente en el miembro derecho de la ecuación anterior se obtiene que \\[ P\\left ( A^{c} \\cap B^{c} \\right )=\\left [ 1-P\\left ( A \\right ) \\right ]\\cdot \\left [ 1-P\\left ( B \\right ) \\right ]. \\] Por último, por la regla del complemento 2.5, se obtiene que \\[ P\\left ( A^{c} \\cap B^{c} \\right )= P\\left ( A^{c} \\right )\\cdot P\\left ( B^{c} \\right ). \\] De donde se concluye que los eventos \\(A^{c} \\;\\textrm{y}\\; B^{c}\\) son independientes si \\(A \\;\\textrm{y}\\; B\\) lo son. Ejemplo 2.13 (Eventos Independietes) Se lanzan tres monedas equilibradas las cueles pueden resultar en cara (\\(c\\)) o sello (\\(s\\)). Sean los eventos \\(A: \\{ \\textrm{en las tres monedas sale el mismo signo} \\}\\); \\(B: \\{ \\textrm{por lo menos una de las tres monedas muestra cara} \\}\\) y \\(C: \\{ \\textrm{por lo menos salen dos caras} \\}\\). Determine si estos eventos son independientes por pares. De acuerdo a este experimento aleatorio, el espacio muestral \\(S\\) está determinado por, \\[ S=\\left\\{ccc, scc, csc, ssc,ccs, scs, css, sss\\right\\}. \\] Mientras que los eventos \\(A\\), \\(B\\), \\(C\\), \\(A \\cap B\\), \\(A \\cap C\\) y \\(B \\cap C\\) viene dados por \\(A=\\left\\{ccc,sss\\right\\}\\), \\(B=\\left\\{ccc, scc, csc, ssc,ccs, scs, css\\right\\}\\), \\(C=\\left\\{ccc, scc, csc, ccs\\right\\}\\), \\(A \\cap B=\\left\\{ccc\\right\\}\\), \\(A \\cap C =\\left\\{ccc\\right\\}\\) y \\(B \\cap C =C=\\left\\{ccc, scc, csc, ccs\\right\\}\\), respectivamente. De lo anterior se obtiene que: \\[ P \\left(A \\cap B \\right)=\\frac{1}{8} \\neq P \\left(A \\right)\\cdot P\\left(B \\right)=\\frac{2}{8}\\cdot\\frac{7}{8}=\\frac{7}{32}. \\] De donde se deduce que los eventos \\(A\\) y \\(B\\) no son independientes, es decir, son dependientes. Por otro lado, \\[ P \\left(A \\cap C \\right)=\\frac{1}{8} = P \\left(A \\right)\\cdot P\\left(C \\right)=\\frac{2}{8}\\cdot\\frac{4}{8}=\\frac{1}{8}. \\] En consecuencia, los eventos \\(A\\) y \\(C\\) son independientes. De manera análoga a como se procedió en los casos anteriores, \\[ P \\left(B \\cap C \\right)=\\frac{4}{8}=\\frac{1}{2} \\neq P \\left(B \\right)\\cdot P\\left(C \\right)=\\frac{7}{8}\\cdot\\frac{4}{8}=\\frac{7}{16}. \\] Lo que implica que los eventos \\(B\\) y \\(C\\) no son independientes (son dependientes). Note de la definición 2.37 que estos tres eventos no son independientes, dado que los eventos \\(A\\) y \\(B\\) y \\(A\\) y \\(C\\) no son independientes, aunque solo basta que uno de los tres pares de eventos no sean independientes para concluir que los tres eventos no son independientes. 2.3.4.8 Ley de la Probabilidad Total Suponga que un espacio muestral \\(S\\) es la unión de los \\(k\\) eventos mutuamente excluyentes \\(A{}_1, A{}_2, \\dotsc, A{}_k\\); es decir, \\(A{}_1, A{}_2, \\dotsc, A{}_k\\) forman una partición de del conjunto \\(S\\). Además, suponga que \\(E\\) es cualquier subconjunto de \\(S\\). Entonces, como se ilustra en la figura 2.15 para el caso \\(k=5\\), \\[ E=E \\cap S=E \\cap \\left(A{}_1 \\cup A{}_2 \\cup \\cdots \\cup A{_k} \\right)=\\left(E \\cap A{_1} \\right) \\cup \\left(E \\cap A{_2} \\right) \\cup \\cdots \\cup \\left(E \\cap A{_k} \\right). \\] knitr::include_graphics(path = &quot;figuras/probabilidad_total.png&quot;) Figura 2.15: Diagrama de Ven para la probabilidad total Como los \\(k\\) eventos a la derecha de la ecuación anterior son también mutuamente excluyentes, esta puede reescribirse de la siguiente manera (ver el axioma 3 de los axiomas de la probabilidad 2.3.4.4). \\[ P \\left(E \\right)=P\\left(E \\cap A{_1} \\right) + P\\left(E \\cap A{_2} \\right) + \\cdots + P\\left(E \\cap A{_k} \\right). \\] Luego, utilizando el teorema de multiplicación para dos eventos 2.9 en cada uno de los sumando de la ecuación anterior , bajo el supuesto de que \\(P\\left(A{}_i \\right) \\neq 0\\) para \\(i=1, 2, \\dotsc, k\\), se obtiene que \\[ \\begin{align*} P \\left(E \\right)&amp;=P \\left(A{}_1 \\right) \\cdot P \\left( E \\mid A{}_1 \\right) + P \\left(A{}_2 \\right) \\cdot P \\left( E \\mid A{}_2 \\right) + \\cdots + P \\left(A{}_k \\right) \\cdot P \\left( E \\mid A{}_k \\right)\\\\ &amp;=\\sum_{i=1}^{k}P\\left ( A{}_i \\right ) \\cdot P\\left ( E \\mid A{}_i \\right ) \\end{align*} \\] Lo anteriormente expuesto se resume en el siguiente teorema: Teorema 2.13 (Ley de la Probabilidad Total) Sea \\(E\\) un evento en un espacio muestral \\(S\\) y sean los eventos \\(A{}_1, A{}_2, \\dotsc, A{}_k\\) una partición de \\(S\\) para los cuales se cumple que \\(P\\left(A{}_i \\right) \\neq 0\\) para \\(i=1, 2, \\dotsc, k\\). Entonces, \\[ \\begin{equation} P \\left(E \\right)=\\sum_{i=1}^{k}P\\left ( A{}_i \\right ) \\cdot P\\left ( E \\mid A{}_i \\right ). \\tag{2.28} \\end{equation} \\] Ejemplo 2.14 (Ley de la Probabilidad Total) Una fábrica utiliza tres máquinas \\(A\\), \\(B\\), \\(C\\) para producir ciertos artículos. Supongamos qe: La máquina \\(A\\) produce el 50% de todos los artículos, de los cuales el 3% son defectuosos. La máquina \\(B\\) produce 30% de todos los artículos, de los cuales el 4% son defectuosos. La máquina \\(C\\) produce 20% de todos los artículos, de los cuales el 5% son defectuosos. Encuentre la probabilidad de que un artículo seleccionado aleatoriamente sea defectuoso. knitr::include_graphics(path = &quot;figuras/ejemplo1_probabilidad_total.png&quot;) Figura 2.16: Diegrama de Venn del ejemplo 2.14 Sea el evento \\(D: \\{ \\textrm{el artículo seleccionado es defectuoso} \\}\\) . Entonces, por la ley de la probabilidad total 2.13 y de acuerdo con la figura 2.16, se obtiene que \\[ \\begin{align*} P \\left(D \\right)&amp;=P \\left(A \\right) \\cdot P \\left( D \\mid A \\right) + P \\left(B \\right) \\cdot P \\left( D \\mid B \\right) + P \\left(C \\right) \\cdot P \\left( E \\mid A{}_k \\right)\\\\ &amp; = \\left(0,5 \\right) \\cdot \\left( 0,03 \\right) + \\left(0,3 \\right) \\cdot \\left( 0,04 \\right) + \\left(0,2 \\right) \\cdot P \\left( 0,05 \\right)\\\\ &amp; =0,037=3,7\\%. \\end{align*} \\] 2.3.4.9 Teorema de Bayes Supóngase que los eventos \\(A{}_1, A{}_2, \\dotsc, A{}_k\\) forman una partición del espacio muestral \\(S\\), y \\(E\\) es cualquier evento de \\(S\\). Entonces, para \\(i=1, 2, \\dotsc, k\\), por definición de probabilidad condicional 2.35 \\[ P \\left( A{}_i \\mid E \\right)=\\frac{P \\left( A{}_i \\cap E \\right)}{P \\left( E \\right)}, \\] si \\(P\\left(E \\right) \\neq 0\\). Luego, aplicando el teorema de la multiplicación para dos eventos 2.9 en el numerador de la ecuación anterior se puede establecer que \\[ P \\left( A{}_i \\mid E \\right)=\\frac{P \\left( A_i \\right) \\cdot P \\left( E \\mid A_i \\right)}{P \\left( E \\right)}, \\] si \\(P \\left(A_i \\right) \\neq 0\\) para \\(i=1, 2, \\dotsc, k\\). Por último, haciendo uso de la ley de la probabilidad total 2.13 para el denominador en la ecuación anterior, se obtiene que \\[ P \\left( A{}_i \\mid E \\right)=\\frac{P \\left(A{}_i \\right) \\cdot P \\left( E \\mid A{}_i \\right)}{\\sum_{i=1}^{k}P\\left ( A{}_i \\right ) \\cdot P\\left ( E \\mid A{}_i \\right )}. \\] El procedimiento anterior se resume en el siguiente teorema: Teorema 2.14 (Teorema de Bayes) Si los eventos \\(A{}_1, A{}_2, \\dotsc, A{}_k\\) constituyen una partición del espacio muestral \\(S\\) y \\(P\\left(A{}_i \\right) \\neq 0\\) para \\(i=1, 2, \\dotsc, k\\). Entonces, para un evento \\(E\\) cualquiera contenido en \\(S\\) tal que \\(P\\left(E \\right) \\neq 0\\) \\[ \\begin{equation} P \\left( A{}_i \\mid E \\right)=\\frac{P \\left(A{}_i \\right) \\cdot P \\left( E \\mid A{}_i \\right)}{\\sum_{i=1}^{k}P\\left ( A{}_i \\right ) \\cdot P\\left ( E \\mid A{}_i \\right )}, \\textrm{para} i=1, 2, \\dotsc, k. \\tag{2.29} \\end{equation} \\] Ejemplo 2.15 (Teorema de Bayes) Considere la fábrica en el ejemplo 2.14. Suponga que se ha encontrado un artículo defectuoso entre la producción. Encuentre la probabilidad de que este provenga de cada una de las máquinas, es decir, encuentre \\(P \\left( A \\mid D \\right)\\), \\(P \\left( B \\mid D \\right)\\) y \\(P \\left( C \\mid D \\right)\\). Como se mostró en el ejemplo 2.14 \\[ \\begin{align*} P \\left(D \\right)&amp;=P \\left(A \\right) \\cdot P \\left( D \\mid A \\right) + P \\left(B \\right) \\cdot P \\left( D \\mid B \\right) + P \\left(C \\right) \\cdot P \\left( E \\mid A{}_k \\right)\\\\ &amp; = \\left(0,5 \\right) \\cdot \\left( 0,03 \\right) + \\left(0,3 \\right) \\cdot \\left( 0,04 \\right) + \\left(0,2 \\right) \\cdot P \\left( 0,05 \\right)\\\\ &amp; =0,037=3,7\\%. \\end{align*} \\] Por tanto, aplicando el teorema de Bayes en el cálculo de las probabilidades requeridas se obtiene que: La probabilidad de que el artículo sea producido por la máquina \\(A\\) dado que este defectuoso se obtiene de la siguiente manera \\[P \\left( A \\mid D \\right)=\\frac{P \\left(A \\right) \\cdot P \\left( D \\mid A \\right)}{P\\left ( D \\right )}=\\frac{ \\left(0,5 \\right) \\cdot \\left( 0,03 \\right)}{\\left ( 0,037 \\right )}=\\frac{15}{37}=40,5\\%. \\] La probabilidad de que el artículo sea producido por la máquina \\(B\\) dado que este defectuoso es \\[P \\left( B \\mid D \\right)=\\frac{P \\left(B \\right) \\cdot P \\left( D \\mid B \\right)}{P\\left ( D \\right )}=\\frac{ \\left(0,3 \\right) \\cdot \\left( 0,04 \\right)}{\\left ( 0,037 \\right )}=\\frac{12}{37}=32,5\\%. \\] La probabilidad de que el artículo sea producido por la máquina \\(C\\) dado que este defectuoso viene dado por \\[P \\left( C \\mid D \\right)=\\frac{P \\left(C \\right) \\cdot P \\left( D \\mid C \\right)}{P\\left ( D \\right )}=\\frac{ \\left(0,2 \\right) \\cdot \\left( 0,05 \\right)}{\\left ( 0,037 \\right )}=\\frac{10}{37}=27\\%. \\] "],["dist_disc.html", "Núcleo Temático 3 Disribuciones Discretas de Probabilidades 3.1 Variable Aleatoria 3.2 Función de Probabilidad 3.3 Función de Distribución Acumulativa de Probabilidad 3.4 Esperanza Mateática de Una Variable Aleatoria Discreta 3.5 Varianza de Una Variable Aleatoria Discreta 3.6 Función Generadora de Momentos de Una Variable Aleatoria Discreta 3.7 Distribuciones de Probabilidad Notables", " Núcleo Temático 3 Disribuciones Discretas de Probabilidades El siguiente bloque de código permite instalar y cargar los paquetes de R que se usaran en esta sección. packages &lt;- c( &quot;ggplot2&quot;, &quot;ggstatsplot&quot;, &quot;tidyverse&quot;, &quot;kableExtra&quot;, &quot;plotly&quot; ) package.check &lt;- lapply(packages, FUN = function(x) { if (!require(x, character.only = TRUE)) { install.packages(x, dependencies = TRUE) library(x, character.only = TRUE) } }) 3.1 Variable Aleatoria Definición 3.1 (Variable Aleatoria) Sea un experimento aleatorio \\(\\varepsilon\\) y \\(S\\) el espacio muestral asociado con el experimento. Una función \\(X\\) que asigna a cada uno de los elementos \\(s\\) de \\(S\\), un número real \\(X \\left(s \\right)\\), se llama variable aleatoria. 3.1.1 Recorrido de una Variable Aleatoria Definición 3.2 (Recorrido de una Variable Aleatoria) Sea \\(X\\) una variable aleatoria, al conjunto de todos los posibles valores de \\(X\\) se llama recorrido de \\(X\\) y se denota \\(R_X\\). Ejemplo 3.1 (Variable Aleatoria) Suponga que lanzamos dos monedas (\\(\\varepsilon\\)), los posibles resultados de este experimento aleatorio \\(S\\) será \\[ S=\\left\\{cc, cs, sc, ss \\right\\}. \\] Ahora, sobre este espacio muestra se define la variable aleatoria \\(X\\) como sigue: \\(X\\) es el número de caras obtenidas en los dos lanzamientos. Por lo tanto \\(X \\left(cc \\right)=2\\), \\(X \\left(cs \\right)=X \\left(sc \\right)=1\\), y \\(X \\left(ss \\right)=0\\). En este ejemplo \\(R_X =0,1,2\\). 3.1.2 Variable Aleatoria Discreta Definición 3.3 (Variable Aleatoria Discreta) Sea \\(X\\) una variable aleatoria. Si el número de valores posibles de \\(X\\), es decir \\(R_X\\), es finito o infinito numerable, se llama a \\(X\\) una variable aleatoria discreta. Esto es, se pueden anotar los valores de \\(X\\) como \\(x_1, x_2, \\dotsc, x_n, \\dots\\) En el caso finito la lista termina y en el caso infinito numerable la lista continúa indefinidamente. Ejemplo 3.2 (Variable Aleatoria) Considere el experimento aleatorio \\(\\varepsilon\\) lanzar una moneda hasta que aparece una cara. En tal caso, el espacio muestral \\(S\\) queda definido por, \\[ S=\\left\\{c, sc, ssc, sssc, ssssc, \\dotsc \\right\\}. \\] Si sobre este espacio muestral se define la variable aleatoria \\(X=\\textrm{número de lanzamientos hata que aparece una cara}\\). Entonces el recorrido de \\(X\\), es decir \\(R_X\\), viene definido por \\(R_X=1, 2, 3, \\dotsc\\). Dado que el recorrido de \\(X\\) es infinito numerable se concluye que \\(X\\) es una variable discreta. Con respecto al ejemplo 3.2, la variable aleatoria \\(X=\\textrm{el número de caras obtenidas en los dos lanzamientos}\\) es discreta ya que esta toma solo cuatro valores, \\(R_X =\\left\\{0, 1, 2 \\right\\}\\). Es decir, el recorrido de \\(X\\) es finito. 3.1.3 Variable Aleatoria Continua Definición 3.4 (Variable Aleatoria Continua) Se dice que una variable aleatoria es continua si su recorrido \\(R_X\\) consiste en uno o más intervalos de la recta de los reales. Ejemplo 3.3 (Variable Aleatoria Continua) Se selecciona de manera aleatoria un punto en un círculo \\(C\\) de radio \\(r\\). Sea \\(X\\) la distancia del punto al centro del círculo. Entonces, \\(X\\) es una variable aleatoria cuyo valor puede ser cualquier número entre 0 y \\(r\\), inclusive. por tanto, el recorrido \\(R_X\\) de \\(X\\) es un intervalo cerrado: \\[ R_X=\\left[ 0,r\\right]=\\left\\{x:0\\le x \\le r \\right\\}. \\] Aquí, \\(X\\) es una variable aleatoria continua. 3.2 Función de Probabilidad Definición 3.5 (Función de Probabilidad) Sea \\(X\\) una variable aleatoria discreta con recorrido \\(R_X=\\left\\{x_1, x_2, \\dotsc \\right\\}\\). Tal que, la probabilidad de que \\(X=x_i\\) es \\(p \\left(x_i \\right)\\), es decir, \\(P \\left(X=x_i \\right)=p \\left(x_i \\right)\\), para \\(i=1,2, \\dotsc\\). Entonces, la función \\(p\\) es una función de probabilidad si cumple las siguientes condiciones: \\[ \\begin{align*} i)&amp; \\: p \\left(x_i \\right) \\ge 0,\\, para \\: i= 1, 2, \\dotsc\\\\ ii)&amp; \\: \\sum_{i=1}^{\\infty }p\\left ( x_i \\right )=1. \\tag{3.1} \\end{align*} \\] Ejemplo 3.4 (Función de Probabilidad) Sea el experimento aleatorio que consiste en lanzar un par de dados equilibrados y \\(X\\) la variable aleatoria representada por la suma de los resultados en cada dado. Como se mostró en el ejemplo 2.10, el espacio muestral viene dado por \\[ S=\\begin{Bmatrix} (1,1);&amp;(1,2);&amp;(1,3);&amp;(1,4);&amp;(1,5);&amp;(1,6);\\\\ (2,1);&amp;(2,2);&amp;(2,3);&amp;(2,4);&amp;(2,5);&amp;(2,6);\\\\ (3,1);&amp;(3,2);&amp;(3,3);&amp;(3,4);&amp;(3,5);&amp;(3,6);\\\\ (4,1);&amp;(4,2);&amp;(4,3);&amp;(4,4);&amp;(4,5);&amp;(4,6);\\\\ (5,1);&amp;(5,2);&amp;(5,3);&amp;(5,4);&amp;(5,5);&amp;(5,6);\\\\ (6,1);&amp;(6,2);&amp;(6,3);&amp;(6,4);&amp;(6,5);&amp;(6,6)\\\\ \\end{Bmatrix}. \\] Por lo que, el Recorrido de \\(X\\) es \\(R_X=\\left\\{2, 3, 4, 5, 6, 7, 8, 9 10, 11, 12 \\right\\}\\), luego las probabilidades asociadas a cada \\(x_i\\), es decir la función de probabilidad, se muestran en la tabla 3.1. dp_ej1 &lt;- data.frame( S = c( &quot;$\\\\left(1, 1 \\\\right)$&quot;, &quot;$\\\\left(1, 2 \\\\right), \\\\left(2, 1 \\\\right)$&quot;, &quot;$\\\\left(1, 3 \\\\right), \\\\left(2, 2 \\\\right), \\\\left(3, 1 \\\\right)$&quot;, &quot;$\\\\left(1, 4 \\\\right), \\\\left(2, 3 \\\\right), \\\\left(3, 2 \\\\right), \\\\left(4, 1 \\\\right)$&quot;, &quot;$\\\\left(1, 5\\\\right), \\\\left(2, 4 \\\\right), \\\\left(3, 3 \\\\right), \\\\left(4, 2 \\\\right),\\\\left(5, 1\\\\right)$&quot;, &quot;$\\\\left(1, 6\\\\right), \\\\left(2, 5 \\\\right), \\\\left(3, 4 \\\\right), \\\\left(4, 3 \\\\right),\\\\left(5, 2\\\\right),\\\\left(6, 1\\\\right)$&quot;, &quot;$\\\\left(2, 6\\\\right), \\\\left(3, 5 \\\\right), \\\\left(4, 4 \\\\right), \\\\left(5, 3 \\\\right),\\\\left(6, 2\\\\right)$&quot;, &quot;$\\\\left(3, 6 \\\\right), \\\\left(4, 5 \\\\right), \\\\left(5, 4 \\\\right), \\\\left(6, 3 \\\\right)$&quot;, &quot;$\\\\left(4, 6 \\\\right), \\\\left(5, 5 \\\\right), \\\\left(6, 4 \\\\right)$&quot;, &quot;$\\\\left(5, 6 \\\\right), \\\\left(6, 5 \\\\right)$&quot;, &quot;$\\\\left(6, 6 \\\\right)$&quot; ), xi = 2:12, numero_ocurrencia = c(1:6, 5:1) ) %&gt;% mutate( p_xi = c( &quot;$\\\\frac{1}{36}$&quot;, &quot;$\\\\frac{2}{36}$&quot;, &quot;$\\\\frac{3}{36}$&quot;, &quot;$\\\\frac{4}{36}$&quot;, &quot;$\\\\frac{5}{36}$&quot;, &quot;$\\\\frac{6}{36}$&quot;, &quot;$\\\\frac{5}{36}$&quot;, &quot;$\\\\frac{4}{36}$&quot;, &quot;$\\\\frac{3}{36}$&quot;, &quot;$\\\\frac{2}{36}$&quot;, &quot;$\\\\frac{1}{36}$&quot; ) ) knitr::kable( dp_ej1, booktabs = TRUE, row.names = TRUE, col.names = c(&quot;Espacio Muestral&quot;, &quot;$x_i$&quot;, &quot;Número de ocurrencia&quot;, &quot;$p\\\\left(x_i \\\\right)$&quot;), align = c(&quot;lccc&quot;), format.args = list(decimal.mark = &quot;,&quot;, big.mark = &quot;.&quot;), caption = &quot;\\\\label{tab2:distribucion-probabilidad1}Distribución de probabilidad de la suma de las caras de dos dados&quot;, escape = FALSE ) %&gt;% kable_styling( bootstrap_options = &quot;striped&quot;, full_width = FALSE, fixed_thead = T ) %&gt;% kable_classic_2() Tabla 3.1: Distribución de probabilidad de la suma de las caras de dos dados Espacio Muestral \\(x_i\\) Número de ocurrencia \\(p\\left(x_i \\right)\\) 1 \\(\\left(1, 1 \\right)\\) 2 1 \\(\\frac{1}{36}\\) 2 \\(\\left(1, 2 \\right), \\left(2, 1 \\right)\\) 3 2 \\(\\frac{2}{36}\\) 3 \\(\\left(1, 3 \\right), \\left(2, 2 \\right), \\left(3, 1 \\right)\\) 4 3 \\(\\frac{3}{36}\\) 4 \\(\\left(1, 4 \\right), \\left(2, 3 \\right), \\left(3, 2 \\right), \\left(4, 1 \\right)\\) 5 4 \\(\\frac{4}{36}\\) 5 \\(\\left(1, 5\\right), \\left(2, 4 \\right), \\left(3, 3 \\right), \\left(4, 2 \\right),\\left(5, 1\\right)\\) 6 5 \\(\\frac{5}{36}\\) 6 \\(\\left(1, 6\\right), \\left(2, 5 \\right), \\left(3, 4 \\right), \\left(4, 3 \\right),\\left(5, 2\\right),\\left(6, 1\\right)\\) 7 6 \\(\\frac{6}{36}\\) 7 \\(\\left(2, 6\\right), \\left(3, 5 \\right), \\left(4, 4 \\right), \\left(5, 3 \\right),\\left(6, 2\\right)\\) 8 5 \\(\\frac{5}{36}\\) 8 \\(\\left(3, 6 \\right), \\left(4, 5 \\right), \\left(5, 4 \\right), \\left(6, 3 \\right)\\) 9 4 \\(\\frac{4}{36}\\) 9 \\(\\left(4, 6 \\right), \\left(5, 5 \\right), \\left(6, 4 \\right)\\) 10 3 \\(\\frac{3}{36}\\) 10 \\(\\left(5, 6 \\right), \\left(6, 5 \\right)\\) 11 2 \\(\\frac{2}{36}\\) 11 \\(\\left(6, 6 \\right)\\) 12 1 \\(\\frac{1}{36}\\) Como se oberva en la tabla 3.1 \\(p\\left ( x_i \\right )\\) es una auténtica función de probabilidad dado que se cumplen las dos condiciones requeridas en la definición 3.5. Es decir, \\[ i) \\: p \\left(x_i \\right) \\ge 0,\\, para \\: i= 1, 2, \\dotsc 11; y \\] \\[ \\begin{align*} ii) \\: \\sum_{i=1}^{11 }p\\left ( x_i \\right )=&amp; \\frac{1}{36}+\\frac{2}{36}+\\frac{3}{36}+\\frac{4}{36}+\\frac{5}{36}+\\frac{6}{36}\\\\ &amp; +\\frac{5}{36}+\\frac{4}{36}+\\frac{3}{36}+\\frac{2}{36}+\\frac{1}{36}\\\\ &amp;=1. \\end{align*} \\] En algunos casos es posible expresar la función de probabilidad a través de una expresión matemática dada en términos de la variable aleatoria. En este caso, la función de probabilidad queda determinada por la siguiente expresión: \\[ p\\left ( x \\right )= \\begin{cases} \\frac{6-\\left|x-7 \\right|}{36} &amp; \\text{si } x= 2, 3, \\cdots ,12\\\\ 0 &amp; \\text{en otros casos }. \\tag{3.2} \\end{cases} \\] Con la ecuación (3.2) también se pueden calcular las probabilidades dadas en la tabla 3.1, tal como se muestra a continuación: \\[ \\begin{align*} P(X=2)&amp;=p\\left (2 \\right )= \\frac{6-\\left|2- 7\\right|}{36}=\\frac{1}{36}\\\\ P(X=3)&amp;=p\\left (3 \\right )= \\frac{6-\\left|3- 7\\right|}{36}=\\frac{2}{36} \\\\ P(X=4)&amp;=p\\left (4 \\right )= \\frac{6-\\left|4- 7\\right|}{36}=\\frac{3}{36} \\\\ P(X=5)&amp;=p\\left (5 \\right )= \\frac{6-\\left|5- 7\\right|}{36}=\\frac{4}{36} \\\\ P(X=6)&amp;=p\\left (6 \\right )= \\frac{6-\\left|6- 7\\right|}{36}=\\frac{5}{36} \\\\ P(X=7)&amp;=p\\left (7 \\right )= \\frac{6-\\left|7- 7\\right|}{36}=\\frac{6}{36} \\\\ P(X=8)&amp;=p\\left (8 \\right )= \\frac{6-\\left|8- 7\\right|}{36}=\\frac{5}{36} \\\\ P(X=9)&amp;=p\\left (9 \\right )= \\frac{6-\\left|9- 7\\right|}{36}=\\frac{4}{36} \\\\ P(X=10)&amp;=p\\left (10 \\right )= \\frac{6-\\left|10- 7\\right|}{36}=\\frac{3}{36} \\\\ P(X=11)&amp;=p\\left (11 \\right )= \\frac{6-\\left|11- 7\\right|}{36}=\\frac{2}{36} \\\\ P(X=12)&amp;=p\\left (12 \\right )= \\frac{6-\\left|12- 7\\right|}{36}=\\frac{1}{36} \\\\. \\end{align*} \\] Como se puede notar, las probabilidades determinadas con esta ecuación se corresponden con las que se muestran en la tabla 3.1. Una forma de visualizar de manera rápida las probabilidades asociadas a cada valor de la variable aleatoria es a través de una gráfica de líneas verticales que comienzan en cada valor de la variable \\(x_i\\) y cuya altura está determinada por sus probabilidades \\(p\\left (x_i \\right )\\). El gráfico de la función de probabilidad para la suma de las caras en el lanzamiento de los dos dados se muestra en la figura 3.1. ggplot( data = dp_ej1, aes(x = xi, y = numero_ocurrencia / 36) ) + geom_segment( aes( x = xi, xend = xi, y = 0, yend = numero_ocurrencia / 36 ), color = &quot;blue&quot; ) + geom_point( size = 3, color = &quot;red&quot; ) + scale_x_continuous(breaks = seq(2, 12, 1)) + theme_classic() + xlab(&quot;Suma de las caras (X)&quot;) + ylab(&quot;Función de probabilidad&quot;) Figura 3.1: Gráfica de la función de probabilidad de la suma de las caras de dos dados 3.3 Función de Distribución Acumulativa de Probabilidad Existen muchos problemas en los que es necesario calcular la probabilidad de que el valor observado de una variable aleatoria \\(X\\) sea menor o igual que algún número real \\(x\\). Al escribir \\(F \\left(x \\right) = P \\left(X \\leq x \\right)\\) para cualquier número real \\(x\\), se define \\(F \\left(x \\right)\\) como la función de distribución acumulativa de probabilidad de la variable aleatoria \\(X\\). De manera formal, la función de distribución acumulativa de probabilidad se define de la siguiente manera: Definición 3.6 (Función de Distribución Acumulativa de Probabilidad) Sea \\(X\\) una variable aleatoria discreta con función de probabilidad \\(p \\left(x_i \\right)\\). Entonces, la función de distribución acumulativa de probabilidad de \\(X\\), denotada como \\(F \\left(X \\right)\\), viene dada por: \\[ \\begin{equation} F\\left ( x \\right )=P\\left ( X \\leq x \\right )=\\sum_{t=x_1}^{x} p\\left ( t \\right ), \\, \\textrm{ para} \\:\\, t \\leq x. \\tag{3.3} \\end{equation} \\] 3.3.1 Propiedades de la Función de Distribución Acumulativa de Probabilidad Dentro de las propiedades más importantes de la función de distribución acumulativa de probabilidad se pueden mencionar las siguientes: \\[ \\begin{align*} i)&amp; \\: 0 \\leq F\\left ( x \\right ) \\leq 1 \\:\\: \\textrm{par cualquier}\\:x; \\\\ ii)&amp; \\:\\displaystyle \\lim_{x \\to - \\infty }F\\left ( x \\right )=0;\\\\ iii)&amp; \\:\\displaystyle \\lim_{x \\to \\infty }F\\left ( x \\right )=1;\\\\ iv)&amp; \\: F\\left ( x_{j} \\right ) \\geq F\\left ( x_{i} \\right ) \\:\\: \\textrm{si} \\: x_{j} \\geq x_{i};\\\\ v)&amp; \\: F\\left ( x_{i} \\right ) = F\\left ( x_{i-1} \\right ) + p\\left ( x_{i} \\right );\\\\ vi)&amp; \\: P\\left ( X &gt; x_{i} \\right ) = 1 - F\\left ( x_{i} \\right ); \\\\ vii)&amp; \\: P\\left ( X &lt; x_{i} \\right ) = F\\left ( x_{i-1} \\right ); \\\\ viii)&amp; \\: P\\left ( X \\geq x_{i} \\right ) = 1 - F\\left ( x_{i-1} \\right ); \\\\ ix)&amp; \\: P\\left ( X=x_{i} \\right )=F\\left ( x_{i} \\right )-F\\left ( x_{i-1} \\right ); \\\\ x)&amp; \\: P\\left ( x_{i} \\leq X \\leq x_{j} \\right )=F\\left ( x_{j} \\right )-F\\left ( x_{i-1} \\right );\\\\ xi)&amp; \\: P\\left ( x_{i} &lt; X \\leq x_{j} \\right )=F\\left ( x_{j} \\right )-F\\left ( x_{i} \\right );\\\\ xii)&amp; \\: P\\left ( x_{i} \\leq X &lt; x_{j} \\right )=F\\left ( x_{j-1} \\right )-F\\left ( x_{i-1} \\right ).\\\\ \\end{align*} \\] Ejemplo 3.4 (Función de Distribución Acumulativa) Determine la función de distribución acumulativa de probabilidad del ejemplo 3.4. La función de distribución acumulativa de probabilidad en este caso viene dada, de acuerdo con la definición 3.6, por: \\[ \\begin{align*} F(2)&amp;=P\\left ( X \\leq 2 \\right )=p\\left (2 \\right )= \\frac{1}{36}\\\\ F(3)&amp;=P\\left ( X \\leq 3 \\right )= p\\left (2 \\right )+p\\left (3 \\right )= \\frac{1}{36} + \\frac{2}{36} =\\frac{3}{36} \\\\ F(4)&amp;=P\\left ( X \\leq 4 \\right )= p\\left (2 \\right )+p\\left (3 \\right )+p\\left (4 \\right )\\\\&amp;= \\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36}=\\frac{6}{36} \\\\ F(5)&amp;=P\\left ( X \\leq 5 \\right )= p\\left (2 \\right )+p\\left (3 \\right )+p\\left (4 \\right )+p\\left (5 \\right )\\\\&amp;= \\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36}+ \\frac{4}{36}=\\frac{10}{36} \\\\ F(6)&amp;=P\\left ( X \\leq 6 \\right )= p\\left (2 \\right )+p\\left (3 \\right )+p\\left (4 \\right )+p\\left (5 \\right )+p\\left (6 \\right )\\\\&amp;= \\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36}+ \\frac{4}{36}+ \\frac{5}{36}=\\frac{15}{36} \\\\ F(7)&amp;=P\\left ( X \\leq 7 \\right )= p\\left (2 \\right )+p\\left (3 \\right )+p\\left (4 \\right )+p\\left (5 \\right )+p\\left (6 \\right )+p\\left (7 \\right )\\\\&amp;= \\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36}+ \\frac{4}{36}+ \\frac{5}{36}+ \\frac{6}{36}=\\frac{21}{36} \\\\ F(8)&amp;=P\\left ( X \\leq 8 \\right )= p\\left (2 \\right )+p\\left (3 \\right )+p\\left (4 \\right )+p\\left (5 \\right )+p\\left (6 \\right )+p\\left (7 \\right )\\\\&amp;+p\\left (8 \\right )\\\\&amp;= \\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36}+ \\frac{4}{36}+ \\frac{5}{36}+ \\frac{6}{36}+ \\frac{5}{36}=\\frac{26}{36} \\\\ F(9)&amp;=P\\left ( X \\leq 9 \\right )= p\\left (2 \\right )+p\\left (3 \\right )+p\\left (4 \\right )+p\\left (5 \\right )+p\\left (6 \\right )+p\\left (7 \\right )\\\\&amp;+p\\left (8 \\right )+p\\left (9 \\right )\\\\&amp;= \\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36}+ \\frac{4}{36}+ \\frac{5}{36}+ \\frac{6}{36}+ \\frac{5}{36}+ \\frac{4}{36}=\\frac{30}{36} \\\\ F(10)&amp;=P\\left ( X \\leq 10 \\right )= p\\left (2 \\right )+p\\left (3 \\right )+p\\left (4 \\right )+p\\left (5 \\right )+p\\left (6 \\right )+p\\left (7 \\right )\\\\&amp;+p\\left (8 \\right )+p\\left (9 \\right )+p\\left (10 \\right )\\\\&amp;= \\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36}+ \\frac{4}{36}+ \\frac{5}{36}+ \\frac{6}{36}+ \\frac{5}{36}+ \\frac{4}{36}+ \\frac{3}{36}\\\\&amp;=\\frac{33}{36} \\\\ F(11)&amp;=P\\left ( X \\leq 11 \\right )= p\\left (2 \\right )+p\\left (3 \\right )+p\\left (4 \\right )+p\\left (5 \\right )+p\\left (6 \\right )+p\\left (7 \\right )\\\\&amp;+p\\left (8 \\right )+p\\left (9 \\right )+p\\left (10 \\right )+p\\left (11 \\right )\\\\&amp;= \\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36}+ \\frac{4}{36}+ \\frac{5}{36}+ \\frac{6}{36}+ \\frac{5}{36}+ \\frac{4}{36}+ \\frac{3}{36}\\\\&amp;+ \\frac{2}{36}=\\frac{35}{36} \\\\ F(12)&amp;=P\\left ( X \\leq 12 \\right )= p\\left (2 \\right )+p\\left (3 \\right )+p\\left (4 \\right )+p\\left (5 \\right )+p\\left (6 \\right )+p\\left (7 \\right )\\\\&amp;+p\\left (8 \\right )+p\\left (9 \\right )+p\\left (10 \\right )+p\\left (11 \\right )+p\\left (12 \\right)\\\\&amp;= \\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36}+ \\frac{4}{36}+ \\frac{5}{36}+ \\frac{6}{36}+ \\frac{5}{36}+ \\frac{4}{36}+ \\frac{3}{36}\\\\&amp;+ \\frac{2}{36}+ \\frac{1}{36}=\\frac{36}{36}=1 \\\\. \\end{align*} \\] Los resultados anteriores pueden resumirse en la tabla 3.2. da_ej1 &lt;- data.frame( S = c( &quot;$\\\\left(1, 1 \\\\right)$&quot;, &quot;$\\\\left(1, 2 \\\\right), \\\\left(2, 1 \\\\right)$&quot;, &quot;$\\\\left(1, 3 \\\\right), \\\\left(2, 2 \\\\right), \\\\left(3, 1 \\\\right)$&quot;, &quot;$\\\\left(1, 4 \\\\right), \\\\left(2, 3 \\\\right), \\\\left(3, 2 \\\\right), \\\\left(4, 1 \\\\right)$&quot;, &quot;$\\\\left(1, 5\\\\right), \\\\left(2, 4 \\\\right), \\\\left(3, 3 \\\\right), \\\\left(4, 2 \\\\right),\\\\left(5, 1\\\\right)$&quot;, &quot;$\\\\left(1, 6\\\\right), \\\\left(2, 5 \\\\right), \\\\left(3, 4 \\\\right), \\\\left(4, 3 \\\\right),\\\\left(5, 2\\\\right),\\\\left(6, 1\\\\right)$&quot;, &quot;$\\\\left(2, 6\\\\right), \\\\left(3, 5 \\\\right), \\\\left(4, 4 \\\\right), \\\\left(5, 3 \\\\right),\\\\left(6, 2\\\\right)$&quot;, &quot;$\\\\left(3, 6 \\\\right), \\\\left(4, 5 \\\\right), \\\\left(5, 4 \\\\right), \\\\left(6, 3 \\\\right)$&quot;, &quot;$\\\\left(4, 6 \\\\right), \\\\left(5, 5 \\\\right), \\\\left(6, 4 \\\\right)$&quot;, &quot;$\\\\left(5, 6 \\\\right), \\\\left(6, 5 \\\\right)$&quot;, &quot;$\\\\left(6, 6 \\\\right)$&quot; ), xi = 2:12, numero_ocurrencia = c(1:6, 5:1) ) %&gt;% mutate( p_xi = c( &quot;$\\\\frac{1}{36}$&quot;, &quot;$\\\\frac{2}{36}$&quot;, &quot;$\\\\frac{3}{36}$&quot;, &quot;$\\\\frac{4}{36}$&quot;, &quot;$\\\\frac{5}{36}$&quot;, &quot;$\\\\frac{6}{36}$&quot;, &quot;$\\\\frac{5}{36}$&quot;, &quot;$\\\\frac{4}{36}$&quot;, &quot;$\\\\frac{3}{36}$&quot;, &quot;$\\\\frac{2}{36}$&quot;, &quot;$\\\\frac{1}{36}$&quot; ), F_xi = c( &quot;$\\\\frac{1}{36}$&quot;, &quot;$\\\\frac{3}{36}$&quot;, &quot;$\\\\frac{6}{36}$&quot;, &quot;$\\\\frac{10}{36}$&quot;, &quot;$\\\\frac{15}{36}$&quot;, &quot;$\\\\frac{21}{36}$&quot;, &quot;$\\\\frac{26}{36}$&quot;, &quot;$\\\\frac{30}{36}$&quot;, &quot;$\\\\frac{33}{36}$&quot;, &quot;$\\\\frac{35}{36}$&quot;, &quot;$\\\\frac{36}{36}$&quot; ) ) knitr::kable( da_ej1, booktabs = TRUE, row.names = TRUE, col.names = c(&quot;Espacio Muestral&quot;, &quot;$x_i$&quot;, &quot;Número de ocurrencia&quot;, &quot;$p\\\\left(x_i \\\\right)$&quot;, &quot;$F\\\\left(x_i \\\\right)$&quot;), align = c(&quot;lccc&quot;), format.args = list(decimal.mark = &quot;,&quot;, big.mark = &quot;.&quot;), caption = &quot;\\\\label{tab2:distribucion-acumulada1}Función de distribución acumulativa de la suma de las caras de dos dados&quot;, escape = FALSE ) %&gt;% kable_styling( bootstrap_options = &quot;striped&quot;, full_width = FALSE, fixed_thead = T ) %&gt;% kable_classic_2() Tabla 3.2: Función de distribución acumulativa de la suma de las caras de dos dados Espacio Muestral \\(x_i\\) Número de ocurrencia \\(p\\left(x_i \\right)\\) \\(F\\left(x_i \\right)\\) 1 \\(\\left(1, 1 \\right)\\) 2 1 \\(\\frac{1}{36}\\) \\(\\frac{1}{36}\\) 2 \\(\\left(1, 2 \\right), \\left(2, 1 \\right)\\) 3 2 \\(\\frac{2}{36}\\) \\(\\frac{3}{36}\\) 3 \\(\\left(1, 3 \\right), \\left(2, 2 \\right), \\left(3, 1 \\right)\\) 4 3 \\(\\frac{3}{36}\\) \\(\\frac{6}{36}\\) 4 \\(\\left(1, 4 \\right), \\left(2, 3 \\right), \\left(3, 2 \\right), \\left(4, 1 \\right)\\) 5 4 \\(\\frac{4}{36}\\) \\(\\frac{10}{36}\\) 5 \\(\\left(1, 5\\right), \\left(2, 4 \\right), \\left(3, 3 \\right), \\left(4, 2 \\right),\\left(5, 1\\right)\\) 6 5 \\(\\frac{5}{36}\\) \\(\\frac{15}{36}\\) 6 \\(\\left(1, 6\\right), \\left(2, 5 \\right), \\left(3, 4 \\right), \\left(4, 3 \\right),\\left(5, 2\\right),\\left(6, 1\\right)\\) 7 6 \\(\\frac{6}{36}\\) \\(\\frac{21}{36}\\) 7 \\(\\left(2, 6\\right), \\left(3, 5 \\right), \\left(4, 4 \\right), \\left(5, 3 \\right),\\left(6, 2\\right)\\) 8 5 \\(\\frac{5}{36}\\) \\(\\frac{26}{36}\\) 8 \\(\\left(3, 6 \\right), \\left(4, 5 \\right), \\left(5, 4 \\right), \\left(6, 3 \\right)\\) 9 4 \\(\\frac{4}{36}\\) \\(\\frac{30}{36}\\) 9 \\(\\left(4, 6 \\right), \\left(5, 5 \\right), \\left(6, 4 \\right)\\) 10 3 \\(\\frac{3}{36}\\) \\(\\frac{33}{36}\\) 10 \\(\\left(5, 6 \\right), \\left(6, 5 \\right)\\) 11 2 \\(\\frac{2}{36}\\) \\(\\frac{35}{36}\\) 11 \\(\\left(6, 6 \\right)\\) 12 1 \\(\\frac{1}{36}\\) \\(\\frac{36}{36}\\) Cuando se conoce la expresión que define la función de probabilidad, la cual, en este caso está dada por la ecuación (3.2), se puede determinar una expresión matemática que defina la función de distribución acumulativa de probabilidad. A continuación se ejecuta un procedimiento para hallar esta ecuación. \\[ \\begin{align*} F\\left ( x \\right )=\\sum_{t=2}^{x}p\\left ( x \\right ) =\\sum_{t=2}^{x}\\frac{6-\\left|7-x \\right|}{36}. \\end{align*} \\] Como la expresión \\(\\left|7-x \\right|\\) es positiva si \\(x=2, 3, \\dotsc, 7\\) y negativa si \\(x=8, 9, \\dotsc, 12\\). Entonces, se derivan expresiones para \\(F\\left ( x \\right )\\) en cada uno de estos casos. si \\(x=2, 3, \\dotsc, 7\\) \\[ \\begin{align*} F\\left ( x \\right )&amp;= \\sum_{t=2}^{x}\\frac{6-\\left|7-x \\right|}{36}=\\frac{1}{36}\\sum_{t=2}^{x}\\left ( 6-7+x \\right )=\\frac{1}{36}\\sum_{t=2}^{x}\\left ( t-1 \\right )\\\\ &amp;=\\frac{1}{36}\\left [ \\sum_{t=2}^{x}t-\\sum_{t=2}^{x}1 \\right ]=\\frac{1}{36}\\left [ \\left ( 2+3+\\cdots +x \\right )-\\left ( x-1 \\right ) \\right ]\\\\ &amp;=\\frac{1}{36}\\left [ \\left ( \\frac{2+x}{2} \\right )\\left ( x-1 \\right )-\\left ( x-1 \\right ) \\right ] = \\frac{1}{36}\\left ( x-1 \\right )\\left ( \\frac{2+x}{2} -1 \\right )\\\\ &amp;=\\frac{1}{36}\\left ( x-1 \\right )\\left ( \\frac{2+x-2}{2} \\right )=\\frac{1}{72}x\\left ( x-1 \\right ). \\end{align*} \\] si \\(x=8, 9, \\dotsc, 12\\) \\[ \\begin{align*} F\\left ( x \\right )&amp;=\\sum_{t=8}^{x}\\frac{6-\\left|7-x \\right|}{36}=\\frac{1}{36}\\sum_{t=8}^{x}\\left ( 6+7-x \\right )\\\\ &amp;=\\frac{1}{36}\\sum_{t=8}^{x}\\left ( 13-x \\right )=\\frac{1}{36}\\left [ \\sum_{t=8}^{x}13-\\sum_{t=8}^{x}x \\right ]\\\\ &amp;=\\frac{1}{36}\\left [ 13\\left ( x-7 \\right )-\\left ( \\frac{8+x}{2} \\right )\\left ( x-7 \\right ) \\right ]\\\\ &amp;=\\frac{1}{36}\\left [ \\left ( x-7 \\right )\\left ( 13-\\left ( \\frac{8+x}{2} \\right ) \\right ) \\right ]\\\\ &amp;=\\frac{1}{36}\\left [ \\left ( x-7 \\right )\\left ( \\frac{26-8-x}{2} \\right ) \\right ]=\\frac{1}{72}\\left ( x-7 \\right )\\left ( x-8 \\right ). \\end{align*} \\] En resumen, la función de distribución acumulada puede expresarse de la siguiente manera: \\[ F\\left ( x \\right )= \\begin{cases} 0 &amp; \\textrm{ si } x&lt; 2 \\\\ \\frac{1}{72}x\\left ( x-1 \\right ) &amp; \\textrm{ si } x=2, 3,\\dotsc,7 \\\\ \\frac{42}{72}+\\frac{1}{72}\\left ( x-7 \\right )\\left ( 18-x \\right ) &amp; \\textrm{ si } x=8, 9, \\dotsc,12 \\\\ 1 &amp; \\textrm{ si } x&gt;1. \\tag{3.4} \\end{cases} \\] Se puede verificar que los valores de \\(F\\left ( x \\right )\\) dados en la tabla 3.2 se corresponden con los que se obtienen con la ecuación (3.4). Por ejemplo: \\[ \\begin{align*} a)&amp; \\: F\\left ( 7 \\right )=\\frac{1}{72}7\\left ( 7-1 \\right )=\\frac{42}{72}=\\frac{42}{72}\\\\ b)&amp; \\: F\\left ( 10 \\right )=\\frac{42}{72}+\\frac{1}{72}\\left ( 10-7 \\right )\\left ( 18-10\\right)=\\frac{42}{72}+\\frac{24}{72}=\\frac{66}{72}=\\frac{33}{36}. \\end{align*} \\] La figura 3.2 muestra la gráfica de la función de distribución acumulativa de la suma de las caras de los dados. Note que esta gráfica es escalonada. dp_ej1 &lt;- dp_ej1 %&gt;% mutate( F_xi = cumsum(numero_ocurrencia) / 36, xi_end = c(3:12, NA), F_xiend = F_xi ) ggplot( dp_ej1, aes( x = xi, y = F_xi, xend = xi_end, yend = F_xiend ) ) + geom_point() + geom_point(aes(x = xi_end, y = F_xi), shape = 1) + geom_segment(color = &quot;blue&quot;) + scale_x_continuous(breaks = seq(2, 12, 1)) + theme_classic() + xlab(&quot;Suma de las caras (X)&quot;) + ylab(&quot;Función de distribución acumulativa&quot;) Figura 3.2: Gráfica de la función de distribución acumulativa de la suma de las caras de dos dados 3.4 Esperanza Mateática de Una Variable Aleatoria Discreta Definición 3.7 (Esperanza Mateática de Una Variable Aleatoria Discreta) Sea \\(X\\) una variable aleatoria discreta con la función de probabilidad \\(p \\left(x \\right)\\). Entonces la esperanza matemática, media o valor esperado de\\(X\\), denotado por \\(E \\left(x \\right)\\) o simplemente \\(\\mu\\), se define como \\[ \\begin{equation} \\mu=E \\left(X \\right)=\\sum_{x}x p \\left(x \\right). \\tag{3.5} \\end{equation} \\] Ejemplo 3.5 (Esperanza Matemática de Una Variable Aleatoria discreta) Calcule el valor esperado de la variable aleatoria \\(X\\) representada por la suma de los resultados del lanzamiento de dos dados descrita en el ejemplo 3.4. De acuerdo con la definición 3.7, en este caso la esperanza viene dada por: \\[ \\begin{align*} \\mu=&amp;E\\left(X \\right)=\\sum_{x=2}^{12 }xp\\left ( x \\right )= 2 \\left(\\frac{1}{36}\\right)+3\\left(\\frac{2}{36}\\right)+4\\left(\\frac{3}{36}\\right)+5\\left(\\frac{4}{36}\\right)+6\\left(\\frac{5}{36}\\right)+7\\left(\\frac{6}{36}\\right) \\\\ &amp; +8\\left(\\frac{5}{36}\\right)+9\\left(\\frac{4}{36}\\right)+10\\left(\\frac{3}{36}\\right)+11\\left(\\frac{2}{36}\\right)+12\\left(\\frac{1}{36}\\right)\\\\ &amp;=7. \\end{align*} \\] Este valor significa que si se lanzan los dos dados un número significativamente grande de veces, el promedio de la suma de las caras va estar próximo a 7. En R, el resultado anterior se puede obtener con el siguiente script. x &lt;- 2:12 p_x &lt;- c(1:6,5:1) / 36 (media &lt;- sum(x * p_x)) #&gt; [1] 7 En muchos problemas de estadística no solo es de interés el valor esperado de la variable \\(X\\), como se definió en 3.7, sino también el valor esperado de alguna variable \\(Y\\) que es una transformación de \\(X\\), es decir \\(g\\left(x \\right)\\). Por ejemplo, \\(y=g\\left(x \\right)=x^2\\). En tal sentido, se establece el teorema siguiente: Teorema 3.1 Si \\(X\\) es una variable aleatoria discreta con función de probabilidad \\(p\\left(x \\right)\\). Entonces, el valor esperado de la variable aleatoria \\(g\\left(x \\right)\\) está dado por \\[ \\begin{equation} E \\left[g\\left(x \\right) \\right]=\\sum_{x}g\\left(x \\right) p \\left(x \\right). \\tag{3.6} \\end{equation} \\] En algunos casos el calculo de esperanzas matemáticas se simplifican mediante el uso de los siguientes teoremas, los cuales permiten calcular valores esperados a partir de otras esperanzas conocidas o que se determinan con menor dificultad. Teorema 3.2 Si \\(X\\) es una variable aleatoria discreta con función de probabilidad \\(p\\left(x \\right)\\) y sean \\(a\\) y \\(b\\) constantes. Entonces, \\[ \\begin{equation} E \\left( ax+b \\right)=a.E \\left( x \\right)+b. \\tag{3.7} \\end{equation} \\] Note que si se hace \\(a=0\\) en el teorema 3.1 se obtiene el siguiente corolario: Corolario 3.1 Si \\(X\\) es una variable aleatoria discreta con función de probabilidad \\(p\\left(x \\right)\\) y \\(a\\) una constantes. Entonces, \\[ \\begin{equation} E \\left( ax \\right) = aE \\left( x \\right). \\tag{3.8} \\end{equation} \\] Mientras que si se hace \\(b=0\\) en el teorema 3.1 se obtiene este otro: Corolario 3.2 Si \\(X\\) es una variable aleatoria discreta con función de probabilidad \\(p\\left(x \\right)\\) y \\(b\\) una constantes. Entonces, \\[ \\begin{equation} E \\left( b \\right) = b. \\tag{3.9} \\end{equation} \\] Observe que si se escribe \\(E \\left( b \\right)\\), la constante \\(b\\) se puede ver como una variable aleatoria que siempre toma el valor \\(b\\). Otro teorema importante relacionado con la esperanza de transformaciones de variables aleatoria es el siguiente: Teorema 3.3 Si \\(X\\) es una variable aleatoria discreta con función de probabilidad \\(p\\left(x \\right)\\). Además, considere que \\(c_1, c_2, \\dotsc, c_n\\) son constantes y \\(g_1\\left(x \\right), g_2\\left(x \\right), \\dotsc, g_n\\left(x \\right)\\) transformaciones de \\(X\\). Entonces, \\[ \\begin{equation} E \\left[\\sum_{i=1}^{n}c_i g_i\\left(x \\right) \\right]=\\sum_{i=1}^{n}c_iE \\left[ g_i\\left(x \\right) \\right]. \\tag{3.10} \\end{equation} \\] 3.5 Varianza de Una Variable Aleatoria Discreta Definición 3.8 (Varianza de Una Variable Aleatoria Discreta) Sea \\(X\\) una variable aleatoria con distribución de probabilidad \\(p \\left(x \\right)\\) y media \\(\\mu\\). La varianza de \\(X\\), denotado por \\(\\sigma^2\\) o \\(E \\left[\\left(X  \\right)^2 \\right]\\) es \\[ \\begin{equation} \\sigma^2=E \\left[\\left(X  \\right)^2 \\right]=\\sum_{x}\\left(X  \\right)^2 p \\left(x \\right). \\tag{3.11} \\end{equation} \\] La raíz cuadrada positiva de la varianza, \\(\\sigma\\), se llama desviación estándar de \\(X\\). Una ecuación alternativa para la varianza se obtiene de la siguiente manera. Primero, se desarrolla la expresión \\(\\left(X  \\right)^2\\) dada en la ecuación (3.11), como sigue. \\[ \\sigma^2=E \\left[\\left(X  \\right)^2 \\right]=E\\left(X^2-2\\mu X +\\mu^2 \\right). \\] Luego, por el teorema 3.3 y el corolario 3.1, se obtiene \\[ \\sigma^2=E \\left[\\left(X  \\right)^2 \\right]=E\\left(X^2 \\right)-2\\mu E \\left(X \\right) +\\mu^2 . \\] Como \\(E \\left(X \\right)=\\mu\\), entonces \\[ \\begin{equation} \\sigma^2=E \\left[\\left(X  \\right)^2 \\right]=E\\left(X^2 \\right)-\\mu^2. \\tag{3.12} \\end{equation} \\] Ejemplo 3.6 (Varianza de Una Variable Aleatoria Discreta) Calcule el valor esperado de la variable aleatoria \\(X\\) representada por la suma de los resultados del lanzamiento de dos dados descrita en el ejemplo 3.4. De acuerdo con la definición 3.8, la varianza de la suma delas caras de los dados es: \\[ \\begin{align*} \\sigma^2=&amp;\\sum_{x=2}^{12}\\left(x  \\right)^2p\\left ( x \\right )= \\left(2-7 \\right)^2 \\left(\\frac{1}{36}\\right)+\\left(3-7 \\right)^2\\left(\\frac{2}{36}\\right)+\\left(4-7 \\right)^2\\left(\\frac{3}{36}\\right)+\\left(5-7 \\right)^2\\left(\\frac{4}{36}\\right) \\\\ &amp;+\\left(6-7 \\right)^2\\left(\\frac{5}{36}\\right)+\\left(7-7 \\right)^2\\left(\\frac{6}{36}\\right) +\\left(8-7 \\right)^2\\left(\\frac{5}{36}\\right)+\\left(9-7 \\right)^2\\left(\\frac{4}{36}\\right)+\\left(10-7 \\right)^2\\left(\\frac{3}{36}\\right) \\\\ &amp;+\\left(11-7 \\right)^2\\left(\\frac{2}{36}\\right)+\\left(12-7 \\right)^2\\left(\\frac{1}{3 6}\\right)\\\\ &amp;=\\frac{35}{6} \\approx 5,83. \\end{align*} \\] Mientras que la desviación estándar es, \\[ \\sigma = \\sqrt{\\frac{35}{6}} \\approx 2,42. \\] Usando la ecuación alternativa para la varianza dada en la ecuación (3.12), el valor de este parámetro se se obtiene como sigue \\[ \\begin{align*} \\sigma^2=&amp;\\sum_{x=2}^{12}x^2p\\left ( x \\right )-\\mu^2= \\left(2 \\right)^2 \\left(\\frac{1}{36}\\right)+\\left(3 \\right)^2\\left(\\frac{2}{36}\\right)+\\left(4 \\right)^2\\left(\\frac{3}{36}\\right)+\\left(5 \\right)^2\\left(\\frac{4}{36}\\right)\\\\ &amp;+\\left(6 \\right)^2\\left(\\frac{5}{36}\\right) +\\left(7 \\right)^2\\left(\\frac{6}{36}\\right) +\\left(8 \\right)^2\\left(\\frac{5}{36}\\right)+\\left(9 \\right)^2\\left(\\frac{4}{36}\\right)+\\left(10 \\right)^2\\left(\\frac{3}{36}\\right)+\\left(11 \\right)^2\\left(\\frac{2}{36}\\right)\\\\ &amp;+\\left(12 \\right)^2\\left(\\frac{1}{3 6}\\right) - \\left(7 \\right)^2\\\\ &amp; =\\frac{329}{6} - 49=\\frac{35}{6} \\approx 5,83. \\end{align*} \\] El valor de la varianza y la desviación estándar obtenidos anteriormente se pueden calcular en R con el siguiente script. (varianza &lt;- sum((x - media) ^ 2 * p_x)) (desviacion &lt;- sqrt(varianza)) #&gt; [1] 5.833333 #&gt; [1] 2.415229 3.6 Función Generadora de Momentos de Una Variable Aleatoria Discreta Definición 3.9 (Función Generadora de Momentos de Una Variable Aleatoria Discreta) Sea \\(X\\) una variable aleatoria discreta con función de probabilidad \\(p \\left(x \\right)\\). El valor esperado de \\(e^{tx}\\) recibe el nombre de función generadora de momentos, y se denota por \\(m_x \\left(t \\right)\\) de \\(X\\), si el valor esperado existe en algún intervalo \\(-c&lt;t&lt;c\\) en donde \\(c\\) es un entero positivo. En otros términos: \\[ \\begin{equation} m_x \\left(t \\right)=E \\left(e^{tx} \\right) =\\sum_{x}e^{tx} p \\left(x \\right), \\:si\\: -c&lt;t&lt;c. \\tag{3.13} \\end{equation} \\] Teorema 3.4 Si \\(X\\) es una variable aleatoria con función generadora de momentos \\(m_x \\left(t \\right)\\). Entonces, \\[ \\begin{equation} \\frac{\\mathrm{d}^{k}m_{x}\\left ( t \\right )}{\\mathrm{d}t^{k}} \\left|\\begin{matrix} \\\\ t=0\\\\ \\end{matrix}={\\mu}^{&#39;}_k \\right. \\tag{3.13} \\end{equation} \\] En muchas situaciones cundo se trabaja con variables aleatorias se definen transformaciones lineales sobre estas variables. En tales casos, si se conoce la función generadora de momentos de estas variables se pueden obtener las funciones generadoras de momentos de esas transformaciones por medio del teorema que sigue: Teorema 3.5 Si \\(X\\) es una variable aleatoria con función generadora de momentos \\(m_x \\left(t \\right)\\). Entonces, \\[ \\begin{align*} i)&amp;\\:m_{x+a}\\left ( t \\right )= E\\left [ e^{\\left ( x+a \\right )t} \\right ]=e^{at} \\cdot m_{x}\\left ( t \\right )\\\\ ii)&amp;\\: m_{bx}\\left ( t \\right )= E\\left ( e^{bxt} \\right )=m_{x}\\left ( bt \\right )\\\\ iii)&amp;\\: m_{\\frac{x+a}{b}} =E\\left [ e^{\\left ( \\frac{x+a}{b} \\right )t} \\right ] =e^{\\frac{a}{b}t} \\cdot m_{x}\\left ( \\frac{t}{b} \\right ). \\tag{3.14} \\end{align*} \\] 3.7 Distribuciones de Probabilidad Notables En esta sección se definen algunas distribuciones de probabilidad de gran importancia por sus múltiples aplicaciones en la descripción de fenómenos que ocurren en la vida diaria, tales como: la distribución binomial, la distribución hipergeométrica y la distribución de Poisson. 3.7.1 Distribución Binomial Definición 3.10 (Distribución Binomial) Sea \\(X\\) una variable aleatoria que representa el número de éxitos en \\(n\\) ensayos y \\(p\\) la probabilidad de éxito en cualquiera de éstos. Se dice que \\(X\\) tiene una distribución binomial con parámetros \\(n\\) y \\(p\\), y se escribe \\(X\\sim Bin\\left ( n, p \\right )\\), con función de probabilidad. \\[ p\\left ( x;n,p \\right )=\\begin{cases} \\binom{n}{x}p^{x}\\left ( 1-p \\right )^{n-x} &amp; \\text{ si } x= 0, 1, 2, \\dotsc, n;\\: 0\\leq p\\leq 1 \\text{ y }n \\in \\mathbb{N}\\\\ 0 &amp; \\text{ en cualquier otro caso }. \\tag{3.15} \\end{cases} \\] La figura 3.3 muestra la gráfica de la función de probabilidad binomial para \\(n=10\\) y \\(p = 0,2; 0,5; 0,8\\). Como se observa en esta gráfica la distribución binomial es asimétrica positiva para \\(p = 0,1\\); simétrica para \\(p = 0,5\\) y asimétrica negativa para \\(p = 0,8\\). De manera general, esta distribución de probabilidad es asimétrica positiva para \\(p &lt; 0,5\\), simétrica si \\(p = 0,5\\) y asimétrica negativa si \\(p &gt; 0,5\\). plot_ly(alpha = 0.5) %&gt;% add_segments( x = ~c(0:10), y = ~rep(x = 0, times = 11), xend = ~c(0:10), yend = ~dbinom(0:10, 10, 0.2), color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;n = 10, p = 0,2&quot; ) %&gt;% add_markers( x = ~c(0:10), y = ~dbinom(0:10, 10, 0.2), color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;n = 10, p = 0,2&quot; ) %&gt;% add_segments( x = ~c(0:10), y = ~rep(x = 0, times = 11), xend = ~c(0:10), yend = ~dbinom(0:10, 10, 0.5), color = I(&quot;blue&quot;), showlegend = TRUE, name = &quot;n = 10, p = 0,5&quot; ) %&gt;% add_markers( x = ~c(0:10), y = ~dbinom(0:10, 10, 0.5), color = I(&quot;blue&quot;), showlegend = TRUE, name = &quot;n = 10, p = 0,5&quot; ) %&gt;% add_segments( x = ~c(0:10), y = ~rep(x = 0, times = 11), xend = ~c(0:10), yend = ~dbinom(0:10, 10, 0.8), color = I(&quot;green&quot;), showlegend = TRUE, name = &quot;n = 10, p = 0,8&quot; ) %&gt;% add_markers( x = ~c(0:10), y = ~dbinom(0:10, 10, 0.8), color = I(&quot;green&quot;), showlegend = TRUE, name = &quot;n = 10, p = 0,8&quot; ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;p(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.3: Gráfica de la función de probabilidad binomial para \\(n = 10\\) y \\(p = 0,2; 0,5; 0,8\\) Ejemplo 3.7 (Función de Probabilidad Binomial) Todos los días se seleccionan, de manera aleatoria, 15 artículos de un proceso de producción con el propósito de vigilar la fracción de artículos defectuosos que produce el proceso. Con base en información pasada, la probabilidad de que el proceso produzca un artículo defectuoso es 0,05. Determine la probabilidad de que se encuentren dos artículos defectuosos en la muestra. Dado que \\(X\\) representa el número de artículo defectuosos encontrados en una muestra de tamaño 15 (\\(n=15\\)) y que la probabilidad de que cualquier artículo en la muestra sea defectuoso es constante e igual a 0,05 (\\(p = 0,05\\)). Entonces, de acuerdo con la definición 3.10, \\(X\\) tiene distribución binomial con parámetros \\(n = 15\\) y \\(p = 0,05\\), es decir, \\(X \\sim Bin\\left(n = 15, p = 0,05 \\right)\\). Por lo tanto, de acuerdo con la ecuación (3.15), \\[ P\\left(X = 2 \\right)=p\\left ( x = 2;n = 15,p = 0,05 \\right )= \\binom{15}{2}\\left(0,05 \\right)^{2}\\left ( 1- 0,05 \\right )^{15-2} \\approx 0,134752. \\] La función dbinom(x, size, prob, log = FALSE) de la distribución base de R permite evaluar la función de probabilidad binomial dada por la ecuación (3.15). El siguiente script permite obtener el resultado anterior. dbinom(x = 2, size = 15, prob = 0.05, log = FALSE) #&gt; [1] 0.1347523 La figura 3.4 muestra la gráfica de la función de probabilidad del número de artículos defectuosos en una muestra de 15 artículos (\\(X\\)). La cual, como se sabe, tiene distribución binomial con parámetros \\(n = 15\\) y \\(p = 0,05\\). Es decir, \\(X \\sim Bin \\left(n = 15, p = 0,05 \\right)\\). plot_ly(alpha = 0.5) %&gt;% add_segments( x = 0:15, y = ~rep(x = 0, times = length(0:15)), xend = 0:15, yend = ~dbinom( x = 0:15, size = 15, prob = 0.05, log = FALSE ), color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;n = 15, p = 0,05&quot; ) %&gt;% add_markers( x = 0:15, y = ~dbinom( x = 0:15, size = 15, prob = 0.05, log = FALSE ), color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;n = 15, p = 0,05&quot; ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;p(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.4: Gráfica de la función de probabilidad binomial para \\(n = 15\\) y \\(p = 0,05\\) 3.7.1.1 Función de Distribución Acumulativa de Probabilidad Binomial La probabilidad de que una variable aleatoria binomial \\(X\\) sea menor o igual que un valor específico \\(x\\) o dicho de otra manera la probabilidad de encontrar a los más \\(x\\) éxitos en los \\(n\\) ensayos, o lo que es igual,la función de distribución acumulativa de probabilidad binomial, queda determinada, de acuerdo con las definiciones 3.6 y 3.10 por: Definición 3.11 (Función de Distribución Acumulativa de Probabilidad Binomial) Sea \\(X\\) una variable aleatoria con distribución binomial. Entonces, la función de distribución acumulativa de probabilidad binomial viene dada por: \\[ F\\left ( x;n,p \\right )=\\begin{cases} 0 &amp; \\text{ si } x &lt; 0\\\\ \\sum_{t=0}^{x } \\binom{n}{t}p^{t}\\left ( 1-p \\right )^{n-t} &amp; \\text{ si } x= 0, 1, 2, \\dotsc, n;\\: 0\\leq p\\leq 1 \\text{ y }n \\in \\mathbb{N}\\\\ 1 &amp; \\text{ si } x &gt; n. \\tag{3.16} \\end{cases} \\] La figura 3.5 muestra la función de distribución acumulativa de probabilidad para una variable binomial con parámetros \\(n = 10\\) y \\(p = 0,2; 0,5; 0,8\\). x &lt;- c(-3, 0:10, 13) px1 &lt;- dbinom(x = x, size = 10, prob = 0.2) Fx1 &lt;- pbinom(q = x, size = 10, prob = 0.2) px2 &lt;- dbinom(x = x, size = 10, prob = 0.5) Fx2 &lt;- pbinom(q = x, size = 10, prob = 0.5) px3 &lt;- dbinom(x = x, size = 10, prob = 0.8) Fx3 &lt;- pbinom(q = x, size = 10, prob = 0.8) plot_ly(x = x, y = Fx1, alpha = 0.5) %&gt;% add_segments( x = ~x[1:12], y = ~Fx1[1:12], xend = ~x[2:13], yend = ~Fx1[1:12], color = I(&quot;red&quot;), name = &quot;n = 10, p = 0,2&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x[2:12], y = ~Fx1[2:12], color = I(&quot;red&quot;), name = &quot;n = 10, p = 0,2&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x[2:12], y = ~Fx1[1:11], color = I(&quot;red&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;n = 10, p = 0,2&quot;, showlegend = TRUE ) %&gt;% add_segments( x = ~x[1:12], y = ~Fx2[1:12], xend = ~x[2:13], yend = ~Fx2[1:12], color = I(&quot;blue&quot;), name = &quot;n = 10, p = 0,5&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x[2:12], y = ~Fx2[2:12], color = I(&quot;blue&quot;), name = &quot;n = 10, p = 0,5&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x[2:12], y = ~Fx2[1:11], color = I(&quot;blue&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;n = 10, p = 0,5&quot;, showlegend = TRUE ) %&gt;% add_segments( x = ~x[1:12], y = ~Fx3[1:12], xend = ~x[2:13], yend = ~Fx3[1:12], color = I(&quot;green&quot;), name = &quot;n = 10, p = 0,8&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x[2:12], y = ~Fx3[2:12], color = I(&quot;green&quot;), name = &quot;n = 10, p = 0,8&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x[2:12], y = ~Fx3[1:11], color = I(&quot;green&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;n = 10, p = 0,8&quot;, showlegend = TRUE ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;F(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.5: Gráfica de la función de distribución acumulativa de probabilidad binomial para \\(n = 15\\) y \\(p = 0,2;0,5;0,8\\) Ejemplo 3.8 (Función de Distribución Acumulativa de Probabilidad Binomial) suponga en el ejemplo 3.7 que la gerencia de control de calidad de la fábrica ha decidido detener la producción cada vez que en una muestra de 15 unidades tenga dos o más artículos defectuosos ¿Cuál es la probabilidad de que, en cualquier día, la producción se detenga? Dado que la probabilidad de que la producción se detenga es igual a la probabilidad de que \\(X\\) sea igual o mayor que dos. De esta manera: \\[ \\begin{align*} P \\left(X \\geq 2 \\right) =&amp; 1 - P \\left(X \\leq 1 \\right)= 1 - F \\left( x = 1;n = 15,p = 0,05 \\right ) = 1 - \\sum_{t=0}^{1 } \\binom{15}{t} \\left( 0,05 \\right)^{t} \\left( 1-0,05 \\right )^{15-t}\\\\ =&amp; \\binom{15}{0}\\left(0,05 \\right)^{0} \\left( 1- 0,05 \\right)^{15-0}+ \\binom{15}{1}\\left(0,05 \\right)^{1} \\left( 1- 0,05 \\right)^{15-1}\\\\ \\approx &amp; 0,170953. \\end{align*} \\] La función pbinom(q, size, prob, lower.tail = TRUE, log.p = FALSE) de la distribución base de R permite evaluar la función de distribución acumulativa de probabilidad binomial dada por la ecuación (3.16). El siguiente script permite obtener el resultado anterior. 1 - pbinom( q = 1, size = 15, prob = 0.05, lower.tail = TRUE, log.p = FALSE ) #&gt; [1] 0.1709525 La figura 3.6 muestra la gráfica de la función de distribución acumulativa del número de artículos defectuosos en una muestra de 15 artículos \\(X\\). La cual, como se sabe, tiene distribución binomial con parámetros \\(n = 15\\) y \\(p= 0,05\\). x &lt;- c(-3, 0:15, 18) px &lt;- dbinom(x = x, size = 15, prob = 0.05) Fx &lt;- pbinom(q = x, size = 15, prob = 0.05) plot_ly(x = x, y = Fx, alpha = 0.5) %&gt;% add_segments( x = ~x[1:17], y = ~Fx[1:17], xend = ~x[2:18], yend = ~Fx[1:17], color = I(&quot;blue&quot;), name = &quot;n = 15, p = 0,05&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x[2:17], y = ~Fx[2:17], color = I(&quot;red&quot;), name = &quot;n = 15, p = 0,05&quot; ) %&gt;% add_markers( x = ~x[2:17], y = ~Fx[1:16], color = I(&quot;red&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;n = 15, p = 0,05&quot; ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;F(x)&quot;, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.6: Gráfica de la función de distribución acumulativa de probabilidad binomial para \\(n = 15\\) y \\(p = 0,05\\) La tabla 3.3 muestra la función de probabilidad y la función de distribución acumulativa de probabilidad de una variable binomial con parámetros \\(n = 15\\) y \\(p = 0,05\\). da_ej2 &lt;- data.frame( x = 0:15, px = dbinom(x = 0:15, size = 15, prob = 0.05), Fx = pbinom(q = 0:15, size = 15, prob = 0.05) ) knitr::kable( da_ej2, booktabs = TRUE, row.names = TRUE, digits = 4, col.names = c( &quot;$X_i$&quot;, &quot;$p\\\\left(x_i \\\\right)$&quot;, &quot;$F\\\\left(x_i \\\\right)$&quot; ), align = c(&quot;ccc&quot;), format.args = list(decimal.mark = &quot;,&quot;, big.mark = &quot;.&quot;), caption = &quot;\\\\label{tab2:distribucion-acumulada2}Función de probabilidad y función de distribución acumulativa de $X \\\\sim Bin \\\\left(n = 15, p= 0,05 \\\\right)$&quot;, escape = FALSE ) %&gt;% kable_styling( bootstrap_options = &quot;striped&quot;, full_width = FALSE, fixed_thead = T ) %&gt;% kable_classic_2() Tabla 3.3: Función de probabilidad y función de distribución acumulativa de \\(X \\sim Bin \\left(n = 15, p= 0,05 \\right)\\) \\(X_i\\) \\(p\\left(x_i \\right)\\) \\(F\\left(x_i \\right)\\) 1 0 0,4633 0,4633 2 1 0,3658 0,8290 3 2 0,1348 0,9638 4 3 0,0307 0,9945 5 4 0,0049 0,9994 6 5 0,0006 0,9999 7 6 0,0000 1,0000 8 7 0,0000 1,0000 9 8 0,0000 1,0000 10 9 0,0000 1,0000 11 10 0,0000 1,0000 12 11 0,0000 1,0000 13 12 0,0000 1,0000 14 13 0,0000 1,0000 15 14 0,0000 1,0000 16 15 0,0000 1,0000 3.7.1.2 Media de la Distribución Binomial La media, promedio o esperanza matemática de la distribución binomial viene representada por un número, tal que si tomamos repetidas muestras de una variable binomial, en la medida en que se va incrementado el número de muestras el promedio de estos valores muestrales tiende a ese número en la medida en que se va incrementando el número de muestras. Lo dicho anteriormente se resume en el siguiente teorema. Teorema 3.6 (Media de la Distribución Binomial) Sea \\(X\\) una variable aleatoria con distribución binomial. Entonces, la media de \\(X\\) viene dada por: \\[ \\begin{equation} E \\left(X \\right)= \\mu = np. \\tag{3.17} \\end{equation} \\] Demostración (Media de la Distribución Binomial). Por las definiciones 3.7 y 3.10 la esperanza de una variable \\(X\\) con distribución binomial es \\[ \\begin{align*} E \\left(X \\right) =&amp; \\sum_{x=0}^{n } x\\frac{n!}{x!\\left ( n-x \\right )!}p^{x}\\left ( 1-p \\right )^{n-x}\\\\ =&amp; \\sum_{x=1}^{n } x\\frac{n!}{x!\\left ( n-x \\right )!}p^{x}\\left ( 1-p \\right )^{n-x}\\\\ =&amp; \\sum_{x=1}^{n } \\frac{n!}{\\left ( x-1 \\right )!\\left ( n-x \\right )!}p^{x}\\left ( 1-p \\right )^{n-x},\\\\ \\end{align*} \\] en donde se ha escrito la suma desde uno hasta \\(n\\), dado que cuando \\(x=0\\) el primer término es cero y se cancela la \\(x\\) del numerador con la \\(x\\) en \\(x!\\). Luego, factorizando \\(n\\) y \\(p\\), se tiene: \\[ \\begin{align*} E \\left(X \\right) =&amp; np\\sum_{x=1}^{n } \\frac{\\left ( n-1 \\right )!}{\\left ( x-1 \\right )!\\left ( n-x \\right )!}p^{x-1}\\left ( 1-p \\right )^{n-x}.\\\\ \\end{align*} \\] Si \\(y=x-1\\) y \\(m=n-1\\), entonces: \\[ \\begin{align*} E \\left(X \\right) =&amp; np\\sum_{y=0}^{m } \\frac{m!}{y!\\left ( m-y \\right )!}p^{y}\\left ( 1-p \\right )^{m-y}.\\\\ \\end{align*} \\] Pero \\(p \\left(y; m, p \\right)= \\left[m!/y!\\left(m-y \\right)! \\right]p^{y}\\left(1-p \\right)^{m-y}\\) es la función de probabilidad de una variable aleatoria binomial \\(Y\\) con parámetros \\(m=n-1\\) y \\(p\\); de esta manera \\(\\sum_{y=0}^{m }p\\left(y; m, p \\right)=1\\), y la media de una variable aleatoria binomial es: \\[ \\begin{equation} E \\left(X \\right) = np. \\end{equation} \\] Note de la ecuación anterior, que para un tamaño de muestra fijo \\(n\\), la media de la distribución binomial tiende a cero cuando \\(p\\) tiende a cero; y tiende a \\(n\\) cuando p tiende a uno. En otras palabras, la media de la distribución binomial disminuye cuando la probabilidad de éxito disminuye y aumenta cuando la probabilidad de éxito aumenta. Ejemplo 3.9 (Media de la Distribución Binomial) Con respecto al el ejemplo 3.7, determine el número de artículos defectuosos que se esperaría encontrar en una muestra de 15 artículos. De acuerdo con el teorema 3.6, se esperaría encontrar \\[ \\begin{equation} E \\left(X \\right) = np=15 \\cdot 0,05=0,75. \\end{equation} \\] Note que el valor anterior no es un número entero, es decir, si se toma una muestra de 15 artículos no se pueden encontrar 0,75 artículos defectuosos. Recuerde que el valor esperado es un promedio, por lo que la interpretación correcta es que la media de \\(X\\) es 0,75; es decir si se toman sucesivas muestras de 15 artículos del proceso se esperaría que la media del número de artículo defectuosos encontrados en las sucesivas muestras va a tender a 0,75. Ahora, si se toma una muestra de 100 artículos (\\(n=100\\)) del proceso de producción, se esperaría encontrar \\[ \\begin{equation} E \\left(X \\right) = np=100 \\cdot 0,05=5 \\end{equation} \\] 5 artículos defectuosos en la muestra. 3.7.1.3 Varianza de la Distribución Binomial La varianza de una variable aleatoria binomial \\(X\\) es un parámetro que indica que tan distante están los posibles valores que puede tomar esta variable, es decir, \\(x=0, 1, 2, \\dotsc, n\\) con respecto a la media de la variable \\(\\left(\\mu=np \\right)\\). En tal sentido, la varianza de una variable binomial se describe en el siguiente teorema: Teorema 3.7 (Varianza de la Distribución Binomial) Sea \\(X\\) una variable aleatoria con distribución binomial. Entonces, la varianza de \\(X\\) viene dada por: \\[ \\begin{equation} V \\left(X \\right)=\\sigma^2 = np \\left(1-p \\right). \\tag{3.18} \\end{equation} \\] Note de la ecuación anterior que para un \\(n\\) fijo, la gráfica de la varianza es una parábola cóncava hacia abajo. Por lo tanto, el vértice de la parábola será un máximo y se halla en \\(p=1/2\\). Es decir, la varianza es hace máxima cuando cuando \\(p=1/2\\). Por lo que, el máximo valor de la varianza será la cuarta parte del tamaño de la muestra. Demostración (varianza de la Distribución Binomial). De la ecuación (3.12) se sabe que \\(V \\left(X \\right) = E \\left(X^2 \\right) - \\mu^2\\). Como \\(\\mu=np\\), solo faltaría calcular \\(E \\left(X^2 \\right)\\). Pero calcular este parámetro usando el teorema 3.1 y la definición 3.10 implica encontrar la convergencia de la siguiente expresión \\[ E \\left(X^2 \\right) = \\sum_{x=0}^{n } x^2\\frac{n!}{x!\\left ( n-x \\right )!}p^{x}\\left ( 1-p \\right )^{n-x}, \\] lo cual es imposible. En lugar de este camino, se elegirá un método alterno. La alternativa es escribir \\(x^2\\) como: \\[ x^2= x \\left(x-1 \\right)+x; \\] de esta manera, por los teoremas 3.1 y 3.3, se tiene: \\[ \\begin{equation} E \\left(X^2 \\right)= E \\left[X \\left(X-1 \\right) \\right]+E \\left(X \\right). \\tag{3.19} \\end{equation} \\] Dado que \\(E \\left(X \\right)\\) ya se ha determinado, faltaría determinar \\(E \\left[x \\left(x-1 \\right) \\right]\\), que según el teorema 3.1, es: \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp; \\sum_{x=0}^{n } x \\left(x-1 \\right)\\frac{n!}{x!\\left ( n-x \\right )!}p^{x}\\left ( 1-p \\right )^{n-x}\\\\ =&amp; \\sum_{x=2}^{n } x \\left(x-1 \\right)\\frac{n!}{x!\\left ( n-x \\right )!}p^{x}\\left ( 1-p \\right )^{n-x}\\\\ =&amp; \\sum_{x=1}^{n } \\frac{n!}{\\left ( x-2 \\right )!\\left ( n-x \\right )!}p^{x}\\left ( 1-p \\right )^{n-x}\\\\ =&amp; n \\left(n-1 \\right)p^2 \\sum_{x=1}^{n } \\frac{\\left(n-2 \\right)!}{\\left ( x-2 \\right )!\\left ( n-x \\right )!}p^{x-2}\\left ( 1-p \\right )^{n-x}. \\end{align*} \\] Note que en los pasos previos se escribió la suma a partir de dos porque los dos primeros términos son cero, se canceló \\(x \\left(x-1 \\right)\\), y se factorizó \\(n \\left(n-1 \\right)p^2\\). Sea \\(y=x-2\\) y \\(m=n-2\\); entonces: \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp; n \\left(n-1 \\right)p^2\\sum_{y=0}^{m } \\frac{m!}{y!\\left ( m-y \\right )!}p^{y}\\left ( 1-p \\right )^{m-y}.\\\\ \\end{align*} \\] Pero \\(p \\left(y; m, p \\right)= \\left[m!/y!\\left(m-y \\right)! \\right]p^{y}\\left(1-p \\right)^{m-y}\\) es la función de probabilidad de una variable aleatoria binomial \\(Y\\) con parámetros \\(m=n-2\\) y \\(p\\); de esta manera $_{y=0}^{m }p(y; m, p )=1 $. En consecuencia, \\[ \\begin{equation} E \\left[X \\left(X-1 \\right) \\right] = n \\left(n-1 \\right)p^2. \\end{equation} \\] De la ecuación (3.19) \\[ E \\left(X^2 \\right)= n \\left(n-1 \\right)p^2+np. \\] De esta manera, la varianza de una variable aleatoria binomial, según la ecuación (3.12), es: \\[ \\begin{align*} V(X)=&amp;n \\left(n-1 \\right)p^2+np-n^2p^2\\\\ =&amp;np \\left[ \\left(n-1 \\right)p + 1 - np \\right]\\\\ =&amp;np \\left(1-p \\right). \\end{align*} \\] Ejemplo 3.10 (Varianza de la Distribución Binomial) Con respecto al ejemplo 3.7, determine la varianza del número de artículos defectuosos encontardos en una muestra de 15 artículos tomados del proceso de producción. De acuerdo con el teorema 3.7, la varianza de \\(X\\) es: \\[ V(X)=np \\left(1-p \\right)=15 \\cdot0,05 \\left(1-0,05 \\right)=0,7125. \\] 3.7.1.4 Función Genradora de Momentos de la Distribución Binomial La función generadora de momentos es un método alternativo para determinar los momentos ordinarios de una distribución de probabilidad determinada, por medio del teorema 3.4. En el caso de la distribución binomial, la función generadora de momentos se indica en el siguienete teorema: Teorema 3.8 (Función Generadora de Momentos de la Distribución Binomial) La función generadora de momentos de la distribución binomial está dada por: \\[ \\begin{equation} m_x \\left(t \\right)=\\left[1+p \\left(e^t-1 \\right) \\right]. \\tag{3.20} \\end{equation} \\] Demostración (Función Generadora de Momentos de la Distribución Binomial). De la definiciones 3.10 y 3.9, se obtiene \\[ \\begin{align*} m_x \\left(t \\right)=&amp; \\sum_{x=0}^{n } e^{tx}\\frac{n!}{x!\\left ( n-x \\right )!}p^{x}\\left ( 1-p \\right )^{n-x}\\\\ =&amp; \\sum_{x=0}^{n } \\frac{n!}{x!\\left ( n-x \\right )!}(e^{t}p)^{x}\\left ( 1-p \\right )^{n-x}.\\\\ \\end{align*} \\] Por el binomio de Newton, se sabe que la última sumatoria es la expansión de la expresión \\(\\left[e^{t}p+ \\left(1-p \\right) \\right]^n=\\left[1+ p\\left(e^t -1 \\right) \\right]^n\\). En resumen, \\[ \\begin{align*} m_x \\left(t \\right)=\\left[1+ p\\left(e^t -1 \\right) \\right]^n.\\\\ \\end{align*} \\] Del teorema 3.4, la media de la distribucón binomial es: \\[ \\begin{equation} \\frac{\\mathrm{d}m_{x}\\left ( t \\right )}{\\mathrm{d}t} \\left|\\begin{matrix} \\\\ t=0\\\\ \\end{matrix}={\\mu}^{&#39;}_1=\\mu \\right. \\end{equation} \\] La primera derivada de la función generadora de momentos es \\[ \\frac{\\mathrm{d}m_{x}\\left ( t \\right )}{\\mathrm{d}t}=npe^t \\left[1+ p\\left(e^t -1 \\right) \\right]^{n-1}. \\] Ahora, evaluando la primera derivada de la función generadora de momentos en \\(t=0\\), se obtiene la media de la distribución binomial, como sigue: \\[ \\begin{equation} \\frac{\\mathrm{d}m_{x}\\left ( t \\right )}{\\mathrm{d}t} \\left|\\begin{matrix} \\\\ t=0\\\\ \\end{matrix}=\\mu=npe^0 \\left[1+ p\\left(e^0 -1 \\right) \\right]^{n-1}=np. \\right. \\end{equation} \\] Note que este resultado es el mismo dado en el teorema 3.6. Se deja al lector que halle la varianza de la distribución binomial usando el método de la función generadora de momentos. 3.7.2 Distribuciones Hipergeométrica Definición 3.12 (Distribución Hipergeométrica) Dada una población que consta de \\(m\\) objetos que poseen una característica de interés y \\(n\\) que no la poseen. Si se selecciona una muestra aleatoria sin reemplazo de tamaño \\(k\\) de estos objetos. Entonces la variable aleatoria \\(X\\) que representa el número objetos en la muestra que tienen la característica de interés tiene distribución hipergeométrica, y se escribe \\(X \\sim H \\left(m, n, k \\right)\\), si su función de probabilidad viene dada por: \\[ p\\left ( x;m,n, k \\right )=\\begin{cases} \\frac{\\binom{m}{x}\\binom{n}{k-x}}{\\binom{m+n}{k}} &amp; \\text{ si } x= \\mathrm{máx} \\left\\{0, k - n \\right\\} \\leq x \\leq \\mathrm{mín} \\left\\{k, m \\right\\} \\\\ 0 &amp; \\text{ en cualquier otro caso }. \\tag{3.21} \\end{cases} \\] Los parámetros de la distribución hipergeométrica \\(m\\), \\(n\\) y \\(k\\) definen una familia de distribuciones con función de probabilidad determinada por la ecuación (3.21). En la figura 3.7 se muestran las gráficas de la función de probabilidad hipergeométrica (3.21) para distintas combinaciones de \\(m\\), \\(n\\) y \\(k\\). La función dhyper(x, m, n, k, log = FALSE) de la distribución base de R permite evaluar la función de probabilidad de la distribución hipergeométrica dada por la ecuación (3.21). m1 &lt;- 10 n1 &lt;- 90 k1 &lt;- 5 x1 &lt;- max(0, k1 - n1):min(k1, m1) px1 &lt;- dhyper(x = x1, m = m1, n = n1, k = k1, log = FALSE) m2 &lt;- 10 n2 &lt;- 90 k2 &lt;- 10 x2 &lt;- max(0, k2 - n2):min(k2, m2) px2 &lt;- dhyper(x = x2, m = m2, n = n2, k = k2, log = FALSE) m3 &lt;- 10 n3 &lt;- 90 k3 &lt;- 15 x3 &lt;- max(0, k3 - n3):min(k3, m3) px3 &lt;- dhyper(x = x3, m = m3, n = n3, k = k3, log = FALSE) plot_ly(alpha = 0.5) %&gt;% add_segments( x = x1, y = ~ rep(x = 0, times = length(x1)), xend = x1, yend = ~px1, color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;m = 10, n = 90, k = 5&quot; ) %&gt;% add_markers( x = x1, y = ~px1, color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;m = 10, n = 90, k = 5&quot; ) %&gt;% add_segments( x = x2, y = ~ rep(x = 0, times = length(x2)), xend = ~x2, yend = ~px2, color = I(&quot;blue&quot;), showlegend = TRUE, name = &quot;m = 10, n = 90, k = 10&quot; ) %&gt;% add_markers( x = ~x2, y = ~px2, color = I(&quot;blue&quot;), showlegend = TRUE, name = &quot;m = 10, n = 90, k = 10&quot; ) %&gt;% add_segments( x = ~x3, y = ~ rep(x = 0, times = length(x3)), xend = ~x3, yend = ~px3, color = I(&quot;green&quot;), showlegend = TRUE, name = &quot;m = 10, n = 90, k = 15&quot; ) %&gt;% add_markers( x = ~x3, y = ~px3, color = I(&quot;green&quot;), showlegend = TRUE, name = &quot;m = 10, n = 90, k = 15&quot; ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &quot;black&quot;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;p(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &quot;black&quot;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.7: Gráfica de la función de probabilidad hipergeométrica para distintos valores de \\(m\\), \\(n\\) y \\(k\\) Ejemplo 3.11 (Función de Probabilidad Hipergeométrica) Se tiene un lote de 100 lamparas, de las cuales el 5% están defectuosas. Si se toma una muestra aleatoria sin reemplazo de 10 de estas lamparas. Determine la probabilidad de que dos estén defectuosas. Dado que el lote de lamparas están particionadas en dos grupos, las defectuosas (característica de interés) y las no defectuosas. Además, la muestra se ha tomado del lote sin reemplazo. Si se define la variable \\(X\\) como el número de artículos defectuosos encontrados en la muestra, por la definición 3.12, \\(X\\) tiene distribución hipergeométrica con parámetros \\(m = 100 \\cdot0,05 = 5\\), \\(n = 95\\) y \\(k = 10\\), es decir, \\(X \\sim H\\left(m = 5 , n = 95, k = 10 \\right)\\). Por lo tanto, de acuerdo con la ecuación (3.21), la probabilidad de encontrar dos lamparas defectuosas en la muestra es: \\[ P\\left(X = 2 \\right)=p\\left ( x = 2;m = 100,n = 10, k =5 \\right )= \\frac{\\binom{5}{2}\\binom{100-5}{10-2}}{\\binom{100}{10}} \\approx 0,070219. \\] En R, el resultado anterior se puede conseguir con el siguiente trozo de código. dhyper(x = 2, m = 5, n = 95, k = 10, log = FALSE) #&gt; [1] 0.07021881 La figura 3.8 muestra la gráfica de la función de probabilidad del número de lamparas defectuosas en una muestra de tamaño 10 \\(\\left(X \\right)\\). La cual, como se sabe, tiene distribución hipergeométrica con parámetros \\(m = 5\\), \\(n = 95\\), \\(k = 10\\). Es decir, \\(X \\sim H \\left(m = 5, n = 95, k = 10 \\right)\\). plot_ly(alpha = 0.5) %&gt;% add_segments( x = 0:5, y = ~rep(x = 0, times = length(0:5)), xend = 0:5, yend = ~dhyper( x = 0:5, m = 5, n = 95, k = 10, log = FALSE ), color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;m = 5, n = 95, k = 10&quot; ) %&gt;% add_markers( x = 0:5, y = ~dhyper( x = 0:5, m = 5, n = 95, k = 10, log = FALSE ), color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;m = 5, n = 95, k = 10&quot; ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;p(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.8: Gráfica de la función de probabilidad hipergeométrica para \\(m = 5\\), \\(n = 95\\) y \\(k = 5\\) 3.7.2.1 Función de Distribución Acumulativa de Probabilidad Hipergeométrica La probabilidad de que en una muestra de tamaño \\(k\\), la cual ha sido extraída sin remplazo de una población constituida por \\(m\\) objetos que poseen una característica de interés y \\(n\\) que no la poseen, a lo más \\(x\\) objetos tengan la característica de interés representa la función de distribución acumulativa de una variable aleatoria con distribución hipergeométrica. Ésta función, de acuerdo con las definiciones 3.6 y 3.12, se enuncia de la siguiente manera: Definición 3.13 (Función de Distribución Acumulativa de Probabilidad Hipergeométrica) Sea \\(X\\) una variable aleatoria con distribución hipergeométrica. Entonces, la función de distribución acumulativa de probabilidad hipergeométrica viene dada por: \\[ F\\left ( x;n,p \\right )=\\begin{cases} 0 &amp; \\text{ si } x &lt; \\mathrm{máx} \\left\\{0, k - n \\right\\}\\\\ \\sum_{t=\\mathrm{máx} \\left\\{0, k - n \\right\\} }^{x } \\frac{\\binom{m}{t}\\binom{n}{k-t}}{\\binom{m+n}{k}} &amp; \\text{ si } x= \\mathrm{máx} \\left\\{0, k - n \\right\\} \\leq x \\leq \\mathrm{mín} \\left\\{k, m \\right\\}\\\\ 1 &amp; \\text{ si } x &gt; \\mathrm{mín} \\left\\{k, m \\right\\}. \\tag{3.22} \\end{cases} \\] La figura 3.9 muestra la función de distribución acumulativa de probabilidad para una variable hipergeométrica para distintos valores de los parámetros \\(m\\), \\(n\\) y \\(k\\). La función phyper(q, m, n, k, lower.tail = TRUE, log.p = FALSE) de la distribución base de R permite evaluar la función de distribución acumulativa de probabilidad hipergeométrica dada por la ecuación (3.22). plot_ly(alpha = 0.5) %&gt;% add_segments( x = ~c(first(x1) -3, x1), y = ~phyper( c(first(x1) -3, x1), m = m1, n = n1, k = k1 ), xend = ~c(x1, last(x1) + 3), yend = ~phyper( c(first(x1) -3, x1), m = m1, n = n1, k = k1 ), color = I(&quot;red&quot;), name = &quot;m = 10, n = 90, k = 5&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x1, y = ~phyper(x1, m = m1, n = n1, k = k1), color = I(&quot;red&quot;), name = &quot;m = 10, n = 90, k = 5&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x1, y = ~phyper( c(first(x1) -3, x1[-last(x1)]), m = m1, n = n1, k = k1 ), color = I(&quot;red&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;m = 10, n = 90, k = 5&quot;, showlegend = TRUE ) %&gt;% add_segments( x = ~c(first(x2) -3, x2), y = ~phyper( c(first(x2) -3, x2), m = m2, n = n2, k = k2 ), xend = ~c(x2, last(x2) + 3), yend = ~phyper( c(first(x2) -3, x2), m = m2, n = n2, k = k2 ), color = I(&quot;blue&quot;), name = &quot;m = 10, n = 90, k = 10&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x2, y = ~phyper(x2, m = m2, n = n2, k = k2), color = I(&quot;blue&quot;), name = &quot;m = 10, n = 90, k = 10&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x2, y = ~phyper( c(first(x2) -3, x2[-last(x1)]), m = m2, n = n2, k = k2 ), color = I(&quot;blue&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;m = 10, n = 90, k = 10&quot;, showlegend = TRUE ) %&gt;% add_segments( x = ~c(first(x3) -3, x3), y = ~phyper( c(first(x3) -3, x3), m = m3, n = n3, k = k3 ), xend = ~c(x3, last(x3) + 3), yend = ~phyper( c(first(x3) -3, x3), m = m3, n = n3, k = k3 ), color = I(&quot;green&quot;), name = &quot;m = 10, n = 90, k = 15&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x3, y = ~phyper(x3, m = m3, n = n3, k = k3), color = I(&quot;green&quot;), name = &quot;m = 10, n = 90, k = 15&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~x3, y = ~phyper( c(first(x3) -3, x3[-last(x3)]), m = m3, n = n3, k = k3 ), color = I(&quot;green&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;m = 10, n = 90, k = 15&quot;, showlegend = TRUE ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;F(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.9: Gráfica de la función de distribución acumulativa de probabilidad hipergeométrica para \\(m = 10\\) y \\(n = 90\\) y \\(k = 5, 10, 15\\) Ejemplo 3.12 (Función de Distribución Acumulativa de Probabilidad Hipergeométrica) Suponga en el ejemplo 3.11 que se desea determinar la probabilidad de que en una muestra aparezcan menos de dos lamparas defectuosas. La probabilidad de que en la muestra aparezcan menos de dos lamparas defectuosas es: \\[ \\begin{align*} P \\left(X &lt; 2 \\right) =&amp; P \\left(X \\leq 1 \\right)= F \\left( x = 1;m = 5,n = 95, k = 10 \\right) = \\sum_{t=0 }^{x } \\frac{\\binom{5}{t}\\binom{95}{5-t}}{\\binom{5+95}{10}}\\\\ =&amp; \\frac{\\binom{5}{0}\\binom{95}{5}}{\\binom{100}{10}}+ \\frac{\\binom{5}{1}\\binom{95}{4}}{\\binom{100}{10}}\\\\ \\approx &amp; 0,923143. \\end{align*} \\] El siguiente script de R permite obtener el resultado anterior. phyper( q = 1, m = 5, n = 95, k = 10, lower.tail = TRUE, log.p = FALSE ) #&gt; [1] 0.9231433 La figura 3.10 muestra la gráfica de la función de distribución acumulativa del número de lamparas defectuosas en una muestra de tamaño 10 (\\(X\\)). La cual, como se sabe, tiene distribución hipergeométrica con parámetros \\(m = 5\\), \\(n = 95\\), \\(k = 10\\). Es decir, \\(X \\sim H \\left(m = 5, n = 95, k = 10 \\right)\\). plot_ly(alpha = 0.5) %&gt;% add_segments( x = ~c(-3, 0:5), y = ~phyper(c(-3, 0:5), m = 5, n = 95, k = 10), xend = ~c(0:5, 8), yend = ~phyper(c(-3, 0:5), m = 5, n = 95, k = 10), color = I(&quot;red&quot;), name = &quot;m = 5, n = 95, k = 10&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~0:5, y = ~phyper(0:5, m = 5, n = 95, k = 10), color = I(&quot;red&quot;), name = &quot;m = 5, n = 95, k = 10&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~c(0:5), y = ~phyper(c(-3, 0:4), m = 5, n = 95, k = 10), color = I(&quot;black&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;m = 5, n = 95, k = 10&quot;, showlegend = TRUE ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;F(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.10: Gráfica de la función de distribución acumulativa de probabilidad hipergeométrica para \\(m = 5\\), \\(n = 95\\) y \\(k = 10\\) La tabla 3.4 muestra la función de probabilidad y la función de distribución acumulativa de probabilidad de una variable hipergeométrica con parámetros \\(m = 5\\), \\(n = 95\\) y \\(k = 10\\). da_ej2 &lt;- data.frame( x = 0:5, px = dhyper(x = 0:5, m = 5, n = 95, k = 10, log = FALSE), Fx = phyper( q = 0:5, m = 5, n = 95, k = 10, lower.tail = TRUE, log.p = FALSE ) ) knitr::kable( da_ej2, booktabs = TRUE, row.names = TRUE, digits = 4, col.names = c( &quot;$X_i$&quot;, &quot;$p\\\\left(x_i \\\\right)$&quot;, &quot;$F\\\\left(x_i \\\\right)$&quot; ), align = c(&quot;ccc&quot;), format.args = list(decimal.mark = &quot;,&quot;, big.mark = &quot;.&quot;), caption = &quot;\\\\label{tab2:distribucion-acumulada2}Función de probabilidad y función de distribución acumulativa de $X \\\\sim H \\\\left(m = 5, n = 95, k= 10 \\\\right)$&quot;, escape = FALSE ) %&gt;% kable_styling( bootstrap_options = &quot;striped&quot;, full_width = FALSE, fixed_thead = T ) %&gt;% kable_classic_2() Tabla 3.4: Función de probabilidad y función de distribución acumulativa de \\(X \\sim H \\left(m = 5, n = 95, k= 10 \\right)\\) \\(X_i\\) \\(p\\left(x_i \\right)\\) \\(F\\left(x_i \\right)\\) 1 0 0,5838 0,5838 2 1 0,3394 0,9231 3 2 0,0702 0,9934 4 3 0,0064 0,9997 5 4 0,0003 1,0000 6 5 0,0000 1,0000 3.7.2.2 Media de la Distribución Hipergeométrica La media, promedio o esperanza matemática de la distribución hipergeométrica es el número de objetos con la característica de interés, que se espera, aparezcan en una muestra de tamaño \\(k\\), la cual ha sido extraída de una población que contiene \\(m\\) objetos que poseen la característica de interés mientras que el resto \\(n\\) no posee tal característica. De manera formal, esto se expresa de la siguiente manera: Teorema 3.9 (Media de la Distribución Hipergeoétrica) Sea \\(X\\) una variable aleatoria con distribución hipergeométrica. Entonces, la media de \\(X\\) viene dada por: \\[ \\begin{equation} E \\left(X \\right)= \\mu = \\frac{mk}{m+n}. \\tag{3.23} \\end{equation} \\] Demostración (Media de la Distribución Hipergeométrica). Note que en la función de probabilidad de la distribución hipergeométrica, dada por la ecuación (3.21), los valores mínimos y máximos del recorrido de la variable dependen de los parámetros \\(m\\), \\(n\\) y \\(k\\). En tal sentido se hará una demostración parcial del teorema suponiendo que \\(n &gt; k\\) y \\(m &gt; k\\). Como consecuencia de estas suposiciones la función de probabilidad hipergeométrica estaría dada de la siguiente manera: \\[ p\\left ( x;m,n, k \\right )=\\begin{cases} \\frac{\\binom{m}{x}\\binom{n}{k-x}}{\\binom{m+n}{k}} &amp; \\text{ si } x= 0, 1, 2, \\dotsc, k \\\\ 0 &amp; \\text{ en cualquier otro caso }. \\tag{3.24} \\end{cases} \\] Luego, por las definición de esperanza matemática 3.7 y la función de probabilidad hipergeométrica, que en ete caso se reduce a la ecuación (3.24), la esperanza de una variable \\(X\\) con distribución hipergeométrica, bajo las condiciones dadas se obtiene como sigue. \\[ \\begin{align*} E \\left(X \\right) =&amp; \\sum_{x=0}^{k } x\\frac{\\binom{m}{x}\\binom{n}{k-x}}{\\binom{m+n}{k}}\\\\ =&amp; \\sum_{x=1}^{k } x \\frac{\\frac{m!}{x!\\left ( m-x \\right )!}\\binom{n}{k-x}}{\\binom{m+n}{k}}\\\\ =&amp; m\\sum_{x=1}^{k } \\frac{\\frac{(m-1)!}{(x-1)!\\left ( m-x \\right )!}\\binom{n}{k-x}}{\\binom{m+n}{k}}\\\\ =&amp; m\\sum_{x=1}^{k } \\frac{\\binom{m-1}{x-1}\\binom{n}{k-x}}{\\binom{m+n}{k}}.\\\\ \\end{align*} \\] Como puede demostrarse que: \\[ \\binom{m+n}{k}=\\frac{m+n}{k}\\binom{m+n-1}{k-1}. \\] Entonces, \\[ \\begin{align*} E \\left(X \\right) =&amp; \\frac{m}{\\frac{m+n}{k}}\\sum_{x=1}^{k } \\frac{\\binom{m-1}{x-1}\\binom{n}{k-x}}{\\binom{m+n-1}{k-1}}.\\\\ \\end{align*} \\] Si \\(r=k-1\\), \\(s=m-1\\) y \\(y=x-1\\), entonces: \\[ \\begin{align*} E \\left(X \\right) =&amp; \\frac{mk}{m+n}\\sum_{y=0}^{r } \\frac{\\binom{s}{y}\\binom{n}{r-y}}{\\binom{s+n}{r}}.\\\\ \\end{align*} \\] La suma es igual dado dado que es la suma de una función de probabilidad hipergeométrica con parámetros \\(s\\), \\(n\\) y \\(r\\). Por lo que quea demostrado que, \\[ \\begin{align*} E \\left(X \\right) =&amp; \\frac{mk}{m+n}.\\\\ \\end{align*} \\] Esta demostración se ha realizado ajo las restricción de los parámetros expuesta al principio, se deja como ejercicio al estudiante demostrar para los demás casos. Ejemplo 3.13 (Media de la Distribución Binomial) Con respecto al el ejemplo 3.11, determine el número de lamparas defectuosas que se esperaría encontrar en una muestra de de 10 de estas lamparas. De acuerdo con el teorema 3.9, se esperaría encontrar \\[ \\begin{align*} E \\left(X \\right) =&amp; \\frac{mk}{m+n}=\\frac{5 \\cdot 10}{5+95}=0,5.\\\\ \\end{align*} \\] Ahora, si se toma una muestra de 60 lamparas (\\(k=60\\)) del lote, se esperaría encontrar \\[ \\begin{align*} E \\left(X \\right) =&amp; \\frac{mk}{m+n}=\\frac{5 \\cdot 60}{5+95}=3.\\\\ \\end{align*} \\] lamparas defectuosos en la muestra. 3.7.2.3 Varianza de la Distribución Hipergeométrica La varianza de una variable aleatoria es una medida absoluta de la dispersión de esta. En el caso de que la variable aleatoria sea hipergeométrica, la medida de esa dispersión se expresa en siguiente teorema: Teorema 3.10 (Varianza de la Distribución Hipergeométrica) Sea \\(X\\) una variable aleatoria con distribución hipergeométrica. Entonces, la varianza de \\(X\\) viene dada por: \\[ \\begin{equation} V \\left(X \\right)=\\sigma^2 = \\frac{mkn\\left(m+n-k\\right)}{\\left(m+n \\right)^2\\left(m+n-1 \\right) }. \\tag{3.25} \\end{equation} \\] Demostración (varianza de la Distribución Hipergeométrica). La demostración de este teorema, al igual que en el teorema de la media de la distribución hipergeométrica 3.9, se hará asumiendo que \\(n &gt; k\\) y \\(m &gt; k\\). La demostración en los otros casos se deja como ejercicio al lector. De la ecución (3.12) se sabe que \\(V \\left(X \\right) = E \\left(X^2 \\right) - \\mu^2\\). Como \\(\\mu=\\frac{mk}{m+n}\\), solo faltaría calcular \\(E \\left(X^2 \\right)\\). Pero calcular este parámetro usando el teorema 3.1 y la función de probabilidad, que para este caso está dada por la ecuación (3.24) implica encontrar la convergencia de la siguiente expresión \\[ \\begin{align*} E \\left(X^2 \\right) =&amp; \\sum_{x=0}^{k } x^2\\frac{\\binom{m}{x}\\binom{n}{k-x}}{\\binom{m+n}{k}},\\\\ \\end{align*} \\] lo cual es sumamente complicado, por decir lo menos. En lugar de este camino, se elegirá un método alterno. La alternativa es escribir \\(x^2\\) como: \\[ x^2= x \\left(x-1 \\right)+x; \\] de esta manera, por los teoremas 3.1 y 3.3, se tiene: \\[ \\begin{equation} E \\left(X^2 \\right)= E \\left[X \\left(X-1 \\right) \\right]+E \\left(X \\right). \\tag{3.19} \\end{equation} \\] Dado que \\(E \\left(X \\right)\\) ya se ha determinado, faltaría determinar \\(E \\left[x \\left(x-1 \\right) \\right]\\), que según el teorema 3.1, es: \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp; \\sum_{x=0}^{k } x \\left(x-1 \\right)\\frac{\\binom{m}{x}\\binom{n}{k-x}}{\\binom{m+n}{k}}\\\\ =&amp; \\sum_{x=2}^{k } x \\left(x-1 \\right)\\frac{\\frac{m!}{x!\\left ( m-x \\right )!}\\binom{n}{k-x}}{\\binom{m+n}{k}}\\\\ =&amp; \\sum_{x=2}^{k } x \\left(x-1 \\right)\\frac{\\frac{m\\left(m-1 \\right)\\left(m-2 \\right)!}{x\\left(x-1 \\right)\\left(x-2 \\right)!\\left ( m-x \\right )!}\\binom{n}{k-x}}{\\binom{m+n}{k}}.\\\\ \\end{align*} \\] Por lo que, cancelando los factores \\(x\\left(x-1 \\right)\\) , lo anterior se puede reescribir de la siguiente manera: \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp; \\sum_{x=2}^{k } \\frac{\\frac{m\\left(m-1 \\right)\\left(m-2 \\right)!}{\\left(x-2 \\right)!\\left ( m-x \\right )!}\\binom{n}{k-x}}{\\binom{m+n}{k}}.\\\\ \\end{align*} \\] Se puede demostrar de manera fácil que, \\[ \\binom{m+n}{k}=\\left( \\frac{m+n}{k} \\right)\\left( \\frac{m+n-1}{k-1} \\right)\\binom{m+n-2}{k-2}. \\] En consecuencia, \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp; \\sum_{x=2}^{k }\\frac{\\frac{m\\left(m-1 \\right)\\left(m-2 \\right)!}{\\left(x-2 \\right)!\\left ( m-x \\right )!}\\binom{n}{k-x}}{\\left( \\frac{m+n}{k} \\right)\\left( \\frac{m+n-1}{k-1} \\right)\\binom{m+n-2}{k-2}}.\\\\ \\end{align*} \\] Luego, factorizando \\[ \\frac{m\\left(m-1 \\right)}{\\left( \\frac{m+n}{k} \\right)\\left( \\frac{m+n-1}{k-1} \\right)}, \\] resulta \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp; \\frac{m\\left(m-1 \\right)}{\\left( \\frac{m+n}{k} \\right)\\left( \\frac{m+n-1}{k-1} \\right)}\\sum_{x=2}^{k }\\frac{\\frac{\\left(m-2 \\right)!}{\\left(x-2 \\right)!\\left ( m-x \\right )!}\\binom{n}{k-x}}{\\binom{m+n-2}{k-2}}.\\\\ \\end{align*} \\] Si \\(r=k-2\\), \\(s=m-2\\) y \\(y=x-2\\), entonces: \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp; \\frac{m\\left(m-1 \\right)}{\\left( \\frac{m+n}{k} \\right)\\left( \\frac{m+n-1}{k-1} \\right)}\\sum_{y=0}^{r }\\frac{\\frac{s!}{y!\\left ( s-y \\right )!}\\binom{n}{r-y}}{\\binom{s+n}{r}}.\\\\ \\end{align*} \\] Como \\[ \\binom{s}{y}=\\frac{s!}{y! \\left( s-y \\right )!}, \\] Entonces, \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp; \\frac{m\\left(m-1 \\right)}{\\left( \\frac{m+n}{k} \\right)\\left( \\frac{m+n-1}{k-1} \\right)}\\sum_{y=0}^{r }\\frac{\\binom{s}{y}\\binom{n}{r-y}}{\\binom{s+n}{r}}.\\\\ \\end{align*} \\] Pero, \\[ p \\left(y; s, n, r\\right)= \\frac{\\binom{s}{y}\\binom{n}{r-y}}{\\binom{s+n}{r}} \\] es la función de probabilidad de una variable aleatoria hipergeométrica \\(Y\\) con parámetros \\(s\\), \\(n\\) y \\(r\\); de esta manera \\(\\sum_{y=0}^{r }p\\left(y; s, n, r \\right)=1\\). En consecuencia, \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp; \\frac{m\\left(m-1 \\right)}{\\left( \\frac{m+n}{k} \\right)\\left( \\frac{m+n-1}{k-1} \\right)}\\\\ =&amp; \\frac{mk\\left(m-1 \\right)\\left(k-1 \\right)}{\\left(m+n \\right)\\left(m+n-1 \\right)}\\\\ \\end{align*} \\] De la ecuación (3.19) \\[ E \\left(X^2 \\right)= \\frac{mk\\left(m-1 \\right)\\left(k-1 \\right)}{\\left(m+n \\right)\\left(m+n-1 \\right)}+\\frac{mk}{m+n}. \\] De esta manera, la varianza de una variable aleatoria binomial, según la ecuación (3.12) es: \\[ \\begin{align*} V(X)=&amp;\\frac{mk\\left(m-1 \\right)\\left(k-1 \\right)}{\\left(m+n \\right)\\left(m+n-1 \\right)}+\\frac{mk}{m+n}-\\left(\\frac{mk}{m+n} \\right)^2\\\\ =&amp;\\frac{mk\\left(m+n \\right)\\left(m-1 \\right)\\left(k-1 \\right)+mk\\left(m+n \\right)\\left(m+n-1 \\right)-m^2k^2\\left(m+n-1 \\right)}{\\left(m+n \\right)^2\\left(m+n-1 \\right)}\\\\ =&amp;\\frac{km^2n+kmn^2-^2mn}{\\left(m+n \\right)^2\\left(m+n-1 \\right)}\\\\ =&amp;\\frac{kmn\\left(m+n-k \\right)}{\\left(m+n \\right)^2\\left(m+n-1 \\right)}\\\\ \\end{align*} \\] Ejemplo 3.10 (Varianza de la Distribución Hipergeométrica) Con respecto al ejemplo 3.7, determine la varianza del número de lamparas defectuosas. De acuerdo con el teorema 3.10, la varianza de \\(X\\) es: \\[ \\begin{align*} V(X)=&amp;\\frac{kmn\\left(m+n-k \\right)}{\\left(m+n \\right)^2\\left(m+n-1 \\right)}=\\frac{10 \\cdot 5 \\cdot 95\\left(5+95-10 \\right)}{\\left(5+95 \\right)^2\\left(5+95-1 \\right)}\\\\ =&amp;\\frac{171}{392} \\approx0,4362. \\end{align*} \\] Otra forma de obtener la media y la varianza es a través de la función generadora de momentos de la distribución hipergeométrica, pero dado las dificultades que implica la derivación de esta función para la distribución en cuestión, no se considerará en este libro. 3.7.3 Distribució de Poisson La distribución de Poisson debe su nombre a Simeón Denis Poisson, probabilista francés del siglo XIX quien fue el primero en describirla. Es una distribución discreta de probabilidad muy útil ya que se aplica para describir la ocurrencia de fenómenos que ocurren a una tasa constante en el tiempo o en el espacio. La presentación formal de esta distribución se probabilidad se describe en el siguiente teorema. Definición 3.14 (Distribución de Poisson) Sea \\(X\\) una variable aleatoria que representa el número de eventos aleatorios independientes que ocurren a una rapidez constante \\(\\lambda\\) sobre el tiempo o el espacio. Se dice entonces que una variable \\(X\\) tiene distribución de Poisson con función de probabilidad \\[ p\\left ( x;\\lambda \\right )=\\begin{cases} \\frac{e^{-\\lambda}\\lambda^x}{x!} &amp; \\text{ si } x= 0, 1, 2, \\dotsc;\\: \\lambda&gt;0 \\\\ 0 &amp; \\text{ en cualquier otro caso }. \\tag{3.26} \\end{cases} \\] La función dpois(x, lambda, log = FALSE) de la distribución base de R permite evaluar la función de probabilidad de Poisson, dada en la ecuación (3.26). El parámetro \\(\\lambda\\) define una familia de distribuciones de probabilidad con una función de probabilidad determinada por la ecuación (3.26). En la figura 3.11 se proporcionan algunas gráficas de la función de probabilidad de Poisson, para distintos valores de \\(\\lambda=1, 5, 10\\): plot_ly(alpha = 0.5) %&gt;% add_segments( x = ~c(0:20), y = ~rep(x = 0, times = 21), xend = ~c(0:20), yend = ~dpois(x = 0:20, lambda = 1, log = FALSE), color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;lambda = 1&quot; ) %&gt;% add_markers( x = ~c(0:20), y = ~dpois(x = 0:20, lambda = 1, log = FALSE), color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;lambda = 1&quot; ) %&gt;% add_segments( x = ~c(0:20), y = ~rep(x = 0, times = 21), xend = ~c(0:20), yend = ~dpois(x = 0:20, lambda = 5, log = FALSE), color = I(&quot;blue&quot;), showlegend = TRUE, name = &quot;lambda = 5&quot; ) %&gt;% add_markers( x = ~c(0:20), y = ~dpois(x = 0:20, lambda = 5, log = FALSE), color = I(&quot;blue&quot;), showlegend = TRUE, name = &quot;lambda = 5&quot; ) %&gt;% add_segments( x = ~c(0:20), y = ~rep(x = 0, times = 21), xend = ~c(0:20), yend = ~dpois(x = 0:20, lambda = 10, log = FALSE), color = I(&quot;green&quot;), showlegend = TRUE, name = &quot;lambda = 10&quot; ) %&gt;% add_markers( x = ~c(0:20), y = ~dpois(x = 0:20, lambda = 10, log = FALSE), color = I(&quot;green&quot;), showlegend = TRUE, name = &quot;lambda = 10&quot; ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;p(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.11: Gráfica de la función de probabilidad de Poisson para \\(\\lambda = 1, 5, 10\\) La distribución de Poisson es asimétrica negativa, es decir es muy raro que ocurran valores grandes de la variable, es decir, las probabilidades asociadas a estos eventos tiende a cero en la medida de que la variable tiende a infinito. Lo anterior mente expuesto se observa en la gráfica 3.11. También, se puede observar e esta gráfica que la distribución de Poisson tiende a ser simétrica en la medida que el parámetro \\(\\lambda\\) aumenta. Ejemplo 3.14 (Función de Probabilidad de Poison) después de una prueba de laboratorio muy rigorosa con cierto componente eléctrico, el fabricante determina que en promedio, sólo fallarán dos componentes antes de tener 1.000 horas de operación. Un comprador observa que son cinco los que fallan antes de las 1.000 horas. Si el número de componentes que fallan es una variable aleatoria de Poisson, ¿existe suficiente evidencia para dudar de la conclusión del fabricante? La duda estadística puede apoyarse en términos de la probabilidad. Si un evento debe o no ocurrir bajo ciertas condiciones, su ocurrencia se decide en términos de la probabilidad del evento bajo esas condiciones. Si la probabilidad de ocurrencia es pequeña y el evento ocurre, entonces se puede preguntar, con justificación, por las condiciones. Al mismo tiempo debe tenerse en mente que un valor de probabilidad pequeño no impide la ocurrencia del evento, a menos que este valor sea cero. En dicho caso, se tiene que \\(\\lambda = 2\\). Se supone que la frecuencia con que ocurren las fallas es constante e igual a dos cada mil hora o un promedio de 1/500 unidades por hora. La probabilidad de que fallen cinco componentes en mil horas es, según la ecuación (3.26), \\[ P\\left(X = 5 \\right)=p\\left ( x = 5;\\lambda =2 \\right )=\\frac{e^{-2}\\lambda^5}{5!}= \\approx 0,036089. \\] Dado que la probabilidad de que cinco componentes fallen en 1.000 horas es una probabilidad bastante pequeña, no se esperaría que esto ocurriera en la primera réplica del experimento, a menos que en realidad su probabilidad de ocurrencia fuera mucho mayor que la que se obtuvo, y esto solo es posible si la tasa de falla fuera mayor que la indicada. Dicho de otra manera, el resultado experimental obtenido aporta información para pensar que la tasa de falla es mayor de 2 por cada 1.000 horas. En R, el cálculo anterior se puede conseguir con el siguinte bloque de código. dpois(x = 5, lambda = 2, log = FALSE) #&gt; [1] 0.03608941 La figura 3.12 muestra la gráfica de la función de probabilidad del número de unidades que fallan en un tiempo de 100 horas \\(\\left(X \\right)\\). La cual, bajo las condiciones expuestas en el ejemplo, tiene distribución de Poisson con parámetros \\(\\lambda = 2\\). Es decir, \\(X \\sim P \\left(\\lambda = 2\\right)\\). plot_ly(alpha = 0.5) %&gt;% add_segments( x = 0:10, y = ~rep(x = 0, times = length(0:10)), xend = 0:10, yend = ~dpois(x = 0:10, lambda = 2, log = FALSE), color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;lambda = 2&quot; ) %&gt;% add_markers( x = 0:10, y = ~dpois(x = 0:10, lambda = 2, log = FALSE), color = I(&quot;red&quot;), showlegend = TRUE, name = &quot;lambda = 2&quot; ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;p(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &#39;black&#39;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.12: Gráfica de la función de probabilidad binomial para \\(n = 15\\) y \\(p = 0,05\\) 3.7.3.1 Función de Distribución Acumulativa de Probabilidad de Poisson De acuerdo con las definiciones 3.6 y 3.14 la función de distribución acumulativa de probabilidad de una variable aleatoria con distribución de Poisson se formaliza en el siguiente teorema: Definición 3.11 (Función de Distribución Acumulativa de Probabilidad Binomial) Sea \\(X\\) una variable aleatoria con distribución de Poisson. Entonces, la función de distribución acumulativa de probabilidad de poisson viene dada por: \\[ F\\left ( x;\\lambda \\right )=\\begin{cases} 0 &amp; \\text{ si } x &lt; 0\\\\ e^{-\\lambda}\\sum_{t=0}^{x }\\frac{\\lambda^t}{t!} &amp; \\text{ si } x= 0, 1, 2, \\dotsc;\\: \\lambda&gt;0 \\tag{3.27} \\end{cases} \\] La función ppois(q, lambda, lower.tail = TRUE, log.p = FALSE) de la distribución base de R permite evaluar la función de distribución acumulativa de probabilidad de Poisson dada en la ecuación (3.27). La figura 3.13 muestra la función de distribución acumulativa de probabilidad para una variable Poisson con parámetros \\(\\lambda = 1, 5, 10\\). x &lt;- c(-3, 0:20, 23) Fx1 &lt;- ppois( q = x, lambda = 1, lower.tail = TRUE, log.p = FALSE ) Fx2 &lt;- ppois( q = x, lambda = 5, lower.tail = TRUE, log.p = FALSE ) Fx3 &lt;- ppois( q = x, lambda = 10, lower.tail = TRUE, log.p = FALSE ) plot_ly(x = x, y = Fx1, alpha = 0.5) %&gt;% add_segments( x = ~ x[-length(x)], y = ~ Fx1[-length(x)], xend = ~ x[-1], yend = ~ Fx1[-length(x)], color = I(&quot;red&quot;), name = &quot;lambda = 1&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~ x[-c(1, length(x))], y = ~ Fx1[-c(1, length(x))], color = I(&quot;red&quot;), name = &quot;Lambda = 1&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~ x[-c(1, length(x))], y = ~ Fx1[-c(length(x) - 1, length(x))], color = I(&quot;red&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;lambda = 1&quot;, showlegend = TRUE ) %&gt;% add_segments( x = ~ x[-length(x)], y = ~ Fx2[-length(x)], xend = ~ x[-1], yend = ~ Fx2[-length(x)], color = I(&quot;blue&quot;), name = &quot;lambda = 5&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~ x[-c(1, length(x))], y = ~ Fx2[-c(1, length(x))], color = I(&quot;blue&quot;), name = &quot;Lambda = 5&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~ x[-c(1, length(x))], y = ~ Fx2[-c(length(x) - 1, length(x))], color = I(&quot;blue&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;lambda = 5&quot;, showlegend = TRUE ) %&gt;% add_segments( x = ~ x[-length(x)], y = ~ Fx3[-length(x)], xend = ~ x[-1], yend = ~ Fx3[-length(x)], color = I(&quot;green&quot;), name = &quot;lambda = 10&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~ x[-c(1, length(x))], y = ~ Fx3[-c(1, length(x))], color = I(&quot;green&quot;), name = &quot;Lambda = 10&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~ x[-c(1, length(x))], y = ~ Fx3[-c(length(x) - 1, length(x))], color = I(&quot;green&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;lambda = 10&quot;, showlegend = TRUE ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &quot;black&quot;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;F(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &quot;black&quot;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.13: Gráfica de la función de distribución acumulativa de probabilidad de Poisson para \\(\\lambda = 1, 5, 10\\) Ejemplo 3.8 (Función de Distribución Acumulativa de Probabilidad de Poisson) Determine en el ejemplo 3.14 la probabilidad de que por lo menos fallen cinco componentes en 1.000 horas. La probabilidad de que al menos cinco componentes fallen en 1.000 horas, según la función de distribución acumulativa de probabilidad de Poisson dada por la ecuación (3.27) para \\(\\lambda = 2\\), es: \\[ \\begin{align*} P \\left(X \\geq 5 \\right) =&amp; 1 - P \\left(X \\leq 4 \\right)= 1 - F \\left( x = 4;\\lambda =2 \\right ) = 1 - e^{-\\lambda}\\sum_{t=0}^{4}\\frac{2^t}{t!}\\\\ =&amp;1 - e^{-2}\\left[ \\frac{2^0}{0!} + \\frac{2^1}{1!} + \\frac{2^2}{2!} + \\frac{2^3}{3!} + \\frac{2^4}{4!} \\right] \\\\ =&amp;1 - 0.947347 \\\\ \\approx &amp; 0.052653. \\end{align*} \\] En R, el resultado anterior se puede obtener con el siguiente script. 1 - ppois(q = 4, lambda = 2, lower.tail = TRUE, log.p = FALSE) #&gt; [1] 0.05265302 La figura 3.14 muestra la gráfica de la función de distribución acumulativa de probabilidad del número de componentes que fallan en 1.000 horas si la tasa de falla es de dos en ese intervalo de tiempo. x &lt;- c(-3, 0:10, 13) Fx &lt;- ppois( q = x, lambda = 2, lower.tail = TRUE, log.p = FALSE ) plot_ly(x = x, y = Fx1, alpha = 0.5) %&gt;% add_segments( x = ~ x[-length(x)], y = ~ Fx[-length(x)], xend = ~ x[-1], yend = ~ Fx[-length(x)], color = I(&quot;red&quot;), name = &quot;lambda = 2&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~ x[-c(1, length(x))], y = ~ Fx[-c(1, length(x))], color = I(&quot;red&quot;), name = &quot;Lambda = 2&quot;, showlegend = TRUE ) %&gt;% add_markers( x = ~ x[-c(1, length(x))], y = ~ Fx[-c(length(x) - 1, length(x))], color = I(&quot;red&quot;), marker = list(symbol = &quot;circle-open&quot;), name = &quot;lambda = 1&quot;, showlegend = TRUE ) %&gt;% layout( xaxis = list( title = &quot;x&quot;, zeroline = F, showgrid = T, showline = T, linewidth = 1, linecolor = &quot;black&quot;, showticklabels = TRUE, tickwidth = 0.5 ), yaxis = list( title = &quot;F(x)&quot;, showgrid = T, showline = T, linewidth = 1, linecolor = &quot;black&quot;, showticklabels = TRUE, tickwidth = 0.5 ), showlegend = TRUE ) %&gt;% config(locale = &quot;es&quot;) Figura 3.14: Gráfica de la función de distribución acumulativa de probabilidad de Poisson para \\(\\lambda = 2\\) La tabla ?? muestra la función de probabilidad y la función de distribución acumulativa de probabilidad de una variable de Poisson con parámetro \\(\\lambda = 2\\). da_ej3 &lt;- data.frame( x = 0:10, px = dpois(x = 0:10, lambda = 2, log = FALSE), Fx = ppois( q = 0:10, lambda = 2, lower.tail = TRUE, log.p = FALSE ) ) knitr::kable( da_ej2, booktabs = TRUE, row.names = TRUE, digits = 4, col.names = c( &quot;$X_i$&quot;, &quot;$p\\\\left(x_i \\\\right)$&quot;, &quot;$F\\\\left(x_i \\\\right)$&quot; ), align = c(&quot;ccc&quot;), format.args = list(decimal.mark = &quot;,&quot;, big.mark = &quot;.&quot;), caption = &quot;\\\\label{tab2:distribucion-acumulada2}Función de probabilidad y función de distribución acumulativa de $X \\\\sim P \\\\left( \\\\lambda = 2 \\\\right)$&quot;, escape = FALSE ) %&gt;% kable_styling( bootstrap_options = &quot;striped&quot;, full_width = FALSE, fixed_thead = T ) %&gt;% kable_classic_2() Tabla 3.5: Función de probabilidad y función de distribución acumulativa de \\(X \\sim P \\left( \\lambda = 2 \\right)\\) \\(X_i\\) \\(p\\left(x_i \\right)\\) \\(F\\left(x_i \\right)\\) 1 0 0,5838 0,5838 2 1 0,3394 0,9231 3 2 0,0702 0,9934 4 3 0,0064 0,9997 5 4 0,0003 1,0000 6 5 0,0000 1,0000 3.7.3.2 Media de la Distribución de Poisson La media, promedio o esperanza matemática de la distribución de Poisson representa el número de éxitos que se espera ocurran en una unidad de muestreo, entendiendo que esta unidad de muestreo puede ser cualquier medida de espacio o tiempo. El siguiente teorema describe la media de la distribución de Poisson. Teorema 3.11 (Media de la Distribución poisson) Sea \\(X\\) una variable aleatoria con distribución de Poisson. Entonces, la media de \\(X\\) viene dada por: \\[ \\begin{equation} E \\left(X \\right)= \\mu = \\lambda. \\tag{3.28} \\end{equation} \\] Demostración (Media de la Distribución de Poisson). Por las definiciones 3.7 y 3.14 la esperanza de una variable \\(X\\) con distribución de Poisson es \\[ \\begin{align*} E \\left(X \\right) =&amp; \\sum_{x=0}^{\\infty } x\\frac{e^{-\\lambda}\\lambda^x}{x!}\\\\ =&amp; \\sum_{x=1}^{\\infty } x\\frac{e^{-\\lambda}\\lambda^x}{x \\left(x-1 \\right)!}\\\\ =&amp; \\sum_{x=1}^{\\infty } \\frac{e^{-\\lambda}\\lambda^x}{ \\left(x-1 \\right)!},\\\\ \\end{align*} \\] en donde se ha escrito la suma desde uno hasta \\(\\infty\\), dado que cuando \\(x=0\\) el primer término es cero y se cancela la \\(x\\) del numerador con la \\(x\\) en \\(x!\\). Luego, factorizando \\(\\lambda\\), se tiene: \\[ \\begin{align*} E \\left(X \\right) =&amp;\\lambda \\sum_{x=1}^{\\infty } \\frac{e^{-\\lambda}\\lambda^{x-1}}{ \\left(x-1 \\right)!},\\\\ \\end{align*} \\] Si \\(y=x-1\\), entonces: \\[ \\begin{align*} E \\left(X \\right) =&amp;\\lambda \\sum_{y=0}^{\\infty } \\frac{e^{-\\lambda}\\lambda^{y}}{ y!},\\\\ \\end{align*} \\] Pero \\(p \\left(y; \\lambda \\right)= e^{-\\lambda}\\lambda^{y}/ y!\\) es la función de probabilidad de una variable aleatoria binomial \\(Y\\) con parámetro \\(\\lambda\\); de esta manera \\(\\sum_{y=0}^{\\infty}p\\left(y; m, p \\right)=1\\), y la media de una variable aleatoria de Poisson es: \\[ \\begin{equation} E \\left(X \\right) = \\lambda. \\end{equation} \\] Ejemplo 3.15 (Media de la Distribución de Poisson) Con respecto al el ejemplo 3.14, determine el número de componentes que se esperaría fallen en un tiempo de 1.000 horas. De acuerdo con el teorema 3.11, el número de componentes que se esperaría fallen es \\[ \\begin{equation} E \\left(X \\right) = \\lambda=2. \\end{equation} \\] 3.7.3.3 Varianza de la Distribución de Poisson La varianza de una variable aleatoria de Poisson \\(X\\) viene dada por el siguiente teorema: Teorema 3.7 (Varianza de la Distribución de Poisson) Sea \\(X\\) una variable aleatoria con distribución de Poisson. Entonces, la varianza de \\(X\\) viene dada por: \\[ \\begin{equation} V \\left(X \\right)=\\sigma^2 =\\lambda. \\tag{3.29} \\end{equation} \\] Demostración (Varianza de la Distribución de Poisson). De la ecuación (3.12) se sabe que \\(V \\left(X \\right) = E \\left(X^2 \\right) - \\mu^2\\). Como \\(\\mu=\\lambda\\), solo faltaría calcular \\(E \\left(X^2 \\right)\\). Pero calcular este parámetro usando el teorema 3.1 y la definición 3.14 implica encontrar la convergencia de la siguiente expresión \\[ E \\left(X^2 \\right) = \\sum_{x=0}^{\\infty} x^2\\frac{e^{-\\lambda}\\lambda^x}{x !}, \\] lo cual es imposible. En lugar de este camino, se elegirá un método alterno. La alternativa es escribir \\(x^2\\) como: \\[ x^2= x \\left(x-1 \\right)+x; \\] de esta manera, por los teoremas 3.1 y 3.3, se tiene: \\[ \\begin{equation} E \\left(X^2 \\right)= E \\left[X \\left(X-1 \\right) \\right]+E \\left(X \\right). \\tag{3.19} \\end{equation} \\] Dado que \\(E \\left(X \\right)\\) ya se ha determinado, faltaría determinar \\(E \\left[x \\left(x-1 \\right) \\right]\\), que según el teorema 3.1, es: \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp; \\sum_{x=0}^{\\infty} x \\left(x-1 \\right)\\frac{e^{-\\lambda}\\lambda^x}{x !}\\\\ =&amp; \\sum_{x=2}^{n } x \\left(x-1 \\right)\\frac{e^{-\\lambda}\\lambda^2\\lambda^{x-2}}{x \\left(x-1 \\right)\\left(x-2 \\right) !}\\\\ =&amp; e^{-\\lambda}\\lambda^2 \\sum_{x=2}^{n } \\frac{\\lambda^{x-2}}{\\left(x-2 \\right) !}\\\\. \\end{align*} \\] Note que en los pasos previos se escribió la suma a partir de dos porque los dos primeros términos son cero, se canceló \\(x \\left(x-1 \\right)\\), y se factorizó \\(\\lambda^2\\). Ahora, sea \\(y=x-2\\); entonces: \\[ \\begin{align*} E \\left[X \\left(X-1 \\right) \\right] =&amp;\\lambda^2 \\sum_{y=0}^{\\infty} \\frac{e^{-\\lambda}\\lambda^{y}}{y !}\\\\. \\end{align*} \\] Pero \\(p \\left(y; \\lambda \\right)= e^{-\\lambda}\\lambda^{y}/ y!\\) es la función de probabilidad de una variable aleatoria de Poisson \\(Y\\) con parámetro \\(\\lambda\\); de esta manera \\(\\sum_{y=0}^{\\infty}p\\left(y; m, p \\right)=1\\). Por lo tanto, \\[ \\begin{equation} E \\left[X \\left(X-1 \\right) \\right] =\\lambda^2. \\end{equation} \\] De la ecuación (3.19) \\[ E \\left(X^2 \\right)= \\lambda^2+\\lambda. \\] De esta manera, la varianza de una variable aleatoria de Poisson, según la ecuación (3.12), es: \\[ \\begin{align*} V(X)=&amp; \\lambda^2+\\lambda-\\lambda^2\\\\ =&amp;\\lambda. \\end{align*} \\] Ejemplo 3.10 (Varianza de la Distribución Binomial) Con respecto al ejemplo 3.7, determine la varianza del número de componentes que fallan en dos horas. De acuerdo con el teorema ??, la varianza de \\(X\\) es: \\[ V(X)=\\lambda=2. \\] 3.7.3.4 Función Genradora de Momentos de la Distribución de Poisson La función generadora de momentos de la distribución de Poisson se indica en el siguiente teorea: Teorema 3.12 (Función Generadora de Momentos de la Distribución de Poisson) La función generadora de momentos de la distribución de Poisson se indica en el siguiente teorema: \\[ \\begin{equation} m_x \\left(t \\right)=e^{\\lambda\\left(e^t -1\\right)}. \\tag{3.30} \\end{equation} \\] ::: {#fgm-binomial .proof name=Función Generadora de Momentos de la Distribución de Poisson} De la definiciones 3.14 y 3.9, se obtiene \\[ \\begin{align*} m_x \\left(t \\right)=&amp; \\sum_{x=0}^{\\infty} e^{tx}\\frac{e^{-\\lambda}\\lambda^x}{x !}\\\\ =&amp; e^{-\\lambda} \\sum_{x=0}^{\\infty} \\frac{\\left(\\lambda e^t\\right)^x}{x !}.\\\\ \\end{align*} \\] Por el teorema de Maclaurin, \\[ \\sum_{x=0}^{\\infty} \\frac{\\left(\\lambda e^t\\right)^x}{x !}=e^{\\lambda e^t}. \\] Entonces, \\[ \\begin{align*} m_x \\left(t \\right)=&amp; e^{-\\lambda}e^{\\lambda e^t}\\\\ =&amp; e^{\\left[\\lambda \\left(e^t-1\\right) \\right]}.\\\\ \\end{align*} \\] Del teorema 3.4, la media de la distribución de Poisson es: \\[ \\begin{equation} \\frac{\\mathrm{d}m_{x}\\left ( t \\right )}{\\mathrm{d}t} \\left|\\begin{matrix} \\\\ t=0\\\\ \\end{matrix}={\\mu}^{&#39;}_1=\\mu \\right. \\end{equation} \\] Luego, la primera derivada de la función generadora de momentos de la distribución de Poisson evaluada en 0 determina la media \\[ \\frac{\\mathrm{d}m_{x}\\left ( t \\right )}{\\mathrm{d}t}=\\lambda e^te^{\\left[\\lambda \\left(e^t-1\\right) \\right]}. \\] Ahora, evaluando la primera derivada de la función generadora de momentos en \\(t=0\\), se obtiene la media de la distribución binomial, como sigue: \\[ \\begin{equation} \\frac{\\mathrm{d}m_{x}\\left ( t \\right )}{\\mathrm{d}t} \\left|\\begin{matrix} \\\\ t=0\\\\ \\end{matrix}=\\mu=\\lambda e^0e^{\\left[\\lambda \\left(e^0-1\\right) \\right]}=\\lambda. \\right. \\end{equation} \\] Note que este resultado es el mismo dado en el teorema 3.11. Se deja al lector que halle la varianza de la distribución de Poisson usando el método de la función generadora de momentos. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
