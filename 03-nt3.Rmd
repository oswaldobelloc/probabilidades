

# Disribuciones Discretas de Probabilidades {#dist_disc}

El siguiente bloque de código permite instalar y cargar los paquetes de `r colorize("R", "blue")` que se usaran en esta sección.

```{r cargar-paquetes-nt3, class.source = "watch-out"}
packages <- c(
  "ggplot2", "ggstatsplot", "tidyverse",
  "kableExtra", "plotly"
)
package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})
```

## Variable Aleatoria {#variable-aleatoria}

::: {#variable-aleatoria .definition name="Variable Aleatoria"} 
Sea un experimento aleatorio $\varepsilon$ y $S$ el espacio muestral asociado con el experimento. Una función $X$ que asigna a cada uno de los elementos $s$ de $S$, un número real $X \left(s \right)$, se llama _variable aleatoria_.
:::

### Recorrido de una Variable Aleatoria {#recorrido}

::: {#recorrido .definition name="Recorrido de una Variable Aleatoria"}
Sea $X$ una variable aleatoria, al conjunto de todos los posibles valores de $X$ se llama _recorrido de_ $X$ y se denota $R_X$.
:::

::: {.example #variable-aleatoria name="Variable Aleatoria"}
Suponga que lanzamos dos monedas ($\varepsilon$), los posibles resultados de este experimento aleatorio $S$ será
$$
S=\left\{cc, cs, sc, ss \right\}.
$$
Ahora, sobre este espacio muestra se define la variable aleatoria $X$ como sigue: $X$ es el número de caras obtenidas en los dos lanzamientos. Por lo tanto $X \left(cc \right)=2$, $X \left(cs \right)=X \left(sc \right)=1$, y $X \left(ss \right)=0$.

En este ejemplo $R_X =0,1,2$.
:::

### Variable Aleatoria Discreta {#variable-discreta}

::: {#variable-discreta .definition name="Variable Aleatoria Discreta"}
Sea $X$ una variable aleatoria. Si el número de valores posibles de $X$, es decir $R_X$, es finito o infinito numerable, se llama a $X$ una _variable aleatoria discreta_. Esto es, se pueden anotar los valores de $X$ como $x_1, x_2, \dotsc, x_n, \dots$ En el caso finito la lista termina y en el caso infinito numerable la lista continúa indefinidamente.
:::

::: {.example #variable-discreta name="Variable Aleatoria"}
Considere el experimento aleatorio $\varepsilon$ lanzar una moneda hasta que aparece una cara. En tal caso, el espacio muestral $S$ queda definido por,
$$
S=\left\{c, sc, ssc, sssc, ssssc, \dotsc \right\}.
$$
Si sobre este espacio muestral se define la variable aleatoria $X=\textrm{número de lanzamientos hata que aparece una cara}$. Entonces el recorrido de $X$, es decir $R_X$, viene definido por $R_X=1, 2, 3, \dotsc$. Dado que el recorrido de $X$ es infinito numerable se concluye que $X$ es una variable discreta.

Con respecto al ejemplo \@ref(exm:variable-discreta), la variable aleatoria $X=\textrm{el número de caras obtenidas en los dos lanzamientos}$ es discreta ya que esta toma solo cuatro valores, $R_X =\left\{0, 1, 2 \right\}$. Es decir, el recorrido de $X$ es finito.
:::

### Variable Aleatoria Continua {#variable-continua}

::: {#variable-continua .definition name="Variable Aleatoria Continua"}
Se dice que una _variable aleatoria es continua_ si su recorrido $R_X$ consiste en uno o más intervalos de la recta de los reales.

:::

::: {.example #variable-continua name="Variable Aleatoria Continua"}
Se selecciona de manera aleatoria un punto en un círculo $C$ de radio $r$. Sea $X$ la distancia del punto al centro del círculo. Entonces, $X$ es una variable aleatoria cuyo valor puede ser cualquier número entre 0 y $r$, inclusive. por tanto, el recorrido $R_X$ de $X$ es un intervalo cerrado:
$$
R_X=\left[ 0,r\right]=\left\{x:0\le x \le r \right\}.
$$
Aquí, $X$ es una variable aleatoria continua.
:::

## Función de Probabilidad {#funcion-probabilidad}

::: {#funcion-probabilidad .definition name="Función de Probabilidad"}
Sea $X$ una variable aleatoria discreta con recorrido $R_X=\left\{x_1, x_2, \dotsc \right\}$. Tal que, la probabilidad de que $X=x_i$ es $p \left(x_i \right)$, es decir, $P \left(X=x_i \right)=p \left(x_i \right)$, para $i=1,2, \dotsc$. Entonces, la función $p$ es una _función de probabilidad_ si cumple las siguientes condiciones:
$$
\begin{align*}
i)& \: p \left(x_i \right) \ge 0,\, para \: i= 1, 2, \dotsc\\
ii)& \: \sum_{i=1}^{\infty }p\left ( x_i \right )=1.
(\#eq:funcion-probabilidad)
\end{align*}
$$
:::

::: {.example #funcion-probabilidad1 name="Función de Probabilidad"}
Sea el experimento aleatorio que consiste en lanzar un par de dados equilibrados y $X$ la variable aleatoria representada por la suma de los resultados en cada dado.

Como se mostró en el ejemplo \@ref(exm:ejemp1-probcond), el espacio muestral viene dado por
$$
S=\begin{Bmatrix}
(1,1);&(1,2);&(1,3);&(1,4);&(1,5);&(1,6);\\
(2,1);&(2,2);&(2,3);&(2,4);&(2,5);&(2,6);\\
(3,1);&(3,2);&(3,3);&(3,4);&(3,5);&(3,6);\\
(4,1);&(4,2);&(4,3);&(4,4);&(4,5);&(4,6);\\
(5,1);&(5,2);&(5,3);&(5,4);&(5,5);&(5,6);\\
(6,1);&(6,2);&(6,3);&(6,4);&(6,5);&(6,6)\\
\end{Bmatrix}.
$$
Por lo que, el Recorrido de $X$ es
$R_X=\left\{2, 3, 4, 5, 6, 7, 8, 9 10, 11, 12 \right\}$, luego las probabilidades asociadas a cada $x_i$, es decir la función de probabilidad, se muestran en la tabla \@ref(tab:distribucion-probabilidad1). 

```{r distribucion-probabilidad1, class.source="watch-out", class.source = "watch-out"}
dp_ej1 <- data.frame(
  S = c(
    "$\\left(1, 1 \\right)$",
    "$\\left(1, 2 \\right), \\left(2, 1
        \\right)$",
    "$\\left(1, 3 \\right), \\left(2, 2
        \\right), \\left(3, 1 \\right)$",
    "$\\left(1, 4 \\right), \\left(2, 3
        \\right), \\left(3, 2 \\right),
        \\left(4, 1 \\right)$",
    "$\\left(1, 5\\right), \\left(2, 4
        \\right), \\left(3, 3 \\right), 
        \\left(4, 2 \\right),\\left(5,
        1\\right)$",
    "$\\left(1, 6\\right), \\left(2, 5
        \\right), \\left(3, 4 \\right), 
        \\left(4, 3 \\right),\\left(5,
        2\\right),\\left(6, 1\\right)$",
    "$\\left(2, 6\\right), \\left(3, 5
        \\right), \\left(4, 4 \\right), 
        \\left(5, 3 \\right),\\left(6,
        2\\right)$",
    "$\\left(3, 6 \\right), \\left(4, 5
        \\right), \\left(5, 4 \\right),
        \\left(6, 3 \\right)$",
    "$\\left(4, 6 \\right), \\left(5, 5
        \\right), \\left(6, 4 \\right)$",
    "$\\left(5, 6 \\right), \\left(6, 5
        \\right)$",
    "$\\left(6, 6 \\right)$"
  ),
  xi = 2:12,
  numero_ocurrencia = c(1:6, 5:1)
) %>%
  mutate(
    p_xi = c(
      "$\\frac{1}{36}$", "$\\frac{2}{36}$",
      "$\\frac{3}{36}$", "$\\frac{4}{36}$",
      "$\\frac{5}{36}$", "$\\frac{6}{36}$",
      "$\\frac{5}{36}$", "$\\frac{4}{36}$",
      "$\\frac{3}{36}$", "$\\frac{2}{36}$",
      "$\\frac{1}{36}$"
    )
  )
knitr::kable(
  dp_ej1,
  booktabs = TRUE,
  row.names = TRUE,
  col.names = c("Espacio Muestral", "$x_i$", "Número de ocurrencia", "$p\\left(x_i \\right)$"),
  align = c("lccc"),
  format.args = list(decimal.mark = ",", big.mark = "."),
  caption = "\\label{tab2:distribucion-probabilidad1}Distribución de probabilidad de la suma de las caras de dos dados",
  escape = FALSE
) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = FALSE,
    fixed_thead = T
  ) %>%
  kable_classic_2()
   
```

:::

Como se oberva en la tabla \@ref(tab:distribucion-probabilidad1) $p\left ( x_i \right )$ es una auténtica función de probabilidad dado que se cumplen las dos condiciones requeridas en la definición \@ref(def:funcion-probabilidad). Es decir,
$$
i) \: p \left(x_i \right) \ge 0,\, para \: i= 1, 2, \dotsc 11; y
$$

$$
\begin{align*}
ii) \: \sum_{i=1}^{11 }p\left ( x_i \right )=& \frac{1}{36}+\frac{2}{36}+\frac{3}{36}+\frac{4}{36}+\frac{5}{36}+\frac{6}{36}\\
& +\frac{5}{36}+\frac{4}{36}+\frac{3}{36}+\frac{2}{36}+\frac{1}{36}\\
&=1.
\end{align*}
$$

En algunos casos es posible expresar la función de probabilidad a través de una expresión matemática dada en términos de la variable aleatoria. En este caso, la función de probabilidad queda determinada por la siguiente expresión:
$$
p\left ( x \right )= \begin{cases}
\frac{6-\left|x-7 \right|}{36} & \text{si } x= 2, 3, \cdots ,12\\
0 & \text{en otros casos }.
(\#eq:funcion-probabilidad1)
\end{cases}
$$

Con la ecuación \@ref(eq:funcion-probabilidad1) también se pueden calcular las probabilidades dadas en la tabla \@ref(tab:distribucion-probabilidad1), tal como se muestra a continuación:
$$
\begin{align*}
 P(X=2)&=p\left (2  \right )= \frac{6-\left|2- 7\right|}{36}=\frac{1}{36}\\
 P(X=3)&=p\left (3  \right )= \frac{6-\left|3- 7\right|}{36}=\frac{2}{36} \\
 P(X=4)&=p\left (4  \right )= \frac{6-\left|4- 7\right|}{36}=\frac{3}{36} \\
 P(X=5)&=p\left (5  \right )= \frac{6-\left|5- 7\right|}{36}=\frac{4}{36} \\
 P(X=6)&=p\left (6  \right )= \frac{6-\left|6- 7\right|}{36}=\frac{5}{36} \\
 P(X=7)&=p\left (7  \right )= \frac{6-\left|7- 7\right|}{36}=\frac{6}{36} \\
 P(X=8)&=p\left (8  \right )= \frac{6-\left|8- 7\right|}{36}=\frac{5}{36} \\
 P(X=9)&=p\left (9  \right )= \frac{6-\left|9- 7\right|}{36}=\frac{4}{36} \\
 P(X=10)&=p\left (10  \right )= \frac{6-\left|10- 7\right|}{36}=\frac{3}{36} \\
 P(X=11)&=p\left (11  \right )= \frac{6-\left|11- 7\right|}{36}=\frac{2}{36} \\
 P(X=12)&=p\left (12  \right )= \frac{6-\left|12- 7\right|}{36}=\frac{1}{36} \\. 
 \end{align*}
$$
Como se puede notar, las probabilidades determinadas con esta ecuación se corresponden con las que se muestran en la tabla \@ref(tab:distribucion-probabilidad1).

Una forma de visualizar de manera rápida las probabilidades asociadas a cada valor de la variable aleatoria es a través de una gráfica de líneas verticales que comienzan en cada valor de la variable $x_i$ y cuya altura está determinada por sus probabilidades $p\left (x_i  \right )$. El gráfico de la función de  probabilidad para la suma de las caras en el lanzamiento de los dos dados se muestra en la figura \@ref(fig:grafico-distribucion-probabilidad1).

```{r grafico-distribucion-probabilidad1, fig.cap = "Gráfica de la función de probabilidad de la suma de las caras de dos dados", class.source = "watch-out"}
ggplot(
  data = dp_ej1,
  aes(x = xi, y = numero_ocurrencia / 36)
) +
  geom_segment(
    aes(
      x = xi, xend = xi, y = 0,
      yend = numero_ocurrencia / 36
    ),
    color = "blue"
  ) +
  geom_point(
    size = 3, color = "red"
  ) +
  scale_x_continuous(breaks = seq(2, 12, 1)) +
  theme_classic() + 
  xlab("Suma de las caras (X)") +
  ylab("Función de probabilidad")
```


## Función de Distribución Acumulativa de Probabilidad {#funcion-distribucion}
Existen muchos problemas en los que es necesario calcular la probabilidad de que el valor observado de una variable aleatoria $X$ sea menor o igual que algún número real $x$. Al escribir $F \left(x \right) = P \left(X \leq x \right)$ para cualquier número real $x$, se define $F \left(x \right)$ como la función de distribución acumulativa de probabilidad de la variable aleatoria $X$. De manera formal, la función de distribución acumulativa de probabilidad se define de la siguiente manera:

::: {#funcion-acumulativa-probabilidad .definition name="Función de Distribución Acumulativa de Probabilidad"}
Sea $X$ una variable aleatoria discreta con función de probabilidad $p \left(x_i \right)$. Entonces, la función de distribución acumulativa de probabilidad de $X$, denotada como $F \left(X \right)$, viene dada por:
$$
\begin{equation}
F\left ( x \right )=P\left ( X \leq x \right )=\sum_{t=x_1}^{x} p\left ( t \right ), \, \textrm{ para} \:\, t \leq x.
(\#eq:distribucion-probabilidad)
\end{equation}
$$
:::

### Propiedades de la Función de Distribución Acumulativa de Probabilidad {#propiedades-funcion-distribucion}

Dentro de las propiedades más importantes de la función de distribución acumulativa de probabilidad se pueden mencionar las siguientes:
$$
\begin{align*}
i)& \: 0 \leq F\left ( x \right ) \leq 1 \:\: \textrm{par cualquier}\:x; \\
ii)& \:\displaystyle \lim_{x \to - \infty }F\left ( x \right )=0;\\
iii)& \:\displaystyle \lim_{x \to  \infty }F\left ( x \right )=1;\\
iv)& \: F\left ( x_{j} \right ) \geq F\left ( x_{i} \right ) \:\: \textrm{si} \: x_{j} \geq x_{i};\\
v)& \: F\left ( x_{i} \right ) = F\left ( x_{i-1} \right ) + p\left ( x_{i} \right );\\
vi)& \: P\left ( X > x_{i} \right ) = 1 - F\left ( x_{i} \right ); \\
vii)& \: P\left ( X <  x_{i} \right ) = F\left ( x_{i-1} \right ); \\
viii)& \: P\left ( X \geq  x_{i} \right ) = 1 - F\left ( x_{i-1} \right ); \\
ix)& \: P\left ( X=x_{i} \right )=F\left ( x_{i} \right )-F\left ( x_{i-1} \right ); \\
x)& \: P\left ( x_{i} \leq X \leq x_{j} \right )=F\left ( x_{j} \right )-F\left ( x_{i-1} \right );\\
xi)& \: P\left ( x_{i} <  X \leq x_{j} \right )=F\left ( x_{j} \right )-F\left ( x_{i} \right );\\ 
xii)& \: P\left ( x_{i} \leq   X <  x_{j} \right )=F\left ( x_{j-1} \right )-F\left ( x_{i-1} \right ).\\
\end{align*}
$$

::: {.example #funcion-probabilidad1 name="Función de Distribución Acumulativa"}
Determine la función de distribución acumulativa de probabilidad del ejemplo \@ref(exm:funcion-probabilidad1).

La función de distribución acumulativa de probabilidad en este caso viene dada, de acuerdo con la definición \@ref(def:funcion-acumulativa-probabilidad), por:
$$
\begin{align*}
 F(2)&=P\left ( X \leq 2 \right )=p\left (2  \right )= \frac{1}{36}\\
 F(3)&=P\left ( X \leq 3 \right )= p\left (2  \right )+p\left (3  \right )= \frac{1}{36} + \frac{2}{36} =\frac{3}{36} \\
F(4)&=P\left ( X \leq 4 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}=\frac{6}{36} \\
F(5)&=P\left ( X \leq 5 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}=\frac{10}{36} \\
F(6)&=P\left ( X \leq 6 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}=\frac{15}{36} \\
F(7)&=P\left ( X \leq 7 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}=\frac{21}{36} \\
F(8)&=P\left ( X \leq 8 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&+p\left (8  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}+ \frac{5}{36}=\frac{26}{36} \\
F(9)&=P\left ( X \leq 9 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&+p\left (8  \right )+p\left (9  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}+ \frac{5}{36}+ \frac{4}{36}=\frac{30}{36} \\
F(10)&=P\left ( X \leq 10 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&+p\left (8  \right )+p\left (9  \right )+p\left (10  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}+ \frac{5}{36}+ \frac{4}{36}+ \frac{3}{36}\\&=\frac{33}{36} \\
F(11)&=P\left ( X \leq 11 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&+p\left (8  \right )+p\left (9  \right )+p\left (10  \right )+p\left (11  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}+ \frac{5}{36}+ \frac{4}{36}+ \frac{3}{36}\\&+ \frac{2}{36}=\frac{35}{36} \\
F(12)&=P\left ( X \leq 12 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&+p\left (8  \right )+p\left (9  \right )+p\left (10  \right )+p\left (11  \right )+p\left (12  \right)\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}+ \frac{5}{36}+ \frac{4}{36}+ \frac{3}{36}\\&+ \frac{2}{36}+ \frac{1}{36}=\frac{36}{36}=1 \\.   
\end{align*}
$$

Los resultados anteriores pueden resumirse en la tabla \@ref(tab:distribucion-acumulada1).

```{r distribucion-acumulada1, class.source="watch-out", class.source = "watch-out"}
da_ej1 <- data.frame(
  S = c(
    "$\\left(1, 1 \\right)$",
    "$\\left(1, 2 \\right), \\left(2, 1
        \\right)$",
    "$\\left(1, 3 \\right), \\left(2, 2
        \\right), \\left(3, 1 \\right)$",
    "$\\left(1, 4 \\right), \\left(2, 3
        \\right), \\left(3, 2 \\right),
        \\left(4, 1 \\right)$",
    "$\\left(1, 5\\right), \\left(2, 4
        \\right), \\left(3, 3 \\right), 
        \\left(4, 2 \\right),\\left(5,
        1\\right)$",
    "$\\left(1, 6\\right), \\left(2, 5
        \\right), \\left(3, 4 \\right), 
        \\left(4, 3 \\right),\\left(5,
        2\\right),\\left(6, 1\\right)$",
    "$\\left(2, 6\\right), \\left(3, 5
        \\right), \\left(4, 4 \\right), 
        \\left(5, 3 \\right),\\left(6,
        2\\right)$",
    "$\\left(3, 6 \\right), \\left(4, 5
        \\right), \\left(5, 4 \\right),
        \\left(6, 3 \\right)$",
    "$\\left(4, 6 \\right), \\left(5, 5
        \\right), \\left(6, 4 \\right)$",
    "$\\left(5, 6 \\right), \\left(6, 5
        \\right)$",
    "$\\left(6, 6 \\right)$"
  ),
  xi = 2:12,
  numero_ocurrencia = c(1:6, 5:1)
) %>%
  mutate(
    p_xi = c(
      "$\\frac{1}{36}$", "$\\frac{2}{36}$",
      "$\\frac{3}{36}$", "$\\frac{4}{36}$",
      "$\\frac{5}{36}$", "$\\frac{6}{36}$",
      "$\\frac{5}{36}$", "$\\frac{4}{36}$",
      "$\\frac{3}{36}$", "$\\frac{2}{36}$",
      "$\\frac{1}{36}$"
    ),
    F_xi = c(
      "$\\frac{1}{36}$", "$\\frac{3}{36}$",
      "$\\frac{6}{36}$", "$\\frac{10}{36}$",
      "$\\frac{15}{36}$", "$\\frac{21}{36}$",
      "$\\frac{26}{36}$", "$\\frac{30}{36}$",
      "$\\frac{33}{36}$", "$\\frac{35}{36}$",
      "$\\frac{36}{36}$"
      )
  )
knitr::kable(
  da_ej1,
  booktabs = TRUE,
  row.names = TRUE,
  col.names = c("Espacio Muestral", "$x_i$", "Número de ocurrencia", "$p\\left(x_i \\right)$", "$F\\left(x_i \\right)$"),
  align = c("lccc"),
  format.args = list(decimal.mark = ",", big.mark = "."),
  caption = "\\label{tab2:distribucion-acumulada1}Función de distribución acumulativa de la suma de las caras de dos dados",
  escape = FALSE
) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = FALSE,
    fixed_thead = T
  ) %>%
  kable_classic_2()
```

Cuando se conoce la expresión que define la función de probabilidad, la cual, en este caso está dada por la ecuación \@ref(eq:funcion-probabilidad1), se puede determinar una expresión matemática que defina la función de distribución acumulativa de probabilidad. A continuación se ejecuta un procedimiento para hallar esta ecuación.
$$
\begin{align*}
F\left ( x \right )=\sum_{t=2}^{x}p\left ( x \right ) =\sum_{t=2}^{x}\frac{6-\left|7-x \right|}{36}. 
\end{align*}
$$

Como la expresión $\left|7-x \right|$ es positiva si $x=2, 3, \dotsc, 7$ y negativa si $x=8, 9, \dotsc, 12$. Entonces, se derivan expresiones para  $F\left ( x \right )$ en cada uno de estos casos.

1.  si $x=2, 3, \dotsc, 7$
$$
\begin{align*}
 F\left ( x \right )&= \sum_{t=2}^{x}\frac{6-\left|7-x \right|}{36}=\frac{1}{36}\sum_{t=2}^{x}\left ( 6-7+x \right )=\frac{1}{36}\sum_{t=2}^{x}\left ( t-1 \right )\\
&=\frac{1}{36}\left [ \sum_{t=2}^{x}t-\sum_{t=2}^{x}1 \right ]=\frac{1}{36}\left [ \left ( 2+3+\cdots +x \right )-\left ( x-1 \right ) \right ]\\
&=\frac{1}{36}\left [ \left ( \frac{2+x}{2} \right )\left ( x-1 \right )-\left ( x-1 \right ) \right ] = \frac{1}{36}\left ( x-1 \right )\left ( \frac{2+x}{2} -1 \right )\\
&=\frac{1}{36}\left ( x-1 \right )\left ( \frac{2+x-2}{2} \right )=\frac{1}{72}x\left ( x-1 \right ).
\end{align*}
$$
2.  si $x=8, 9, \dotsc, 12$
$$
\begin{align*}
 F\left ( x \right )&=\sum_{t=8}^{x}\frac{6-\left|7-x \right|}{36}=\frac{1}{36}\sum_{t=8}^{x}\left ( 6+7-x \right )\\
&=\frac{1}{36}\sum_{t=8}^{x}\left ( 13-x \right )=\frac{1}{36}\left [ \sum_{t=8}^{x}13-\sum_{t=8}^{x}x \right ]\\
&=\frac{1}{36}\left [ 13\left ( x-7 \right )-\left ( \frac{8+x}{2} \right )\left ( x-7 \right ) \right ]\\
&=\frac{1}{36}\left [ \left ( x-7 \right )\left ( 13-\left ( \frac{8+x}{2} \right ) \right ) \right ]\\
&=\frac{1}{36}\left [ \left ( x-7 \right )\left ( \frac{26-8-x}{2} \right ) \right ]=\frac{1}{72}\left ( x-7 \right )\left ( x-8 \right ).
\end{align*}
$$

En resumen, la función de distribución acumulada puede expresarse de la siguiente manera:
$$
F\left ( x \right )=
\begin{cases}
0 & \textrm{ si } x< 2 \\
\frac{1}{72}x\left ( x-1 \right ) & \textrm{ si } x=2, 3,\dotsc,7 \\
\frac{42}{72}+\frac{1}{72}\left ( x-7 \right )\left ( 18-x \right ) & \textrm{ si } x=8, 9, \dotsc,12 \\
1 & \textrm{ si } x>1. 
(\#eq:funcion-dictribucion1)
\end{cases}
$$

Se puede verificar que los valores de $F\left ( x \right )$  dados en la tabla \@ref(tab:distribucion-acumulada1) se corresponden con los que se obtienen con la ecuación \@ref(eq:funcion-dictribucion1). Por ejemplo:
$$
\begin{align*}
a)& \: F\left ( 7 \right )=\frac{1}{72}7\left ( 7-1 \right )=\frac{42}{72}=\frac{42}{72}\\
b)& \: F\left ( 10 \right )=\frac{42}{72}+\frac{1}{72}\left ( 10-7 \right )\left ( 18-10\right)=\frac{42}{72}+\frac{24}{72}=\frac{66}{72}=\frac{33}{36}.
\end{align*}
$$
:::

La figura \@ref(fig:grafico-distribucion-acumulada1) muestra la gráfica de la función de distribución acumulativa de la suma de las caras de los dados. Note que esta gráfica es escalonada. 

```{r grafico-distribucion-acumulada1, fig.cap = "Gráfica de la función de distribución acumulativa de la suma de las caras de dos dados", class.source = "watch-out"}
dp_ej1 <- dp_ej1 %>%
  mutate(
    F_xi = cumsum(numero_ocurrencia) / 36,
    xi_end = c(3:12, NA),
    F_xiend = F_xi
  )
ggplot(
  dp_ej1, aes(
    x = xi, y = F_xi, xend = xi_end, yend = F_xiend
  )
) +
  geom_point() +
  geom_point(aes(x = xi_end, y = F_xi), shape = 1) +
  geom_segment(color = "blue") +
  scale_x_continuous(breaks = seq(2, 12, 1)) +
  theme_classic() +
  xlab("Suma de las caras (X)") +
  ylab("Función de distribución acumulativa")
```

## Esperanza Mateática de Una Variable Aleatoria Discreta {#esperanza-matematica}

::: {#esperanza .definition name="Esperanza Mateática de Una Variable Aleatoria Discreta"}
Sea $X$ una variable aleatoria discreta con la función de probabilidad $p \left(x \right)$. Entonces la
esperanza matemática, media o valor esperado de$X$, denotado por $E \left(x \right)$ o simplemente $\mu$, se define como
$$
\begin{equation}
\mu=E \left(X \right)=\sum_{x}x p \left(x \right).
(\#eq:esperanza)
\end{equation}
$$
:::

::: {.example #esperanza name="Esperanza Matemática de Una Variable Aleatoria discreta"}
Calcule el valor esperado de la variable aleatoria $X$  representada por la suma de los resultados del lanzamiento de dos dados descrita en el ejemplo \@ref(exm:funcion-probabilidad1).

De acuerdo con la definición \@ref(def:esperanza), en este caso la esperanza viene dada por:
$$
\begin{align*}
\mu=&E\left(X \right)=\sum_{x=2}^{12 }xp\left ( x \right )= 2 \left(\frac{1}{36}\right)+3\left(\frac{2}{36}\right)+4\left(\frac{3}{36}\right)+5\left(\frac{4}{36}\right)+6\left(\frac{5}{36}\right)+7\left(\frac{6}{36}\right) \\
& +8\left(\frac{5}{36}\right)+9\left(\frac{4}{36}\right)+10\left(\frac{3}{36}\right)+11\left(\frac{2}{36}\right)+12\left(\frac{1}{36}\right)\\
&=7.
\end{align*}
$$
Este valor significa que si se lanzan los dos dados un número significativamente grande de veces, el promedio de la suma de las caras va estar próximo a 7. 

En `r colorize("R", "blue")`, el resultado anterior se puede obtener con el siguiente script.
```{r esperanza}
x <- 2:12
p_x <- c(1:6,5:1) / 36
(media <- sum(x * p_x))
```

:::

En muchos problemas de estadística no solo es de interés el valor esperado de la variable $X$, como se definió en \@ref(def:esperanza), sino también el valor esperado de alguna variable $Y$ que es una transformación de $X$, es decir $g\left(x \right)$. Por ejemplo, $y=g\left(x \right)=x^2$. En tal sentido, se establece el teorema siguiente:

::: {#esperanza-transformacion .theorem}
Si $X$ es una variable aleatoria discreta con función de probabilidad $p\left(x \right)$. Entonces, el valor esperado de la variable aleatoria $g\left(x \right)$ está dado por
$$
\begin{equation}
E \left[g\left(x \right) \right]=\sum_{x}g\left(x \right) p \left(x \right).
(\#eq:esperanza-transformacion)
\end{equation}
$$
:::

En algunos casos el calculo de esperanzas matemáticas se simplifican mediante el uso de los siguientes teoremas, los cuales permiten calcular valores esperados a partir de otras esperanzas conocidas o que se determinan con menor dificultad. 

::: {#esperanza-transformacion-lineal .theorem}
Si $X$ es una variable aleatoria discreta con función de probabilidad $p\left(x \right)$ y sean $a$ y $b$ constantes. Entonces,
$$
\begin{equation}
E \left( ax+b \right)=a.E \left( x \right)+b.
(\#eq:esperanza-transformacion-lineal)
\end{equation}
$$
:::

Note que si se hace $a=0$ en el teorema \@ref(thm:esperanza-transformacion) se obtiene el siguiente corolario:

::: {#corolario1 .corollary}
Si $X$ es una variable aleatoria discreta con función de probabilidad $p\left(x \right)$ y $a$ una constantes. Entonces,
$$
\begin{equation}
E \left( ax \right) = aE \left( x \right).
(\#eq:corolario1)
\end{equation}
$$
:::

Mientras que si se hace $b=0$ en el teorema \@ref(thm:esperanza-transformacion) se obtiene este otro: 

::: {#corolario2 .corollary}
Si $X$ es una variable aleatoria discreta con función de probabilidad $p\left(x \right)$ y $b$ una constantes. Entonces,
$$
\begin{equation}
E \left( b \right) = b.
(\#eq:corolario2)
\end{equation}
$$
:::

Observe que si se escribe $E \left( b \right)$, la constante $b$ se puede ver como una variable aleatoria que siempre toma el valor $b$.

Otro teorema importante relacionado con la esperanza de transformaciones de variables aleatoria es el siguiente:

::: {#esperanza-suma-transformaciones .theorem}
Si $X$ es una variable aleatoria discreta con función de probabilidad $p\left(x \right)$. Además, considere que $c_1, c_2, \dotsc, c_n$ son constantes y $g_1\left(x \right), g_2\left(x \right), \dotsc, g_n\left(x \right)$ transformaciones de $X$. Entonces,
$$
\begin{equation}
E \left[\sum_{i=1}^{n}c_i g_i\left(x \right) \right]=\sum_{i=1}^{n}c_iE \left[ g_i\left(x \right) \right].
(\#eq:esperanza-suma-transformaciones)
\end{equation}
$$
:::


## Varianza de Una Variable Aleatoria Discreta {#varianza}

::: {#varianza .definition name="Varianza de Una Variable Aleatoria Discreta"}
Sea $X$ una variable aleatoria con distribución de probabilidad $p \left(x \right)$ y media $\mu$. La varianza
de $X$, denotado por $\sigma^2$ o $E \left[\left(X −μ \right)^2 \right]$ es

$$
\begin{equation}
\sigma^2=E \left[\left(X −μ \right)^2 \right]=\sum_{x}\left(X −μ \right)^2 p \left(x \right).
(\#eq:varianza)
\end{equation}
$$
La raíz cuadrada positiva de la varianza, $\sigma$, se llama desviación estándar de $X$.
:::

Una ecuación alternativa para la varianza se obtiene de la siguiente manera. Primero, se desarrolla la expresión $\left(X −μ \right)^2$ dada en la ecuación \@ref(eq:varianza), como sigue.
$$
\sigma^2=E \left[\left(X −μ \right)^2 \right]=E\left(X^2-2\mu X +\mu^2 \right).
$$
Luego, por el teorema \@ref(thm:esperanza-suma-transformaciones) y el corolario \@ref(cor:corolario1), se obtiene
$$
\sigma^2=E \left[\left(X −μ \right)^2 \right]=E\left(X^2 \right)-2\mu E \left(X \right) +\mu^2 .
$$
Como $E \left(X \right)=\mu$, entonces
$$
\begin{equation}
\sigma^2=E \left[\left(X −μ \right)^2 \right]=E\left(X^2 \right)-\mu^2.
(\#eq:varianza2)
\end{equation}
$$

::: {.example #varianza name="Varianza de Una Variable Aleatoria Discreta"}
Calcule el valor esperado de la variable aleatoria $X$  representada por la suma de los resultados del lanzamiento de dos dados descrita en el ejemplo \@ref(exm:funcion-probabilidad1).

De acuerdo con la definición \@ref(def:varianza), la varianza de la suma delas caras de los dados es:


$$
\begin{align*}
\sigma^2=&\sum_{x=2}^{12}\left(x −μ \right)^2p\left ( x \right )= \left(2-7 \right)^2 \left(\frac{1}{36}\right)+\left(3-7 \right)^2\left(\frac{2}{36}\right)+\left(4-7 \right)^2\left(\frac{3}{36}\right)+\left(5-7 \right)^2\left(\frac{4}{36}\right) \\
&+\left(6-7 \right)^2\left(\frac{5}{36}\right)+\left(7-7 \right)^2\left(\frac{6}{36}\right) +\left(8-7 \right)^2\left(\frac{5}{36}\right)+\left(9-7 \right)^2\left(\frac{4}{36}\right)+\left(10-7 \right)^2\left(\frac{3}{36}\right) \\
&+\left(11-7 \right)^2\left(\frac{2}{36}\right)+\left(12-7 \right)^2\left(\frac{1}{3
6}\right)\\
&=\frac{35}{6} \approx 5,83.
\end{align*}
$$
Mientras que la desviación estándar es,
$$
\sigma = \sqrt{\frac{35}{6}} \approx 2,42.
$$
Usando la ecuación alternativa para la varianza dada en la ecuación \@ref(eq:varianza2), el valor de este parámetro se se obtiene como sigue
$$
\begin{align*}
\sigma^2=&\sum_{x=2}^{12}x^2p\left ( x \right )-\mu^2= \left(2 \right)^2 \left(\frac{1}{36}\right)+\left(3 \right)^2\left(\frac{2}{36}\right)+\left(4 \right)^2\left(\frac{3}{36}\right)+\left(5 \right)^2\left(\frac{4}{36}\right)\\
&+\left(6 \right)^2\left(\frac{5}{36}\right) +\left(7 \right)^2\left(\frac{6}{36}\right) +\left(8 \right)^2\left(\frac{5}{36}\right)+\left(9 \right)^2\left(\frac{4}{36}\right)+\left(10 \right)^2\left(\frac{3}{36}\right)+\left(11 \right)^2\left(\frac{2}{36}\right)\\
&+\left(12 \right)^2\left(\frac{1}{3
6}\right) - \left(7 \right)^2\\
& =\frac{329}{6} - 49=\frac{35}{6} \approx 5,83.
\end{align*}
$$

El valor de la varianza y la desviación estándar obtenidos anteriormente se pueden calcular en `r colorize("R", "blue")` con el siguiente script.
```{r varianza}
(varianza <-  sum((x - media) ^ 2 * p_x))
(desviacion <- sqrt(varianza))
```
:::

## Función Generadora de Momentos de Una Variable Aleatoria Discreta {#funcion-generadora-momentos}

::: {#funcion-generadora-momentos .definition name="Función Generadora de Momentos de Una Variable Aleatoria Discreta"}
Sea $X$ una variable aleatoria discreta con función de probabilidad $p \left(x \right)$. El valor esperado de $e^{tx}$ recibe el nombre de _función generadora de momentos_, y se denota por $m_x \left(t \right)$
de $X$, si el valor esperado existe en algún intervalo $-c<t<c$ en donde $c$ es un entero positivo. En otros términos:

$$
\begin{equation}
m_x \left(t \right)=E \left(e^{tx} \right) =\sum_{x}e^{tx} p \left(x \right), \:si\: -c<t<c.
(\#eq:funcion-generadora-momentos)
\end{equation}
$$
:::

::: {#funcion-generadora-momentos .theorem}
Si $X$ es una variable aleatoria con función generadora de momentos $m_x \left(t \right)$. Entonces,
$$
\begin{equation}
\frac{\mathrm{d}^{k}m_{x}\left ( t \right )}{\mathrm{d}t^{k}} \left|\begin{matrix}
 \\
t=0\\
\end{matrix}={\mu}^{'}_k \right.
(\#eq:funcion-generadora-momentos)
\end{equation}
$$
:::

En muchas situaciones cundo se trabaja con variables aleatorias se definen transformaciones lineales sobre estas variables. En tales casos, si se conoce la función generadora de momentos de estas variables se pueden obtener las funciones generadoras de momentos de esas transformaciones por medio del teorema que sigue:

::: {#funcion-generadora-momentos .theorem}
Si $X$ es una variable aleatoria con función generadora de momentos $m_x \left(t \right)$. Entonces,
$$
\begin{align*}
i)&\:m_{x+a}\left ( t \right )= E\left [ e^{\left ( x+a \right )t} \right ]=e^{at} \cdot m_{x}\left ( t \right )\\
ii)&\: m_{bx}\left ( t \right )= E\left ( e^{bxt} \right )=m_{x}\left ( bt \right )\\
iii)&\: m_{\frac{x+a}{b}} =E\left [ e^{\left ( \frac{x+a}{b} \right )t} \right ] =e^{\frac{a}{b}t} \cdot m_{x}\left ( \frac{t}{b} \right ).
(\#eq:teorema-funcion-generadora-momentos)
\end{align*}
$$
:::

## Distribuciones de Probabilidad Notables {#distribuciones-notables}
En esta sección se definen algunas distribuciones de probabilidad de gran importancia por sus múltiples aplicaciones en la descripción de fenómenos que ocurren en la vida diaria, tales como: la _distribución binomial_, la _distribución hipergeométrica_ y la _distribución de Poisson_.

### Distribución Binomial {#distribucion-binomial}

::: {#distribucion-binomial .definition name="Distribución Binomial"}
Sea $X$ una variable aleatoria que representa el número de éxitos en $n$ ensayos y $p$ la probabilidad de éxito en cualquiera de éstos. Se dice que $X$ tiene una _distribución binomial_ con parámetros $n$ y $p$, y se escribe $X\sim Bin\left ( n, p \right )$, con función de probabilidad.
$$
p\left ( x;n,p \right )=\begin{cases}
\binom{n}{x}p^{x}\left ( 1-p \right )^{n-x} & \text{ si } x= 0, 1, 2, \dotsc, n;\: 0\leq p\leq 1 \text{ y }n \in \mathbb{N}\\
0 & \text{ en cualquier otro caso }.
(\#eq:funcion-probabilidad-binomial)
\end{cases}
$$
:::

La figura \@ref(fig:grafico-distribucion-binomial) muestra la gráfica de la función de probabilidad binomial para $n=10$ y $p$ igual a 0,2; 0,5 y 0,8. Como se observa en esta gráfica la distribución binomial es asimétrica positiva para $p = 0,1$; simétrica para $ p = 0,5$ y asimétrica negativa para $p = 0,8$. De manera general, esta distribución de probabilidad es asimétrica positiva para $p < 0,5$, simétrica si $p = 0,5$ y asimétrica negativa si $p > 0,5$.

```{r grafico-distribucion-binomial, fig.cap = "Gráfica de la función de probabilidad binomial para $n = 10$ y $p = 0,2; 0,5; 0,8$", class.source = "watch-out"}
plot_ly(alpha = 0.5) %>%
  add_segments(
    x = ~c(0:10), y = ~rep(x = 0, times = 11),
    xend = ~c(0:10), yend = ~dbinom(0:10, 10, 0.2), 
    color = I("red"), showlegend = TRUE,
    name = "n = 10, p = 0,2"
  ) %>%
  add_markers(
    x = ~c(0:10), y = ~dbinom(0:10, 10, 0.2), 
    color = I("red"), showlegend = TRUE,
    name = "n = 10, p = 0,2"
  ) %>%
  add_segments(
    x = ~c(0:10), y = ~rep(x = 0, times = 11),
    xend = ~c(0:10), yend = ~dbinom(0:10, 10, 0.5), 
    color = I("blue"), showlegend = TRUE,
    name = "n = 10, p = 0,5"
  ) %>%
  add_markers(
    x = ~c(0:10), y = ~dbinom(0:10, 10, 0.5), 
    color = I("blue"), showlegend = TRUE,
    name = "n = 10, p = 0,5"
  ) %>%
  add_segments(
    x = ~c(0:10), y = ~rep(x = 0, times = 11),
    xend = ~c(0:10), yend = ~dbinom(0:10, 10, 0.8), 
    color = I("green"), showlegend = TRUE,
    name = "n = 10, p = 0,8"
  ) %>%
  add_markers(
    x = ~c(0:10), y = ~dbinom(0:10, 10, 0.8), 
    color = I("green"), showlegend = TRUE,
    name = "n = 10, p = 0,8"
  ) %>% 
  layout(
    xaxis = list(
      title = "x", 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = "p(x)",
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es")
```

::: {.example #ejemplo-funcion-probabilidad-binomial name="Función de probabilidad binomial"}
Todos los días se seleccionan, de manera aleatoria, 15 artículos de un proceso de producción con el propósito de vigilar la fracción de artículos defectuosos que produce el proceso. Con base en información pasada, la probabilidad de que el proceso produzca un artículo defectuoso es 0,05. Determine la probabilidad de que se encuentren dos artículos defectuosos en la muestra.

Dado que $X$ representa el número de artículo defectuosos encontrados en la muestra de tamaño 15 ($n=15$) y que la probabilidad de encontrar un artículo defectuoso en la muestra es 0,05 ($p = 0,05$). Entonces, de acuerdo con la definición \@ref(def:distribucion-binomial), $X$ tiene distribución binomial con parámetros $n = 15$ y $p = 0,05$, es decir, $X \sim Bin\left(n = 15, p = 0,05 \right)$. Por lo tanto, de acuerdo con la ecuación \@ref(eq:funcion-probabilidad-binomial),

$$
P\left(X = 2 \right)=p\left ( x = 2;n = 15,p = 0,05 \right )=
\binom{15}{2}\left(0,05 \right)^{2}\left ( 1- 0,05 \right )^{15-2} \approx 0,1348.
$$
La función `dbinom(x, size, prob, log = FALSE)` de la distribución base de `r colorize("R", "blue")` permite evaluar la función de probabilidad binomial dada por la ecuación \@ref(eq:funcion-probabilidad-binomial). El siguiente script permite obtener el resultado anterior.

```{r}
dbinom(x = 2, size = 15, prob = 0.05, log = FALSE)
```
:::

#### Distribución Binomial {#distribucion-acumulada-binomial}

La probabilidad de que una variable aleatoria binomial $X$ sea menor o igual que un valor específico $x$ o dicho de otra manera la probabilidad de encontrar a los más $x$ éxitos en los $n$ ensayos, o lo que es igual,la función de distribución acumulativa de probabilidad binomial, queda deterinada, de acuerdo con la definición \@ref(def:funcion-acumulativa-probabilidad) por:

::: {#distribucion-acumulada-binomial .definition name="Función Generadora de Momentos de Una Variable Aleatoria Discreta"}
Sea $X$ una variable aleatoria con distribución binomial. Entonces, la _función de distribución acumulativa de probabilidad binomial_ viene dada por:
$$
F\left ( x;n,p \right )=\begin{cases}
0 & \text{ si } x < 0\\
 \sum_{t=0}^{x } \binom{n}{t}p^{t}\left ( 1-p \right )^{n-t} & \text{ si } x= 0, 1, 2, \dotsc, n;\: 0\leq p\leq 1 \text{ y }n \in \mathbb{N}\\
1 & \text{ si } x > n.
(\#eq:funcion-acumulativa-binomial)
\end{cases}
$$
:::

La figura \@ref(fig:grafico-distribucion-binomial) muestra la función de distribución acumulativa de probabilidad para una variable binomial con parámetros $n = 10$ y $p = 0,2; 0,5 \, \text{y} \, 0,8$. 

```{r grafico-acumulativa-binomial, fig.cap = "Gráfica de la función de distribución acumulativa de probabilidad binomial para $n = 15$ y $p = 0,2;0,5;0,8$", class.source = "watch-out"}
x <- c(-3, 0:10, 13)
px1  <-  dbinom(x = x, size = 10, prob = 0.2)
Fx1  <-  pbinom(q = x, size = 10, prob = 0.2)
px2  <-  dbinom(x = x, size = 10, prob = 0.5)
Fx2  <-  pbinom(q = x, size = 10, prob = 0.5)
px3  <-  dbinom(x = x, size = 10, prob = 0.8)
Fx3  <-  pbinom(q = x, size = 10, prob = 0.8)
plot_ly(x = x, y = Fx1, alpha = 0.5) %>%
  add_segments(
    x = ~x[1:12], 
    y = ~Fx1[1:12],
    xend = ~x[2:13], 
    yend = ~Fx1[1:12], 
    color = I("red"),
    name = "n = 10, p = 0,2",
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx1[2:12], 
    color = I("red"),
    name = "n = 10, p = 0,2",
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx1[1:11], 
    color = I("red"),
    marker = list(symbol = "circle-open"),
    name = "n = 10, p = 0,2",
    showlegend = TRUE
  )  %>%
  add_segments(
    x = ~x[1:12], 
    y = ~Fx2[1:12],
    xend = ~x[2:13], 
    yend = ~Fx2[1:12], 
    color = I("blue"), 
    name = "n = 10, p = 0,5",
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx2[2:12], 
    color = I("blue"),
    name = "n = 10, p = 0,5",
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx2[1:11], 
    color = I("blue"),
    marker = list(symbol = "circle-open"),
    name = "n = 10, p = 0,5",
    showlegend = TRUE
  )  %>%
  add_segments(
    x = ~x[1:12], 
    y = ~Fx3[1:12],
    xend = ~x[2:13], 
    yend = ~Fx3[1:12], 
    color = I("green"),
    name = "n = 10, p = 0,8",
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx3[2:12], 
    color = I("green"),
    name = "n = 10, p = 0,8",
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx3[1:11], 
    color = I("green"),
    marker = list(symbol = "circle-open"),
    name = "n = 10, p = 0,8",
    showlegend = TRUE
  ) %>% 
  layout(
    xaxis = list(
      title = "x", 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = "F(x)",
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es")
```

::: {.example #ejemplo-distribucion-acumulada-binomial name="Función de Distribución Acumulativa de Probabilidad Binomial"}
suponga en el ejemplo \@ref(exm:ejemplo-funcion-probabilidad-binomial) que la gerencia de control de calidad de la fábrica ha decidido detener la producción cada vez que en una muestra de 15 unidades tenga dos o más artículos defectuosos ¿Cuál es la probabilidad de que, en cualquier día, la se detenga?

Dado que la probabilidad de que la producción se detenga es igual a la probabilidad de que $X$ sea igual o mayor que dos. De esta manera:

$$
\begin{align*}
P \left(X \geq 2 \right) =& 1 - P \left(X \leq 1
\right)=  1 - F \left( x = 1;n = 15,p = 0,05 \right ) = 1 - \sum_{t=0}^{1 } \binom{15}{t} \left( 0,05 \right)^{t} \left( 1-0,05 \right )^{15-t}\\
=& \binom{15}{0}\left(0,05 \right)^{0} \left( 1- 0,05 \right)^{15-0}+ \binom{15}{1}\left(0,05 \right)^{1} \left( 1- 0,05 \right)^{15-1}\\ \approx &  0.1709525.
\end{align*}
$$

La función `pbinom(q, size, prob, lower.tail = TRUE, log.p = FALSE)` de la distribución base de `r colorize("R", "blue")` permite evaluar la función de distribución acumulativa de probabilidad binomial dada por la ecuación \@ref(eq:funcion-acumulativa-binomial). El siguiente script permite obtener el resultado anterior.

```{r}
1 - pbinom(
  q = 1, size = 15, prob = 0.05, lower.tail = TRUE, 
  log.p = FALSE
)
```
:::

La figura \@ref(fig:grafico-ejemplo-distribucion-acumulada-binomial) muestra la gráfica de la función de distribución acumulativa del número de artículos defectuosos en una muestra de 15 artículos $X$. La cual, como se sabe, tiene distribución binomial con parámetros $n = 15$ y $p= 0,05$. 

```{r grafico-ejemplo-distribucion-acumulada-binomial, fig.cap = "Gráfica de la función de distribución acumulativa de probabilidad binomial para $n = 15$ y $p = 0,05$", class.source = "watch-out"}
x <- c(-3, 0:15, 18)
px  <-  dbinom(x = x, size = 15, prob = 0.05)
Fx  <-  pbinom(q = x, size = 15, prob = 0.05)
plot_ly(x = x, y = Fx, alpha = 0.5) %>%
  add_segments(
    x = ~x[1:17], 
    y = ~Fx[1:17],
    xend = ~x[2:18], 
    yend = ~Fx[1:17], 
    color = I("blue"),
    name = "n = 15, p = 0,05",
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:17], 
    y = ~Fx[2:17], 
    color = I("red"),
    name = "n = 15, p = 0,05"
  ) %>%
  add_markers(
    x = ~x[2:17], 
    y = ~Fx[1:16], 
    color = I("red"),
    marker = list(symbol = "circle-open"),
    name = "n = 15, p = 0,05"
  )  %>% 
  layout(
    xaxis = list(
      title = "x", 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = "F(x)",
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es")
```

La tabla \@ref(tab:distribucion-acumulada2) muestra la función de probabilidad y la función de distribución acumulativa de probabilidad de una variable binomial con parámetros $n = 15$ y $p = 0,05$.

```{r distribucion-acumulada2, class.source="watch-out", class.source = "watch-out"}
da_ej2 <- data.frame(
  x = 0:15,
  px = dbinom(x = 0:15, size = 15, prob = 0.05),
  Fx =  pbinom(q = 0:15, size = 15, prob = 0.05)
) 
knitr::kable(
  da_ej2,
  booktabs = TRUE,
  row.names = TRUE,
  digits = 4,
  col.names = c(
    "$X_i$", 
    "$p\\left(x_i \\right)$", 
    "$F\\left(x_i \\right)$"
  ),
  align = c("ccc"),
  format.args = list(decimal.mark = ",", big.mark = "."),
  caption = "\\label{tab2:distribucion-acumulada2}Distribución de probabilidad del número de artículos defectuosos en una muestra de 15 artículos",
  escape = FALSE
) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = FALSE,
    fixed_thead = T
  ) %>%
  kable_classic_2()
```

#### Media de la Distribución Binomial {#media-binomial}

La media, promedio o esperanza matemática de la distribución binomial viene representada por un número, tal que si tomamos repetidas muestras de una variable binomial, en la medida en que se va incrementado el número de muestras el promedio de estos valores muestrales tiende a ese número en la medida en que se va incrementando el número de muestras. Lo dicho anteriormente se resume en el siguiente teorema.

::: {#media-binomial .theorem name="Media de la Distribución Binomial"}
Sea $X$ una variable aleatoria con distribución binomial. Entonces, la _media_ de $X$ viene dada por:
$$
\begin{equation}
E \left(X \right)= \mu = np.
(\#eq:media-binomial)
\end{equation}
$$
:::

::: {#media-binomial .proof name="Media de la Distribución Binomial"}
Por las definiciones \@ref(def:esperanza) y \@ref(def:distribucion-binomial) la esperanza una variable $X$ distribución binomialmente es

$$
\begin{align*}
E \left(X \right) =&  \sum_{x=0}^{n } x\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=& \sum_{x=1}^{n } x\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=& \sum_{x=1}^{n } \frac{n!}{\left ( x-1 \right )!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x},\\
\end{align*}
$$
en donde se ha escrito la suma desde uno hasta $n$, dado que cuando $x=0$ el primer término es cero y se cancela la $x$ del numerador con la $x$ en $x!$. Luego, factorizando $n$ y $p$, se tiene:

$$
\begin{align*}
E \left(X \right) =&  np\sum_{x=1}^{n } \frac{\left ( n-1 \right )!}{\left ( x-1 \right )!\left ( n-x \right )!}p^{x-1}\left ( 1-p \right )^{n-x}.\\
\end{align*}
$$
Si $y=x-1$ y $m=n-1$, entonces:

$$
\begin{align*}
E \left(X \right) =&  np\sum_{y=0}^{m } \frac{m!}{y!\left ( m-y \right )!}p^{y}\left ( 1-p \right )^{m-y}.\\
\end{align*}
$$
Pero $p \left(y; m, p \right)= \left[m!/y!\left(m-y \right)! \right]p^{y}\left(1-p \right)^{m-y}$ es la función de probabilidad de una variable aleatoria binomial $Y$ con parámetros $m=n-1$ y $p$; de esta manera $\sum_{y=0}^{m }p\left(y; m, p \right)=1 $, y la media de una variable aleatoria binomial es:
$$
\begin{equation}
E \left(X \right) = np.
\end{equation}
$$
:::

Note de la ecuación anterior, que para un tamaño de muestra fijo $n$, la media de la distribución binomial tiende a cero cuando $p$ tiende a cero; y tiende a $n$ cuando p tiende a uno. En otras palabras, la media de la distribución binomial disminuye cuando la probabilidad de éxito disminuye y aumenta cuando la probabilidad de éxito aumenta.   

::: {.example #ejemplo-media-distribucion-binomial name="Media de la Distribución Binomial"}
Con respecto al el ejemplo \@ref(exm:ejemplo-funcion-probabilidad-binomial), determine el número de artículos defectuosos que se esperaría encontrar en una muestra de 15 artículos.

De acuerdo con el teorema \@ref(thm:media-binomial), se esperaría encontrar
$$
\begin{equation}
E \left(X \right) = np=15 \cdot 0,05=0,75.
\end{equation}
$$
Note que el valor anterior no es un número entero, es decir, si se toma una muestra de 15 artículos no se pueden encontrar 0,75 artículos defectuosos. Recuerde que el valor esperado es un promedio, por lo que la interpretación correcta es que la media de $X$ es 0,75; es decir si se toman sucesivas muestras de 15 artículos del proceso se esperaría que la media del número de artículo defectuosos encontrados en las sucesivas muestras va a tender a 0,75.

Ahora, si se toma una muestra de 100 artículos ($n=100$) del proceso de producción, se esperaría encontrar 
$$
\begin{equation}
E \left(X \right) = np=100 \cdot 0,05=5
\end{equation}
$$
5 artículos defectuosos en la muestra.
:::

#### Varianza de la Distribución Binomial {#varianza-binomial}
La varianza de una variable aleatoria binomial $X$ es un parámetro que indica que tan distante están los posibles valores que puede tomar esta variable, es decir, $x=0, 1, 2, \dotsc, n$ con respecto a la media de la variable $\left(\mu=np \right)$. En tal sentido, la varianza de una variable binomial se describe en el siguiente teorema: 

::: {#varianza-binomial .theorem name="Varianza de la Distribución Binomial"}
Sea $X$ una variable aleatoria con distribución binomial. Entonces, la _varianza_ de $X$ viene dada por:
$$
\begin{equation}
V \left(X \right)=\sigma^2 = np \left(1-p \right).
(\#eq:media-binomial)
\end{equation}
$$
:::

Note de la ecuación anterior que para un $n$ fijo, la gráfica de la varianza es una parábola cóncava hacia abajo. Por lo tanto, el vértice de la parábola será un máximo y se halla en $p=1/2$. Es decir, la varianza es hace máxima cuando cuando $p=1/2$. Por lo que, el máximo valor de la varianza será la cuarta parte del tamaño de la muestra. 

::: {#varianza-binomial .proof name="varianza de la Distribución Binomial"}
De la \@ref(eq:varianza2) se sabe que $V \left(X \right) = E \left(X^2 \right) - \mu^2$. Como $\mu=np$, solo faltaría calcular $E \left(X^2 \right)$. Pero calcular este parámetro usando el teorema \@ref(thm:esperanza-transformacion) y la definición \@ref(def:distribucion-binomial) implica encontrar la convergencia de la siguiente expresión

$$
E \left(X^2 \right) =  \sum_{x=0}^{n } x^2\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x},
$$
lo cual es imposible. En lugar de este camino, se eligirá un método alterno. La alternativa es escribir $x^2$ como:

$$
x^2= x \left(x-1 \right)+x;
$$
de esta manera, por los teoremas \@ref(thm:esperanza-transformacion) y \@ref(thm:esperanza-suma-transformaciones), se tiene:

$$
\begin{equation}
E \left(X^2 \right)= E \left[X \left(X-1 \right) \right]+E \left(X \right).
(\#eq:varianza-alterna-binomial)
\end{equation}
$$
Dado que $E \left(X \right)$ ya se ha determinado, faltaría determinar $E \left[x \left(x-1 \right) \right]$, que según el teorema \@ref(thm:esperanza-transformacion), es:


$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =&  \sum_{x=0}^{n } x \left(x-1 \right)\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=& \sum_{x=2}^{n } x \left(x-1 \right)\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=& \sum_{x=1}^{n } \frac{n!}{\left ( x-2 \right )!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=& n \left(n-1 \right)p^2 \sum_{x=1}^{n } \frac{\left(n-2 \right)!}{\left ( x-2 \right )!\left ( n-x \right )!}p^{x-2}\left ( 1-p \right )^{n-x}.
\end{align*}
$$
Note que en los pasos previos se escribió la suma a partir de dos porque los dos primeros términos on cero, se canceló $x \left(x-1 \right)$, y se factorizó $n \left(n-1 \right)p^2$. Sea $y=x-2$ y $m=n-2$; entonces:

$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =&  n \left(n-1 \right)p^2\sum_{y=0}^{m } \frac{m!}{y!\left ( m-y \right )!}p^{y}\left ( 1-p \right )^{m-y}.\\
\end{align*}
$$
Pero $p \left(y; m, p \right)= \left[m!/y!\left(m-y \right)! \right]p^{y}\left(1-p \right)^{m-y}$ es la función de probabilidad de una variable aleatoria binomial $Y$ con parámetros $m=n-2$ y $p$; de esta manera $\sum_{y=0}^{m }p\left(y; m, p \right)=1 $. En consecuencia, 
$$
\begin{equation}
E \left[X \left(X-1 \right) \right] = n \left(n-1 \right)p^2.
\end{equation}
$$

De \@ref(eq:varianza-alterna-binomial)
$$
E \left(X^2 \right)=  n \left(n-1 \right)p^2+np.
$$

De esta maanera, la varianza de una variable aleatoria binomial, según la ecuación \@ref(eq:varianza2) es:
$$
\begin{align*}
V(X)=&n \left(n-1 \right)p^2+np-n^2p^2\\
=&np \left[ \left(n-1 \right)p + 1 - np \right]\\
=&np \left(1-p \right).
\end{align*}
$$
:::

::: {.example #ejemplo-varianza-binomial name="Varianza de la Distribución Binomial"}
Con respecto al ejemplo \@ref(exm:ejemplo-funcion-probabilidad-binomial), determine la varianza del número de artículos defectuosos encontardos en una muestra de 15 artículos tomados del proceso de producción.

De acuerdo con el teorema \@ref(thm:varianza-binomial), la varianza de $X$ es:

$$
V(X)=np \left(1-p \right)=15 \cdot0,05 \left(1-0,05 \right)=0,7125.
$$
:::

#### Función Genradora de Momentos de la Distribución Binomial {#funcion-generadora-momentos-binomial}
La función generadora de momentos es un método alternativo para determinar los momentos ordinarios de una distribución de probabilidad determinada, por medio del teorema \@ref(thm:funcion-generadora-momentos). En el caso de la distribución binomial, la función generadora de momentos se indica en el siguienete teorema: 

::: {#fgm-binomial .theorem name="Varianza de la Distribución Binomial"}
La función generadora de momentos de la distribución binomial está dada por:
$$
\begin{equation}
m_x \left(t \right)=\left[1+p \left(e^t-1 \right) \right].
(\#eq:fgm-binomial)
\end{equation}
$$
:::

::: {#fgm-binomial .proof name="Función Generadora de Momentos de la Distribución Binomial"}
De la definiciones \@ref(def:distribucion-binomial) y \@ref(def:funcion-generadora-momentos), se obtiene

$$
\begin{align*}
m_x \left(t \right)=&  \sum_{x=0}^{n } e^{tx}\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=&  \sum_{x=0}^{n } \frac{n!}{x!\left ( n-x \right )!}(e^{t}p)^{x}\left ( 1-p \right )^{n-x}.\\
\end{align*}
$$
Por el binomio de Newton, se sabe que la última sumatoria es la expansión de la expresión $\left[e^{t}p+ \left(1-p \right) \right]^n=\left[1+ p\left(e^t -1 \right) \right]^n$. En resumen,
$$
\begin{align*}
m_x \left(t \right)=\left[1+ p\left(e^t -1 \right) \right]^n.\\
\end{align*}
$$
:::

Del teorema \@ref(thm:funcion-generadora-momentos), la media de la distribucón binomial es:
$$
\begin{equation}
\frac{\mathrm{d}m_{x}\left ( t \right )}{\mathrm{d}t} \left|\begin{matrix}
 \\
t=0\\
\end{matrix}={\mu}^{'}_1=\mu \right.
\end{equation}
$$
La primera derivada de la función generadora de omentos es

$$
\frac{\mathrm{d}m_{x}\left ( t \right )}{\mathrm{d}t}=npe^t \left[1+ p\left(e^t -1 \right) \right]^{n-1}.
$$
Ahora, evaluando la primera derivada de la función generadora de momentos en $t=0$, se obtiene la media de la distribución binomial, como sigue:
$$
\begin{equation}
\frac{\mathrm{d}m_{x}\left ( t \right )}{\mathrm{d}t} \left|\begin{matrix}
 \\
t=0\\
\end{matrix}=\mu=npe^0 \left[1+ p\left(e^0 -1 \right) \right]^{n-1}=np. \right.
\end{equation}
$$
Note que este resultado es el mismo dado en el teorema \@ref(thm:media-binomial). Se deja al lector que halle la varianza de la distribución binomial usando el método de la función generadora de momentos. 


### Distribuciones Hipergeométrica {#distribuciones-hipergeometrica}

::: {#distribucion-hipergeometrica .definition name="Distribución Hipergeométrica"}
Sea $X$ una variable aleatoria que representa el número de éxitos en $n$ ensayos y $p$ la probabilidad de éxito en cualquiera de éstos. Se dice que $X$ tiene una _distribución binomial_ con parámetros $n$ y $p$, y se escribe $X\sim Bin\left ( n, p \right )$, con función de probabilidad.
$$
p\left ( x;n,p \right )=\begin{cases}
\binom{n}{x}p^{x}\left ( 1-p \right )^{n-x} & \text{ si } x= 0, 1, 2, \dotsc, n;\: 0\leq p\leq 1 \text{ y }n \in \mathbb{N}\\
0 & \text{ en cualquier otro caso }.
(\#eq:funcion-probabilidad-binomial)
\end{cases}
$$
:::


### Distribuciones de Poisson {#distribuciones-poisson}






