# Disribuciones Discretas de Probabilidad {#dist_disc}

El siguiente bloque de código permite instalar y cargar los paquetes de `r colorize("R", "blue")` que se usaran en esta sección.

```{r cargar-paquetes-nt3, class.source = "watch-out"}
packages <- c(
  "ggstatsplot", "tidyverse", "kableExtra", "plotly",
  "prob", "magrittr"
)
package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})
```


## Variable Aleatoria {#variable-aleatoria}

::: {#variable-aleatoria .definition name="Variable Aleatoria"} 
Sea un experimento aleatorio $\varepsilon$ y $S$ el espacio muestral asociado con el experimento. Una función $X$ que asigna a cada uno de los elementos $s$ de $S$, un número real $X \left(s \right)$, se llama _variable aleatoria_.
:::


### Recorrido de una Variable Aleatoria {#recorrido}

::: {#recorrido .definition name="Recorrido de una Variable Aleatoria"}
Sea $X$ una variable aleatoria, al conjunto de todos los posibles valores de $X$ se llama _recorrido de_ $X$ y se denota $R_X$.
:::

::: {.example #variable-aleatoria name="Variable Aleatoria"}
Suponga que lanzamos dos monedas ($\varepsilon$), los posibles resultados de este experimento aleatorio $S$ será
$$
S=\left\{cc, cs, sc, ss \right\}.
$$
Ahora, sobre este espacio muestra se define la variable aleatoria $X$ como sigue: $X$ es el número de caras obtenidas en los dos lanzamientos. Por lo tanto $X \left(cc \right)=2$, $X \left(cs \right)=X \left(sc \right)=1$, y $X \left(ss \right)=0$.

En este ejemplo $R_X =0,1,2$.
:::


### Variable Aleatoria Discreta {#variable-discreta}

::: {#variable-discreta .definition name="Variable Aleatoria Discreta"}
Sea $X$ una variable aleatoria. Si el número de valores posibles de $X$, es decir $R_X$, es finito o infinito numerable, se llama a $X$ una _variable aleatoria discreta_. Esto es, se pueden anotar los valores de $X$ como $x_1, x_2, \dotsc, x_n, \dots$ En el caso finito la lista termina y en el caso infinito numerable la lista continúa indefinidamente.
:::

::: {.example #variable-discreta name="Variable Aleatoria"}
Considere el experimento aleatorio $\varepsilon$ lanzar una moneda hasta que aparece una cara. En tal caso, el espacio muestral $S$ queda definido por,
$$
S=\left\{c, sc, ssc, sssc, ssssc, \dotsc \right\}.
$$
Si sobre este espacio muestral se define la variable aleatoria $X=\textrm{número de lanzamientos hata que aparece una cara}$. Entonces el recorrido de $X$, es decir $R_X$, viene definido por $R_X=1, 2, 3, \dotsc$. Dado que el recorrido de $X$ es infinito numerable se concluye que $X$ es una variable discreta.

Con respecto al ejemplo \@ref(exm:variable-discreta), la variable aleatoria $X=\textrm{el número de caras obtenidas en los dos lanzamientos}$ es discreta ya que esta toma solo cuatro valores, $R_X =\left\{0, 1, 2 \right\}$. Es decir, el recorrido de $X$ es finito.
:::


### Variable Aleatoria Continua {#variable-continua}

::: {#variable-continua .definition name="Variable Aleatoria Continua"}
Se dice que una _variable aleatoria es continua_ si su recorrido $R_X$ consiste en uno o más intervalos de la recta de los reales.

:::

::: {.example #variable-continua name="Variable Aleatoria Continua"}
Se selecciona de manera aleatoria un punto en un círculo $C$ de radio $r$. Sea $X$ la distancia del punto al centro del círculo. Entonces, $X$ es una variable aleatoria cuyo valor puede ser cualquier número entre 0 y $r$, inclusive. por tanto, el recorrido $R_X$ de $X$ es un intervalo cerrado:
$$
R_X=\left[ 0,r\right]=\left\{x:0\le x \le r \right\}.
$$
Aquí, $X$ es una variable aleatoria continua.
:::


## Función de Probabilidad {#funcion-probabilidad}

::: {#funcion-probabilidad .definition name="Función de Probabilidad"}
Sea $X$ una variable aleatoria discreta con recorrido $R_X=\left\{x_1, x_2, \dotsc \right\}$. Tal que, la probabilidad de que $X=x_i$ es $p \left(x_i \right)$, es decir, $P \left(X=x_i \right)=p \left(x_i \right)$, para $i=1,2, \dotsc$. Entonces, la función $p$ es una _función de probabilidad_ si cumple las siguientes condiciones:
$$
\begin{align*}
i)& \: p \left(x_i \right) \ge 0,\, para \: i= 1, 2, \dotsc\\
ii)& \: \sum_{i=1}^{\infty }p\left ( x_i \right )=1.
(\#eq:funcion-probabilidad)
\end{align*}
$$
:::

::: {.example #funcion-probabilidad1 name="Función de Probabilidad"}
Sea el experimento aleatorio que consiste en lanzar un par de dados equilibrados y $X$ la variable aleatoria representada por la suma de los resultados en cada dado.

Como se mostró en el ejemplo \@ref(exm:ejemp1-probcond), el espacio muestral viene dado por
$$
S=\begin{Bmatrix}
(1,1);&(1,2);&(1,3);&(1,4);&(1,5);&(1,6);\\
(2,1);&(2,2);&(2,3);&(2,4);&(2,5);&(2,6);\\
(3,1);&(3,2);&(3,3);&(3,4);&(3,5);&(3,6);\\
(4,1);&(4,2);&(4,3);&(4,4);&(4,5);&(4,6);\\
(5,1);&(5,2);&(5,3);&(5,4);&(5,5);&(5,6);\\
(6,1);&(6,2);&(6,3);&(6,4);&(6,5);&(6,6)\\
\end{Bmatrix}.
$$
Por lo que, el Recorrido de $X$ es
$R_X=\left\{2, 3, 4, 5, 6, 7, 8, 9 10, 11, 12 \right\}$, luego las probabilidades asociadas a cada $x_i$, es decir la función de probabilidad, se muestran en la tabla \@ref(tab:distribucion-probabilidad1). 

```{r distribucion-probabilidad1, class.source="watch-out", class.output = "bg-warning"}
dp_ej1 <- data.frame(
  S = c(
    "$\\left(1, 1 \\right)$",
    "$\\left(1, 2 \\right), \\left(2, 1
        \\right)$",
    "$\\left(1, 3 \\right), \\left(2, 2
        \\right), \\left(3, 1 \\right)$",
    "$\\left(1, 4 \\right), \\left(2, 3
        \\right), \\left(3, 2 \\right),
        \\left(4, 1 \\right)$",
    "$\\left(1, 5\\right), \\left(2, 4
        \\right), \\left(3, 3 \\right), 
        \\left(4, 2 \\right),\\left(5,
        1\\right)$",
    "$\\left(1, 6\\right), \\left(2, 5
        \\right), \\left(3, 4 \\right), 
        \\left(4, 3 \\right),\\left(5,
        2\\right),\\left(6, 1\\right)$",
    "$\\left(2, 6\\right), \\left(3, 5
        \\right), \\left(4, 4 \\right), 
        \\left(5, 3 \\right),\\left(6,
        2\\right)$",
    "$\\left(3, 6 \\right), \\left(4, 5
        \\right), \\left(5, 4 \\right),
        \\left(6, 3 \\right)$",
    "$\\left(4, 6 \\right), \\left(5, 5
        \\right), \\left(6, 4 \\right)$",
    "$\\left(5, 6 \\right), \\left(6, 5
        \\right)$",
    "$\\left(6, 6 \\right)$"
  ),
  xi = 2:12,
  numero_ocurrencia = c(1:6, 5:1)
) %>%
  mutate(
    p_xi = paste0(
      "$\\frac{", numero_ocurrencia, "}{36}", "\\approx ",
      format(
        round(
          x = numero_ocurrencia / 36,
          digits = 4
        ),
        mode = "double",
        big.mark = ".",
        decimal.mark = ","
      ), "$"
    )
  )
knitr::kable(
  dp_ej1,
  booktabs = TRUE,
  row.names = TRUE,
  col.names = c("Espacio Muestral", "$x_i$", "Número de ocurrencia", "$p\\left(x_i \\right)$"),
  align = c("lccc"),
  format.args = list(decimal.mark = ",", big.mark = "."),
  caption = "\\label{tab2:distribucion-probabilidad1}Distribución de probabilidad de la suma de las caras de dos dados",
  escape = FALSE
) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = FALSE,
    fixed_thead = T
  ) %>%
  kable_classic_2() %>%
  scroll_box(width = "100%", height = "400px")
```
<br>

El siguiente trozo de código de `r colorize("R", "blue")` permite replicar la tabla \@ref(tab:distribucion-probabilidad1), usando la función `urnsample` del paquete `prob`. Note que en este chunk, a diferencia del anterior, las columnas han sido creadas de manera automáticas. Lo que hace que este código sea más autorreproducible que el anterior. 

```{r distribucion-probabilidad1-ursample, class.source="watch-out", class.output = "bg-warning"}
dp <- data.frame(
  urnsamples(
    x = 1:6, size = 2, replace = T, ordered = T
  ) %>%
    dplyr::transmute(
      em = paste0("$\\left(", X2, ",", X1, " \\right)$"),
      xi = X1 + X2
    )
)
dp_urnsample <- data.frame(
  em = dp %>% split(.$xi) %>% map("em") %>%
    map_chr(str_c, collapse = "") %>%
    str_replace_all(pattern = "\\$\\$", replacement = ",  ")
) %>%
  dplyr::bind_cols(
    as.data.frame(
      table(dp$xi)
    )
  ) %>%
  dplyr::mutate(
    p_xi = paste0(
      "$\\frac{", Freq, "}{", sum(Freq), "}", "\\approx ",
      format(
        round(
          x = Freq / sum(Freq),
          digits = 4
        ),
        mode = "double",
        big.mark = ".",
        decimal.mark = ","
      ), "$"
    )
  )
knitr::kable(
  dp_urnsample,
  booktabs = TRUE,
  row.names = TRUE,
  col.names = c("Espacio Muestral", "$x_i$", "Número de ocurrencia", "$p\\left(x_i \\right)$"),
  align = c("lccc"),
  format.args = list(decimal.mark = ",", big.mark = "."),
  caption = "\\label{tab2:distribucion-probabilidad1}Distribución de probabilidad de la suma de las caras de dos dados (usando la función `ursample` del paquete `prob`)",
  escape = FALSE
) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = FALSE,
    fixed_thead = T
  ) %>%
  kable_classic_2() %>%
  scroll_box(width = "100%", height = "400px")
```
<br>
:::

Como se oberva en la tabla \@ref(tab:distribucion-probabilidad1) $p\left ( x_i \right )$ es una auténtica función de probabilidad dado que se cumplen las dos condiciones requeridas en la definición \@ref(def:funcion-probabilidad). Es decir,
$$
i) \: p \left(x_i \right) \ge 0,\, para \: i= 1, 2, \dotsc, 11; y
$$

$$
\begin{align*}
ii) \: \sum_{i=1}^{11 }p\left ( x_i \right )=& \frac{1}{36}+\frac{2}{36}+\frac{3}{36}+\frac{4}{36}+\frac{5}{36}+\frac{6}{36}\\
& +\frac{5}{36}+\frac{4}{36}+\frac{3}{36}+\frac{2}{36}+\frac{1}{36}\\
&=1.
\end{align*}
$$

En algunos casos es posible expresar la función de probabilidad a través de una expresión matemática dada en términos de la variable aleatoria. En este caso, la función de probabilidad queda determinada por la siguiente expresión:
$$
p\left ( x \right )= \begin{cases}
\frac{6-\left|x-7 \right|}{36} & \text{si } x= 2, 3, \dotsc ,12\\
0 & \text{en otros casos }.
(\#eq:funcion-probabilidad1)
\end{cases}
$$

Con la ecuación \@ref(eq:funcion-probabilidad1) también se pueden calcular las probabilidades dadas en la tabla \@ref(tab:distribucion-probabilidad1), tal como se muestra a continuación:
$$
\begin{align*}
 P(X=2)&=p\left (2  \right )= \frac{6-\left|2- 7\right|}{36}=\frac{1}{36}\\
 P(X=3)&=p\left (3  \right )= \frac{6-\left|3- 7\right|}{36}=\frac{2}{36} \\
 P(X=4)&=p\left (4  \right )= \frac{6-\left|4- 7\right|}{36}=\frac{3}{36} \\
 P(X=5)&=p\left (5  \right )= \frac{6-\left|5- 7\right|}{36}=\frac{4}{36} \\
 P(X=6)&=p\left (6  \right )= \frac{6-\left|6- 7\right|}{36}=\frac{5}{36} \\
 P(X=7)&=p\left (7  \right )= \frac{6-\left|7- 7\right|}{36}=\frac{6}{36} \\
 P(X=8)&=p\left (8  \right )= \frac{6-\left|8- 7\right|}{36}=\frac{5}{36} \\
 P(X=9)&=p\left (9  \right )= \frac{6-\left|9- 7\right|}{36}=\frac{4}{36} \\
 P(X=10)&=p\left (10  \right )= \frac{6-\left|10- 7\right|}{36}=\frac{3}{36} \\
 P(X=11)&=p\left (11  \right )= \frac{6-\left|11- 7\right|}{36}=\frac{2}{36} \\
 P(X=12)&=p\left (12  \right )= \frac{6-\left|12- 7\right|}{36}=\frac{1}{36} \\. 
 \end{align*}
$$
Como se puede notar, las probabilidades determinadas con esta ecuación se corresponden con las que se muestran en la tabla \@ref(tab:distribucion-probabilidad1).

Una forma de visualizar de manera rápida las probabilidades asociadas a cada valor de la variable aleatoria es a través de una gráfica de líneas verticales que comienzan en cada valor de la variable $x_i$ y cuya altura está determinada por sus probabilidades $p\left (x_i  \right )$. El gráfico de la función de  probabilidad para la suma de las caras en el lanzamiento de los dos dados se muestra en la figura \@ref(fig:grafico-distribucion-probabilidad1).

```{r grafico-distribucion-probabilidad1, fig.cap = "Gráfica de la función de probabilidad de la suma de las caras de dos dados", class.source = "watch-out"}
plot_ly(data = dp_ej1, alpha = 0.5) %>%
  add_segments(
    x = ~xi, 
    y = ~rep(x = 0, times = length(xi)),
    xend = ~xi, 
    yend = ~(numero_ocurrencia / 36), 
    color = I("red"), 
    showlegend = FALSE,
    name = ""
  ) %>%
  add_markers(
    x = ~xi, 
    y = ~numero_ocurrencia / 36, 
    color = I("red"), 
    showlegend = FALSE,
    name = ""
  ) %>%  
  layout(
    xaxis = list(
      title = TeX("\\text{Suma de las caras} \\left(x \\right)"), 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("p \\left(x \\right)"),
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = FALSE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```


## Función de Distribución Acumulativa de Probabilidad {#funcion-distribucion}

Existen muchos problemas en los que es necesario calcular la probabilidad de que el valor observado de una variable aleatoria $X$ sea menor o igual que algún número real $x$. Al escribir $F \left(x \right) = P \left(X \leq x \right)$ para cualquier número real $x$, se define $F \left(x \right)$ como la función de distribución acumulativa de probabilidad de la variable aleatoria $X$. De manera formal, la función de distribución acumulativa de probabilidad se define de la siguiente manera:

::: {#funcion-acumulativa-probabilidad .definition name="Función de Distribución Acumulativa de Probabilidad"}
Sea $X$ una variable aleatoria discreta con función de probabilidad $p \left(x_i \right)$. Entonces, la función de distribución acumulativa de probabilidad de $X$, denotada como $F \left(X \right)$, viene dada por:
$$
\begin{equation}
F\left ( x \right )=P\left ( X \leq x \right )=\sum_{t=x_1}^{x} p\left ( t \right ), \, \textrm{ para} \:\, t \leq x.
(\#eq:distribucion-probabilidad)
\end{equation}
$$
:::


### Propiedades de la Función de Distribución Acumulativa de Probabilidad {#propiedades-funcion-distribucion}

Dentro de las propiedades más importantes de la función de distribución acumulativa de probabilidad se pueden mencionar las siguientes:
$$
\begin{align*}
i)& \: 0 \leq F\left ( x \right ) \leq 1 \:\: \textrm{par cualquier}\:x, \\
ii)& \:\displaystyle \lim_{x \to - \infty }F\left ( x \right )=0,\\
iii)& \:\displaystyle \lim_{x \to  \infty }F\left ( x \right )=1,\\
iv)& \: F\left ( x_{j} \right ) \geq F\left ( x_{i} \right ) \:\: \textrm{si} \: x_{i} \leq x_{j},\\
v)& \: F\left ( x_{i} \right ) = F\left ( x_{i-1} \right ) + p\left ( x_{i} \right ),\\
vi)& \: P\left ( X > x_{i} \right ) = 1 - F\left ( x_{i} \right ), \\
vii)& \: P\left ( X <  x_{i} \right ) = F\left ( x_{i-1} \right ), \\
viii)& \: P\left ( X \geq  x_{i} \right ) = 1 - F\left ( x_{i-1} \right ), \\
ix)& \: P\left ( X=x_{i} \right )=p \left(x_{i} \right)=F\left ( x_{i} \right )-F\left ( x_{i-1} \right ), \\
x)& \: P\left ( x_{i} \leq X \leq x_{j} \right )=F\left ( x_{j} \right )-F\left ( x_{i-1} \right ) \: \textrm{si} \: x_{i} \leq x_{j},\\
xi)& \: P\left ( x_{i} <  X \leq x_{j} \right )=F\left ( x_{j} \right )-F\left ( x_{i} \right ) \: \textrm{si} \: x_{i} \leq x_{j},\\ 
xii)& \: P\left ( x_{i} \leq   X <  x_{j} \right )=F\left ( x_{j-1} \right )-F\left ( x_{i-1} \right ) \: \textrm{si} \: x_{i} \leq x_{j},\\
xiii)& \: P\left ( x_{i} <   X <  x_{j} \right )=F\left ( x_{j-1} \right )-F\left ( x_{i} \right ) \: \textrm{si} \: x_{i} \leq x_{j}.\\
\end{align*}
$$

::: {.example #funcion-probabilidad1 name="Función de Distribución Acumulativa"}
Determine la función de distribución acumulativa de probabilidad del ejemplo \@ref(exm:funcion-probabilidad1).

La función de distribución acumulativa de probabilidad en este caso viene dada, de acuerdo con la definición \@ref(def:funcion-acumulativa-probabilidad), por:
$$
\begin{align*}
 F(2)&=P\left ( X \leq 2 \right )=p\left (2  \right )= \frac{1}{36}\\
 F(3)&=P\left ( X \leq 3 \right )= p\left (2  \right )+p\left (3  \right )= \frac{1}{36} + \frac{2}{36} =\frac{3}{36} \\
F(4)&=P\left ( X \leq 4 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}=\frac{6}{36} \\
F(5)&=P\left ( X \leq 5 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}=\frac{10}{36} \\
F(6)&=P\left ( X \leq 6 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}=\frac{15}{36} \\
F(7)&=P\left ( X \leq 7 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}=\frac{21}{36} \\
F(8)&=P\left ( X \leq 8 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&+p\left (8  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}+ \frac{5}{36}=\frac{26}{36} \\
F(9)&=P\left ( X \leq 9 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&+p\left (8  \right )+p\left (9  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}+ \frac{5}{36}+ \frac{4}{36}=\frac{30}{36} \\
F(10)&=P\left ( X \leq 10 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&+p\left (8  \right )+p\left (9  \right )+p\left (10  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}+ \frac{5}{36}+ \frac{4}{36}+ \frac{3}{36}\\&=\frac{33}{36} \\
F(11)&=P\left ( X \leq 11 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&+p\left (8  \right )+p\left (9  \right )+p\left (10  \right )+p\left (11  \right )\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}+ \frac{5}{36}+ \frac{4}{36}+ \frac{3}{36}\\&+ \frac{2}{36}=\frac{35}{36} \\
F(12)&=P\left ( X \leq 12 \right )= p\left (2  \right )+p\left (3  \right )+p\left (4  \right )+p\left (5  \right )+p\left (6  \right )+p\left (7  \right )\\&+p\left (8  \right )+p\left (9  \right )+p\left (10  \right )+p\left (11  \right )+p\left (12  \right)\\&= \frac{1}{36} + \frac{2}{36} + \frac{3}{36}+ \frac{4}{36}+ \frac{5}{36}+ \frac{6}{36}+ \frac{5}{36}+ \frac{4}{36}+ \frac{3}{36}\\&+ \frac{2}{36}+ \frac{1}{36}=\frac{36}{36}=1 \\.   
\end{align*}
$$

Los resultados anteriores pueden resumirse en la tabla \@ref(tab:distribucion-acumulada1).

```{r distribucion-acumulada1, class.source="watch-out", class.output = "bg-warning"}
dp_ej1 <- dp_ej1 %>% 
  mutate(
    F_xi = paste0(
      "$\\frac{", cumsum(numero_ocurrencia), "}{36}",
      "\\approx ",
      format(
        round(
          x = cumsum(numero_ocurrencia / 36),
          digits = 4
        ),
        mode = "double",
        big.mark = ".",
        decimal.mark = ","
      ), "$"
    )
  )
knitr::kable(
  dp_ej1,
  booktabs = TRUE,
  row.names = TRUE,
  col.names = c("Espacio Muestral", "$x_i$", "Número de ocurrencia", "$p\\left(x_i \\right)$", "$F\\left(x_i \\right)$"),
  align = c("lccc"),
  format.args = list(decimal.mark = ",", big.mark = "."),
  caption = "\\label{tab2:distribucion-acumulada1}Función de distribución acumulativa de la suma de las caras de dos dados",
  escape = FALSE
) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = FALSE,
    fixed_thead = T
  ) %>%
  kable_classic_2() %>% 
  scroll_box(width = "100%", height = "400px")
```
<br>

Cuando se conoce la expresión que define la función de probabilidad, la cual, en este caso está dada por la ecuación \@ref(eq:funcion-probabilidad1), se puede determinar una expresión matemática que defina la función de distribución acumulativa de probabilidad. A continuación se ejecuta un procedimiento para hallar esta ecuación.

$$
\begin{align*}
F\left ( x \right )=\sum_{t=2}^{x}p\left ( x \right ) =\sum_{t=2}^{x}\frac{6-\left|7-x \right|}{36}. 
\end{align*}
$$

Como la expresión $\left|7-x \right|$ es positiva si $x=2, 3, \dotsc, 7$ y negativa si $x=8, 9, \dotsc, 12$. Entonces, se derivan expresiones para  $F\left ( x \right )$ en cada uno de estos casos.

1.  si $x=2, 3, \dotsc, 7$
$$
\begin{align*}
 F\left ( x \right )&= \sum_{t=2}^{x}\frac{6-\left|7-x \right|}{36}=\frac{1}{36}\sum_{t=2}^{x}\left ( 6-7+x \right )=\frac{1}{36}\sum_{t=2}^{x}\left ( t-1 \right )\\
&=\frac{1}{36}\left [ \sum_{t=2}^{x}t-\sum_{t=2}^{x}1 \right ]=\frac{1}{36}\left [ \left ( 2+3+\cdots +x \right )-\left ( x-1 \right ) \right ]\\
&=\frac{1}{36}\left [ \left ( \frac{2+x}{2} \right )\left ( x-1 \right )-\left ( x-1 \right ) \right ] = \frac{1}{36}\left ( x-1 \right )\left ( \frac{2+x}{2} -1 \right )\\
&=\frac{1}{36}\left ( x-1 \right )\left ( \frac{2+x-2}{2} \right )=\frac{1}{72}x\left ( x-1 \right ).
\end{align*}
$$
2.  si $x=8, 9, \dotsc, 12$
$$
\begin{align*}
 F\left ( x \right )&=\sum_{t=8}^{x}\frac{6-\left|7-x \right|}{36}=\frac{1}{36}\sum_{t=8}^{x}\left ( 6+7-x \right )\\
&=\frac{1}{36}\sum_{t=8}^{x}\left ( 13-x \right )=\frac{1}{36}\left [ \sum_{t=8}^{x}13-\sum_{t=8}^{x}x \right ]\\
&=\frac{1}{36}\left [ 13\left ( x-7 \right )-\left ( \frac{8+x}{2} \right )\left ( x-7 \right ) \right ]\\
&=\frac{1}{36}\left [ \left ( x-7 \right )\left ( 13-\left ( \frac{8+x}{2} \right ) \right ) \right ]\\
&=\frac{1}{36}\left [ \left ( x-7 \right )\left ( \frac{26-8-x}{2} \right ) \right ]=\frac{1}{72}\left ( x-7 \right )\left ( x-8 \right ).
\end{align*}
$$

En resumen, la función de distribución acumulada puede expresarse de la siguiente manera:
$$
F\left ( x \right )=
\begin{cases}
0 & \textrm{ si } x< 2 \\
\frac{1}{72}x\left ( x-1 \right ) & \textrm{ si } x=2, 3,\dotsc,7 \\
\frac{42}{72}+\frac{1}{72}\left ( x-7 \right )\left ( 18-x \right ) & \textrm{ si } x=8, 9, \dotsc,12 \\
1 & \textrm{ si } x>1. 
(\#eq:funcion-dictribucion1)
\end{cases}
$$

Se puede verificar que los valores de $F\left ( x \right )$  dados en la tabla \@ref(tab:distribucion-acumulada1) se corresponden con los que se obtienen con la ecuación \@ref(eq:funcion-dictribucion1). Por ejemplo:
$$
\begin{align*}
a)& \: F\left ( 7 \right )=\frac{1}{72}7\left ( 7-1 \right )=\frac{42}{72}=\frac{21}{36}\\
b)& \: F\left ( 10 \right )=\frac{42}{72}+\frac{1}{72}\left ( 10-7 \right )\left ( 18-10\right)=\frac{42}{72}+\frac{24}{72}=\frac{66}{72}=\frac{33}{36}.
\end{align*}
$$
:::

La figura \@ref(fig:grafico-distribucion-acumulada1) muestra la gráfica de la función de distribución acumulativa de la suma de las caras de los dados. Note que esta gráfica es escalonada. 

```{r grafico-distribucion-acumulada1, fig.cap = "Gráfica de la función de distribución acumulativa de la suma de las caras de dos dados", class.source = "watch-out", class.output = "bg-warning"}
plot_ly(dp_ej1, alpha = 0.5) %>%
  add_segments(
    x = ~c(0, xi), 
    y = ~cumsum(c(0, numero_ocurrencia / 36)),
    xend = ~c(xi, 14), 
    yend = ~cumsum(c(0, numero_ocurrencia / 36)), 
    color = I("red"),
    showlegend = FALSE,
    name = ""
  ) %>%
  add_markers(
    x = ~xi, 
    y = ~cumsum(numero_ocurrencia / 36), 
    color = I("red"),
    showlegend = FALSE,
    name = ""
  ) %>%
  add_markers(
    x = ~xi, 
    y = ~cumsum(c(0, numero_ocurrencia[-11] / 36)), 
    color = I("red"),
    marker = list(symbol = "circle-open"),
    showlegend = FALSE,
    name = ""
  )  %>% 
  layout(
    xaxis = list(
      title = TeX(
        "\\text{Suma de las caras de los dados} \\left(X \\right)"
      ),
      scaleanchor = "xi",
      scaleratio = 1,
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("F\\left(x \\right)"),
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = FALSE
  ) %>%
   config(locale = "es", mathjax = "cdn")
```


## Esperanza Mateática de Una Variable Aleatoria Discreta {#esperanza-matematica}

::: {#esperanza .definition name="Esperanza Mateática de Una Variable Aleatoria Discreta"}
Sea $X$ una variable aleatoria discreta con la función de probabilidad $p \left(x \right)$. Entonces la
esperanza matemática, media o valor esperado de$X$, denotado por $E \left(x \right)$ o simplemente $\mu$, se define como
$$
\begin{equation}
\mu=E \left(X \right)=\sum_{x}x p \left(x \right).
(\#eq:esperanza)
\end{equation}
$$
:::

::: {.example #esperanza name="Esperanza Matemática de Una Variable Aleatoria discreta"}
Calcule el valor esperado de la variable aleatoria $X$  representada por la suma de los resultados del lanzamiento de dos dados descrita en el ejemplo \@ref(exm:funcion-probabilidad1).

De acuerdo con la definición \@ref(def:esperanza), en este caso la esperanza viene dada por:
$$
\begin{align*}
\mu=&E\left(X \right)=\sum_{x=2}^{12 }xp\left ( x \right )= 2 \left(\frac{1}{36}\right)+3\left(\frac{2}{36}\right)+4\left(\frac{3}{36}\right)+5\left(\frac{4}{36}\right)+6\left(\frac{5}{36}\right)+7\left(\frac{6}{36}\right) \\
& +8\left(\frac{5}{36}\right)+9\left(\frac{4}{36}\right)+10\left(\frac{3}{36}\right)+11\left(\frac{2}{36}\right)+12\left(\frac{1}{36}\right)\\
&=7.
\end{align*}
$$
Este valor significa que si se lanzan los dos dados un número significativamente grande de veces, el promedio de la suma de las caras va estar próximo a 7. 

En `r colorize("R", "blue")`, el resultado anterior se puede obtener con el siguiente script.
```{r esperanza}
x <- 2:12
p_x <- c(1:6,5:1) / 36
(media <- sum(x * p_x))
```
:::

En muchos problemas de estadística no solo es de interés el valor esperado de la variable $X$, como se definió en \@ref(def:esperanza), sino también el valor esperado de alguna variable $Y$ que es una transformación de $X$, es decir $g\left(x \right)$. Por ejemplo, $y=g\left(x \right)=x^2$. En tal sentido, se establece el teorema siguiente:

::: {#esperanza-transformacion .theorem}
Si $X$ es una variable aleatoria discreta con función de probabilidad $p\left(x \right)$. Entonces, el valor esperado de la variable aleatoria $g\left(x \right)$ está dado por
$$
\begin{equation}
E \left[g\left(x \right) \right]=\sum_{x}g\left(x \right) p \left(x \right).
(\#eq:esperanza-transformacion)
\end{equation}
$$
:::

En algunos casos el calculo de esperanzas matemáticas se simplifican mediante el uso de los siguientes teoremas, los cuales permiten calcular valores esperados a partir de otras esperanzas conocidas o que se determinan con menor dificultad. 

::: {#esperanza-transformacion-lineal .theorem}
Si $X$ es una variable aleatoria discreta con función de probabilidad $p\left(x \right)$ y sean $a$ y $b$ constantes. Entonces,
$$
\begin{equation}
E \left( ax+b \right)=a  E \left( x \right)+b.
(\#eq:esperanza-transformacion-lineal)
\end{equation}
$$
:::

Note que si se hace $a=0$ en el teorema \@ref(thm:esperanza-transformacion) se obtiene el siguiente corolario:

::: {#corolario1 .corollary}
Si $X$ es una variable aleatoria discreta con función de probabilidad $p\left(x \right)$ y $a$ una constantes. Entonces,
$$
\begin{equation}
E \left( ax \right) = a E \left( x \right).
(\#eq:corolario1)
\end{equation}
$$
:::

Mientras que si se hace $b=0$ en el teorema \@ref(thm:esperanza-transformacion) se obtiene este otro: 

::: {#corolario2 .corollary}
Si $X$ es una variable aleatoria discreta con función de probabilidad $p\left(x \right)$ y $b$ una constantes. Entonces,
$$
\begin{equation}
E \left( b \right) = b.
(\#eq:corolario2)
\end{equation}
$$
:::

Observe que si se escribe $E \left( b \right)$, la constante $b$ se puede ver como una variable aleatoria que siempre toma el valor $b$.

Otro teorema importante relacionado con la esperanza de transformaciones de variables aleatoria es el siguiente:

::: {#esperanza-suma-transformaciones .theorem}
Si $X$ es una variable aleatoria discreta con función de probabilidad $p\left(x \right)$. Además, considere que $c_1, c_2, \dotsc, c_n$ son constantes y $g_1\left(x \right), g_2\left(x \right), \dotsc, g_n\left(x \right)$ transformaciones de $X$. Entonces,
$$
\begin{equation}
E \left[\sum_{i=1}^{n}c_i g_i\left(x \right) \right]=\sum_{i=1}^{n}c_iE \left[ g_i\left(x \right) \right].
(\#eq:esperanza-suma-transformaciones)
\end{equation}
$$
:::


## Varianza de Una Variable Aleatoria Discreta {#varianza}

::: {#varianza .definition name="Varianza de Una Variable Aleatoria Discreta"}
Sea $X$ una variable aleatoria con distribución de probabilidad $p \left(x \right)$ y media $\mu$. La varianza
de $X$, denotado por $\sigma^2$ o $E \left[\left(X −μ \right)^2 \right]$ es

$$
\begin{equation}
\sigma^2=E \left[\left(X −μ \right)^2 \right]=\sum_{x}\left(X −μ \right)^2 p \left(x \right).
(\#eq:varianza)
\end{equation}
$$
La raíz cuadrada positiva de la varianza, $\sigma$, se llama desviación estándar de $X$.
:::

Una ecuación alternativa para la varianza se obtiene de la siguiente manera. Primero, se desarrolla la expresión $\left(X −μ \right)^2$ dada en la ecuación \@ref(eq:varianza), como sigue.
$$
\sigma^2=E \left[\left(X −μ \right)^2 \right]=E\left(X^2-2\mu X +\mu^2 \right).
$$
Luego, por el teorema \@ref(thm:esperanza-suma-transformaciones) y el corolario \@ref(cor:corolario1), se obtiene
$$
\sigma^2=E \left[\left(X −μ \right)^2 \right]=E\left(X^2 \right)-2\mu E \left(X \right) +\mu^2 .
$$
Como $E \left(X \right)=\mu$, entonces
$$
\begin{equation}
\sigma^2=E \left[\left(X −μ \right)^2 \right]=E\left(X^2 \right)-\mu^2.
(\#eq:varianza2)
\end{equation}
$$

::: {.example #varianza name="Varianza de Una Variable Aleatoria Discreta"}
Calcule el valor esperado de la variable aleatoria $X$  representada por la suma de los resultados del lanzamiento de dos dados descrita en el ejemplo \@ref(exm:funcion-probabilidad1).

De acuerdo con la definición \@ref(def:varianza), la varianza de la suma delas caras de los dados es:


$$
\begin{align*}
\sigma^2=&\sum_{x=2}^{12}\left(x −μ \right)^2p\left ( x \right )= \left(2-7 \right)^2 \left(\frac{1}{36}\right)+\left(3-7 \right)^2\left(\frac{2}{36}\right)+\left(4-7 \right)^2\left(\frac{3}{36}\right)+\left(5-7 \right)^2\left(\frac{4}{36}\right) \\
&+\left(6-7 \right)^2\left(\frac{5}{36}\right)+\left(7-7 \right)^2\left(\frac{6}{36}\right) +\left(8-7 \right)^2\left(\frac{5}{36}\right)+\left(9-7 \right)^2\left(\frac{4}{36}\right)+\left(10-7 \right)^2\left(\frac{3}{36}\right) \\
&+\left(11-7 \right)^2\left(\frac{2}{36}\right)+\left(12-7 \right)^2\left(\frac{1}{3
6}\right)\\
&=\frac{35}{6} \approx 5,83.
\end{align*}
$$
Mientras que la desviación estándar es,
$$
\sigma = \sqrt{\frac{35}{6}} \approx 2,42.
$$
Usando la ecuación alternativa para la varianza dada en la ecuación \@ref(eq:varianza2), el valor de este parámetro se se obtiene como sigue
$$
\begin{align*}
\sigma^2=&\sum_{x=2}^{12}x^2p\left ( x \right )-\mu^2= \left(2 \right)^2 \left(\frac{1}{36}\right)+\left(3 \right)^2\left(\frac{2}{36}\right)+\left(4 \right)^2\left(\frac{3}{36}\right)+\left(5 \right)^2\left(\frac{4}{36}\right)\\
&+\left(6 \right)^2\left(\frac{5}{36}\right) +\left(7 \right)^2\left(\frac{6}{36}\right) +\left(8 \right)^2\left(\frac{5}{36}\right)+\left(9 \right)^2\left(\frac{4}{36}\right)+\left(10 \right)^2\left(\frac{3}{36}\right)+\left(11 \right)^2\left(\frac{2}{36}\right)\\
&+\left(12 \right)^2\left(\frac{1}{3
6}\right) - \left(7 \right)^2\\
& =\frac{329}{6} - 49=\frac{35}{6} \approx 5,83.
\end{align*}
$$

El valor de la varianza y la desviación estándar obtenidos anteriormente se pueden calcular en `r colorize("R", "blue")` con el siguiente script.
```{r varianza}
(varianza <-  sum((x - media) ^ 2 * p_x))
(desviacion <- sqrt(varianza))
```
:::


## Función Generadora de Momentos de Una Variable Aleatoria Discreta {#funcion-generadora-momentos}

::: {#funcion-generadora-momentos .definition name="Función Generadora de Momentos de Una Variable Aleatoria Discreta"}
Sea $X$ una variable aleatoria discreta con función de probabilidad $p \left(x \right)$. El valor esperado de $e^{tx}$ recibe el nombre de _función generadora de momentos_, y se denota por $m_x \left(t \right)$
de $X$, si el valor esperado existe en algún intervalo $-c<t<c$ en donde $c$ es un entero positivo. En otros términos:

$$
\begin{equation}
m_x \left(t \right)=E \left(e^{tx} \right) =\sum_{x}e^{tx} p \left(x \right), \:si\: -c<t<c.
(\#eq:funcion-generadora-momentos)
\end{equation}
$$
:::

::: {#funcion-generadora-momentos .theorem}
Si $X$ es una variable aleatoria con función generadora de momentos $m_x \left(t \right)$. Entonces,
$$
\begin{equation}
\frac{\mathrm{d}^{k}m_{x}\left ( t \right )}{\mathrm{d}t^{k}} \left|\begin{matrix}
 \\
t=0\\
\end{matrix}={\mu}^{'}_k \right.
(\#eq:funcion-generadora-momentos)
\end{equation}
$$
:::

En muchas situaciones cundo se trabaja con variables aleatorias se definen transformaciones lineales sobre estas variables. En tales casos, si se conoce la función generadora de momentos de estas variables se pueden obtener las funciones generadoras de momentos de esas transformaciones por medio del teorema que sigue:

::: {#propiedades-funcion-generadora-momentos .theorem}
Si $X$ es una variable aleatoria con función generadora de momentos $m_x \left(t \right)$. Entonces,
$$
\begin{align*}
i)&\:m_{x+a}\left ( t \right )= E\left [ e^{\left ( x+a \right )t} \right ]=e^{at} \cdot m_{x}\left ( t \right )\\
ii)&\: m_{bx}\left ( t \right )= E\left ( e^{bxt} \right )=m_{x}\left ( bt \right )\\
iii)&\: m_{\frac{x+a}{b}} =E\left [ e^{\left ( \frac{x+a}{b} \right )t} \right ] =e^{\frac{a}{b}t} \cdot m_{x}\left ( \frac{t}{b} \right ).
(\#eq:propiedades-teorema-funcion-generadora-momentos)
\end{align*}
$$
:::


## Distribuciones de Probabilidad Notables {#distribuciones-notables}

En esta sección se definen algunas distribuciones de probabilidad de gran importancia por sus múltiples aplicaciones en la descripción de fenómenos que ocurren en la vida diaria, tales como: la _distribución binomial_, la _distribución hipergeométrica_ y la _distribución de Poisson_.


### Distribución Binomial {#distribucion-binomial}

::: {#distribucion-binomial .definition name="Distribución Binomial"}
Sea $X$ una variable aleatoria que representa el número de éxitos en $n$ ensayos y $p$ la probabilidad de éxito en cualquiera de éstos. Se dice que $X$ tiene una _distribución binomial_ con parámetros $n$ y $p$, y se escribe $X\sim Bin\left ( n, p \right )$, con función de probabilidad.
$$
p\left ( x;n,p \right )=\begin{cases}
\binom{n}{x}p^{x}\left ( 1-p \right )^{n-x} & \text{ si } x= 0, 1, 2, \dotsc, n;\: 0\leq p\leq 1 \text{ y }n \in \mathbb{N}\\
0 & \text{ en cualquier otro caso }.
(\#eq:funcion-probabilidad-binomial)
\end{cases}
$$
:::

La figura \@ref(fig:grafico-distribucion-binomial) muestra la gráfica de la función de probabilidad binomial para $n=10$ y $p = 0,2; 0,5; 0,8$. Como se observa en esta gráfica la distribución binomial es asimétrica positiva para $p = 0,1$; simétrica para $p = 0,5$ y asimétrica negativa para $p = 0,8$. De manera general, esta distribución de probabilidad es asimétrica positiva para $p < 0,5$, simétrica si $p = 0,5$ y asimétrica negativa si $p > 0,5$.

```{r grafico-distribucion-binomial, fig.cap = "Gráfica de la función de probabilidad binomial para $n = 10$ y $p = 0,2; 0,5; 0,8$", class.source = "watch-out"}
plot_ly(alpha = 0.5) %>%
  add_segments(
    x = ~c(0:10), y = ~rep(x = 0, times = 11),
    xend = ~c(0:10), yend = ~dbinom(0:10, 10, 0.2), 
    color = I("red"), showlegend = TRUE,
    name = TeX("n = 10, p = 0,2")
  ) %>%
  add_markers(
    x = ~c(0:10), y = ~dbinom(0:10, 10, 0.2), 
    color = I("red"), showlegend = TRUE,
    name = TeX("n = 10, p = 0,2")
  ) %>%
  add_segments(
    x = ~c(0:10), y = ~rep(x = 0, times = 11),
    xend = ~c(0:10), yend = ~dbinom(0:10, 10, 0.5), 
    color = I("blue"), showlegend = TRUE,
    name = TeX("n = 10, p = 0,5")
  ) %>%
  add_markers(
    x = ~c(0:10), y = ~dbinom(0:10, 10, 0.5), 
    color = I("blue"), showlegend = TRUE,
    name = TeX("n = 10, p = 0,5")
  ) %>%
  add_segments(
    x = ~c(0:10), y = ~rep(x = 0, times = 11),
    xend = ~c(0:10), yend = ~dbinom(0:10, 10, 0.8), 
    color = I("green"), showlegend = TRUE,
    name = TeX("n = 10, p = 0,8")
  ) %>%
  add_markers(
    x = ~c(0:10), y = ~dbinom(0:10, 10, 0.8), 
    color = I("green"), showlegend = TRUE,
    name = TeX("n = 10, p = 0,8")
  ) %>% 
  layout(
    xaxis = list(
      title = TeX("x"), 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("p \\left(x; n, p\\right)"),
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```

::: {.example #ejemplo-funcion-probabilidad-binomial name="Función de Probabilidad Binomial"}
Todos los días se seleccionan, de manera aleatoria, 15 artículos de un proceso de producción con el propósito de vigilar la fracción de artículos defectuosos que produce el proceso. Con base en información pasada, la probabilidad de que el proceso produzca un artículo defectuoso es 0,05. Determine la probabilidad de que se encuentren dos artículos defectuosos en la muestra.

Dado que $X$ representa el número de artículo defectuosos encontrados en una muestra de tamaño 15 ($n=15$) y que la probabilidad de que cualquier artículo en la muestra sea defectuoso es constante e igual a 0,05 ($p = 0,05$). Entonces, de acuerdo con la definición \@ref(def:distribucion-binomial), $X$ tiene distribución binomial con parámetros $n = 15$ y $p = 0,05$, es decir, $X \sim Bin\left(n = 15, p = 0,05 \right)$. Por lo tanto, de acuerdo con la ecuación \@ref(eq:funcion-probabilidad-binomial),

$$
P\left(X = 2 \right)=p\left ( x = 2;n = 15,p = 0,05 \right )=
\binom{15}{2}\left(0,05 \right)^{2}\left ( 1- 0,05 \right )^{15-2} \approx `r formato(dbinom(x = 2, size = 15, prob = 0.05, log = FALSE))`.
$$
La función `dbinom(x, size, prob, log = FALSE)` de la distribución base de `r colorize("R", "blue")` permite evaluar la función de probabilidad binomial dada por la ecuación \@ref(eq:funcion-probabilidad-binomial). El siguiente script permite obtener el resultado anterior.

```{r ejemplo-funcion-probabilidad-binomial}
dbinom(x = 2, size = 15, prob = 0.05, log = FALSE)
```

La figura \@ref(fig:funcion-probabilidad-binomial) muestra la gráfica de la función de probabilidad del número de artículos defectuosos en una muestra de 15 artículos ($X$). La cual, como se sabe, tiene distribución binomial con parámetros $n = 15$ y $p = 0,05$. Es decir, $X \sim Bin \left(n = 15, p = 0,05 \right)$. 

```{r funcion-probabilidad-binomial, fig.cap = "Gráfica de la función de probabilidad binomial para $n = 15$ y $p = 0,05$", class.source = "watch-out"}
plot_ly(alpha = 0.5) %>%
  add_segments(
    x = 0:15, 
    y = ~rep(x = 0, times = length(0:15)),
    xend = 0:15, 
    yend = ~dbinom(
      x = 0:15, size = 15, prob = 0.05, log = FALSE
    ), 
    color = I("red"), 
    showlegend = FALSE,
    name = ""
  ) %>%
  add_markers(
    x = 0:15, 
    y = ~dbinom(
      x = 0:15, size = 15, prob = 0.05, log = FALSE
    ), 
    color = I("red"), showlegend = FALSE,
    name = ""
  ) %>%  
  layout(
    xaxis = list(
      title = TeX("x"), 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("p \\left(x; n= 15, p = 0,05 \\right)"),
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = FALSE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```

:::


#### Función de Distribución Acumulativa de Probabilidad Binomial {#distribucion-acumulada-binomial}

La probabilidad de que una variable aleatoria binomial $X$ sea menor o igual que un valor específico $x$ o dicho de otra manera la probabilidad de encontrar a los más $x$ éxitos en los $n$ ensayos, o lo que es igual,la función de distribución acumulativa de probabilidad binomial, queda determinada, de acuerdo con las definiciones \@ref(def:funcion-acumulativa-probabilidad) y \@ref(def:distribucion-binomial) por:

::: {#distribucion-acumulada-binomial .definition name="Función de Distribución Acumulativa de Probabilidad Binomial"}
Sea $X$ una variable aleatoria con distribución binomial. Entonces, la _función de distribución acumulativa de probabilidad binomial_ viene dada por:
$$
F\left ( x;n,p \right )=\begin{cases}
0 & \text{ si } x < 0\\
 \sum_{t=0}^{x } \binom{n}{t}p^{t}\left ( 1-p \right )^{n-t} & \text{ si } x= 0, 1, 2, \dotsc, n;\: 0\leq p\leq 1 \text{ y }n \in \mathbb{N}\\
1 & \text{ si } x > n.
(\#eq:funcion-acumulativa-binomial)
\end{cases}
$$
:::

La figura \@ref(fig:grafico-acumulativa-binomial) muestra la función de distribución acumulativa de probabilidad para una variable binomial con parámetros $n = 10$ y $p = 0,2; 0,5; 0,8$. 

```{r grafico-acumulativa-binomial, fig.cap = "Gráfica de la función de distribución acumulativa de probabilidad binomial para $n = 15$ y $p = 0,2;0,5;0,8$", class.source = "watch-out"}
x <- c(-3, 0:10, 13)
px1  <-  dbinom(x = x, size = 10, prob = 0.2)
Fx1  <-  pbinom(q = x, size = 10, prob = 0.2)
px2  <-  dbinom(x = x, size = 10, prob = 0.5)
Fx2  <-  pbinom(q = x, size = 10, prob = 0.5)
px3  <-  dbinom(x = x, size = 10, prob = 0.8)
Fx3  <-  pbinom(q = x, size = 10, prob = 0.8)
plot_ly(x = x, y = Fx1, alpha = 0.5) %>%
  add_segments(
    x = ~x[1:12], 
    y = ~Fx1[1:12],
    xend = ~x[2:13], 
    yend = ~Fx1[1:12], 
    color = I("red"),
    name = TeX("n = 10, p = 0,2"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx1[2:12], 
    color = I("red"),
    name = TeX("n = 10, p = 0,2"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx1[1:11], 
    color = I("red"),
    marker = list(symbol = "circle-open"),
    name = TeX("n = 10, p = 0,2"),
    showlegend = TRUE
  )  %>%
  add_segments(
    x = ~x[1:12], 
    y = ~Fx2[1:12],
    xend = ~x[2:13], 
    yend = ~Fx2[1:12], 
    color = I("blue"), 
    name = TeX("n = 10, p = 0,5"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx2[2:12], 
    color = I("blue"),
    name = TeX("n = 10, p = 0,5"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx2[1:11], 
    color = I("blue"),
    marker = list(symbol = "circle-open"),
    name = TeX("n = 10, p = 0,5"),
    showlegend = TRUE
  )  %>%
  add_segments(
    x = ~x[1:12], 
    y = ~Fx3[1:12],
    xend = ~x[2:13], 
    yend = ~Fx3[1:12], 
    color = I("green"),
    name = TeX("n = 10, p = 0,8"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx3[2:12], 
    color = I("green"),
    name = TeX("n = 10, p = 0,8"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:12], 
    y = ~Fx3[1:11], 
    color = I("green"),
    marker = list(symbol = "circle-open"),
    name = TeX("n = 10, p = 0,8"),
    showlegend = TRUE
  ) %>% 
  layout(
    xaxis = list(
      title = TeX("x"), 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("F\\left(x; n, p \\right)"),
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```

::: {.example #ejemplo-distribucion-acumulada-binomial name="Función de Distribución Acumulativa de Probabilidad Binomial"}
suponga en el ejemplo \@ref(exm:ejemplo-funcion-probabilidad-binomial) que la gerencia de control de calidad de la fábrica ha decidido detener la producción cada vez que en una muestra de 15 unidades tenga dos o más artículos defectuosos ¿Cuál es la probabilidad de que, en cualquier día, la producción se detenga?

Dado que la probabilidad de que la producción se detenga es igual a la probabilidad de que $X$ sea igual o mayor que dos. De esta manera:

$$
\begin{align*}
P \left(X \geq 2 \right) =& 1 - P \left(X \leq 1
\right)=  1 - F \left( x = 1;n = 15,p = 0,05 \right )\\ =&  1 - \sum_{t=0}^{1 } \binom{15}{t} \left( 0,05 \right)^{t} \left( 1-0,05 \right )^{15-t}\\
=& 1- \left[ \binom{15}{0}\left(0,05 \right)^{0} \left( 1- 0,05 \right)^{15-0}+ \binom{15}{1}\left(0,05 \right)^{1} \left( 1- 0,05 \right)^{15-1} \right] \\ \approx &  `r formato(1 - pbinom(q = 1, size = 15, prob = 0.05, lower.tail = TRUE, log.p = FALSE
))`.
\end{align*}
$$

La función `pbinom(q, size, prob, lower.tail = TRUE, log.p = FALSE)` de la distribución base de `r colorize("R", "blue")` permite evaluar la función de distribución acumulativa de probabilidad binomial dada por la ecuación \@ref(eq:funcion-acumulativa-binomial). El siguiente script permite obtener el resultado anterior.

```{r ejemplo-distribucion-acumulada-binomial}
1 - pbinom(
  q = 1, size = 15, prob = 0.05, lower.tail = TRUE, 
  log.p = FALSE
)
```
:::

La figura \@ref(fig:grafico-ejemplo-distribucion-acumulada-binomial) muestra la gráfica de la función de distribución acumulativa del número de artículos defectuosos en una muestra de 15 artículos $X$. La cual, como se sabe, tiene distribución binomial con parámetros $n = 15$ y $p= 0,05$. 

```{r grafico-ejemplo-distribucion-acumulada-binomial, fig.cap = "Gráfica de la función de distribución acumulativa de probabilidad binomial para $n = 15$ y $p = 0,05$", class.source = "watch-out"}
x <- c(-3, 0:15, 18)
px  <-  dbinom(x = x, size = 15, prob = 0.05)
Fx  <-  pbinom(q = x, size = 15, prob = 0.05)
plot_ly(x = x, y = Fx, alpha = 0.5) %>%
  add_segments(
    x = ~x[1:17], 
    y = ~Fx[1:17],
    xend = ~x[2:18], 
    yend = ~Fx[1:17], 
    color = I("blue"),
    name = TeX("n = 15, p = 0,05"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x[2:17], 
    y = ~Fx[2:17], 
    color = I("red"),
    name = TeX("n = 15, p = 0,05")
  ) %>%
  add_markers(
    x = ~x[2:17], 
    y = ~Fx[1:16], 
    color = I("red"),
    marker = list(symbol = "circle-open"),
    name = TeX("n = 15, p = 0,05")
  )  %>% 
  layout(
    xaxis = list(
      title = TeX("x"), 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("F\\left(x; n = 15, p = 0,05 \\right)"),
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
   config(locale = "es", mathjax = "cdn")
```

La tabla \@ref(tab:distribucion-acumulada2) muestra la función de probabilidad y la función de distribución acumulativa de probabilidad de una variable binomial con parámetros $n = 15$ y $p = 0,05$.

```{r distribucion-acumulada2, class.source="watch-out", class.output = "bg-warning"}
da_ej2 <- data.frame(
  x = 0:15,
  px = dbinom(x = 0:15, size = 15, prob = 0.05),
  Fx =  pbinom(q = 0:15, size = 15, prob = 0.05)
) 
knitr::kable(
  da_ej2,
  booktabs = TRUE,
  row.names = TRUE,
  digits = 4,
  col.names = c(
    "$X_i$", 
    "$p\\left(x_i \\right)$", 
    "$F\\left(x_i \\right)$"
  ),
  align = c("ccc"),
  format.args = list(decimal.mark = ",", big.mark = "."),
  caption = "\\label{tab2:distribucion-acumulada2}Función de probabilidad y función de distribución acumulativa de $X \\sim Bin \\left(n = 15, p= 0,05 \\right)$",
  escape = FALSE
) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = FALSE,
    fixed_thead = T
  ) %>%
  kable_classic_2() %>% 
  scroll_box(width = "100%", height = "400px")
```
<br>

#### Media de la Distribución Binomial {#media-binomial}

La media, promedio o esperanza matemática de la distribución binomial viene representada por un número, tal que si tomamos repetidas muestras de una variable binomial, en la medida en que se va incrementado el número de muestras el promedio de estos valores muestrales tiende a ese número en la medida en que se va incrementando el número de muestras. Lo dicho anteriormente se resume en el siguiente teorema.

::: {#media-binomial .theorem name="Media de la Distribución Binomial"}
Sea $X$ una variable aleatoria con distribución binomial. Entonces, la _media_ de $X$ viene dada por:
$$
\begin{equation}
E \left(X \right)= \mu = np.
(\#eq:media-binomial)
\end{equation}
$$
:::

::: {#media-binomial .proof name="Media de la Distribución Binomial"}
Por las definiciones \@ref(def:esperanza) y \@ref(def:distribucion-binomial) la esperanza de una variable $X$ con distribución binomial es

$$
\begin{align*}
E \left(X \right) =&  \sum_{x=0}^{n } x\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=& \sum_{x=1}^{n } x\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=& \sum_{x=1}^{n } \frac{n!}{\left ( x-1 \right )!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x},\\
\end{align*}
$$
en donde se ha escrito la suma desde uno hasta $n$, dado que cuando $x=0$ el primer término es cero y se cancela la $x$ del numerador con la $x$ en $x!$. Luego, factorizando $n$ y $p$, se tiene:

$$
\begin{align*}
E \left(X \right) =&  np\sum_{x=1}^{n } \frac{\left ( n-1 \right )!}{\left ( x-1 \right )!\left ( n-x \right )!}p^{x-1}\left ( 1-p \right )^{n-x}.\\
\end{align*}
$$
Si $y=x-1$ y $m=n-1$, entonces:

$$
\begin{align*}
E \left(X \right) =&  np\sum_{y=0}^{m } \frac{m!}{y!\left ( m-y \right )!}p^{y}\left ( 1-p \right )^{m-y}.\\
\end{align*}
$$
Pero $p \left(y; m, p \right)= \left[m!/y!\left(m-y \right)! \right]p^{y}\left(1-p \right)^{m-y}$ es la función de probabilidad de una variable aleatoria binomial $Y$ con parámetros $m=n-1$ y $p$; de esta manera $\sum_{y=0}^{m }p\left(y; m, p \right)=1$, y la media de una variable aleatoria binomial es:
$$
\begin{equation}
E \left(X \right) = np.
\end{equation}
$$
:::

Note de la ecuación anterior, que para un tamaño de muestra fijo $n$, la media de la distribución binomial tiende a cero cuando $p$ tiende a cero; y tiende a $n$ cuando p tiende a uno. En otras palabras, la media de la distribución binomial disminuye cuando la probabilidad de éxito disminuye y aumenta cuando la probabilidad de éxito aumenta.   

::: {.example #ejemplo-media-distribucion-binomial name="Media de la Distribución Binomial"}
Con respecto al el ejemplo \@ref(exm:ejemplo-funcion-probabilidad-binomial), determine el número de artículos defectuosos que se esperaría encontrar en una muestra de 15 artículos.

De acuerdo con el teorema \@ref(thm:media-binomial), se esperaría encontrar
$$
\begin{equation}
E \left(X \right) = np=15 \cdot 0,05=0,75.
\end{equation}
$$
Note que el valor anterior no es un número entero, es decir, si se toma una muestra de 15 artículos no se pueden encontrar 0,75 artículos defectuosos. Recuerde que el valor esperado es un promedio, por lo que la interpretación correcta es que la media de $X$ es 0,75; es decir si se toman sucesivas muestras de 15 artículos del proceso se esperaría que la media del número de artículo defectuosos encontrados en las sucesivas muestras va a tender a 0,75.

Ahora, si se toma una muestra de 100 artículos ($n=100$) del proceso de producción, se esperaría encontrar 
$$
\begin{equation}
E \left(X \right) = np=100 \cdot 0,05=5
\end{equation}
$$
5 artículos defectuosos en la muestra.
:::


#### Varianza de la Distribución Binomial {#varianza-binomial}

La varianza de una variable aleatoria binomial $X$ es un parámetro que indica que tan distante están los posibles valores que puede tomar esta variable, es decir, $x=0, 1, 2, \dotsc, n$ con respecto a la media de la variable $\left(\mu=np \right)$. En tal sentido, la varianza de una variable binomial se describe en el siguiente teorema: 

::: {#varianza-binomial .theorem name="Varianza de la Distribución Binomial"}
Sea $X$ una variable aleatoria con distribución binomial. Entonces, la _varianza_ de $X$ viene dada por:
$$
\begin{equation}
V \left(X \right)=\sigma^2 = np \left(1-p \right).
(\#eq:varianza-binomial)
\end{equation}
$$
:::

Note de la ecuación anterior, que para un $n$ fijo, la gráfica de la varianza se una parábola cóncava hacia abajo. Por lo tanto, el vértice de la parábola será un máximo y se halla en $p=1/2$. Es decir, la varianza es hace máxima cuando cuando $p=1/2$. Por lo que, el máximo valor de la varianza será la cuarta parte del tamaño de la muestra. 

::: {#varianza-binomial .proof name="varianza de la Distribución Binomial"}
De la ecuación \@ref(eq:varianza2) se sabe que $V \left(X \right) = E \left(X^2 \right) - \mu^2$. Como $\mu=np$, solo faltaría calcular $E \left(X^2 \right)$. Pero calcular este parámetro usando el teorema \@ref(thm:esperanza-transformacion) y la definición \@ref(def:distribucion-binomial) implica encontrar la convergencia de la siguiente expresión

$$
E \left(X^2 \right) =  \sum_{x=0}^{n } x^2\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x},
$$
lo cual es imposible. En lugar de este camino, se elegirá un método alterno. La alternativa es escribir $x^2$ como:

$$
x^2= x \left(x-1 \right)+x;
$$
de esta manera, por los teoremas \@ref(thm:esperanza-transformacion) y \@ref(thm:esperanza-suma-transformaciones), se tiene:

$$
\begin{equation}
E \left(X^2 \right)= E \left[X \left(X-1 \right) \right]+E \left(X \right).
(\#eq:varianza-alterna-binomial)
\end{equation}
$$
Dado que $E \left(X \right)$ ya se ha determinado, faltaría determinar $E \left[x \left(x-1 \right) \right]$, que según el teorema \@ref(thm:esperanza-transformacion), es:


$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =&  \sum_{x=0}^{n } x \left(x-1 \right)\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=& \sum_{x=2}^{n } x \left(x-1 \right)\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=& \sum_{x=1}^{n } \frac{n!}{\left ( x-2 \right )!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=& n \left(n-1 \right)p^2 \sum_{x=1}^{n } \frac{\left(n-2 \right)!}{\left ( x-2 \right )!\left ( n-x \right )!}p^{x-2}\left ( 1-p \right )^{n-x}.
\end{align*}
$$
Note que en los pasos previos se escribió la suma a partir de dos porque los dos primeros términos son cero, se canceló $x \left(x-1 \right)$, y se factorizó $n \left(n-1 \right)p^2$. Sea $y=x-2$ y $m=n-2$; entonces:

$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =&  n \left(n-1 \right)p^2\sum_{y=0}^{m } \frac{m!}{y!\left ( m-y \right )!}p^{y}\left ( 1-p \right )^{m-y}.\\
\end{align*}
$$
Pero $p \left(y; m, p \right)= \left[m!/y!\left(m-y \right)! \right]p^{y}\left(1-p \right)^{m-y}$ es la función de probabilidad de una variable aleatoria binomial $Y$ con parámetros $m=n-2$ y $p$; de esta manera $\sum_{y=0}^{m }p\left(y; m, p \right)=1 $. En consecuencia, 
$$
\begin{equation}
E \left[X \left(X-1 \right) \right] = n \left(n-1 \right)p^2.
\end{equation}
$$

De la ecuación \@ref(eq:varianza-alterna-binomial)
$$
E \left(X^2 \right)=  n \left(n-1 \right)p^2+np.
$$

De esta manera, la varianza de una variable aleatoria binomial, según la ecuación \@ref(eq:varianza2), es:
$$
\begin{align*}
V(X)=&n \left(n-1 \right)p^2+np-n^2p^2\\
=&np \left[ \left(n-1 \right)p + 1 - np \right]\\
=&np \left(1-p \right).
\end{align*}
$$
:::

::: {.example #ejemplo-varianza-binomial name="Varianza de la Distribución Binomial"}
Con respecto al ejemplo \@ref(exm:ejemplo-funcion-probabilidad-binomial), determine la varianza del número de artículos defectuosos encontardos en una muestra de 15 artículos tomados del proceso de producción.

De acuerdo con el teorema \@ref(thm:varianza-binomial), la varianza de $X$ es:

$$
V(X)=np \left(1-p \right)=15 \cdot0,05 \left(1-0,05 \right)=0,7125.
$$
:::


#### Función Genradora de Momentos de la Distribución Binomial {#funcion-generadora-momentos-binomial}

La función generadora de momentos es un método alternativo para determinar los momentos ordinarios de una distribución de probabilidad determinada, por medio del teorema \@ref(thm:funcion-generadora-momentos). En el caso de la distribución binomial, la función generadora de momentos se indica en el siguienete teorema: 

::: {#fgm-binomial .theorem name="Función Generadora de Momentos de la Distribución Binomial"}
La función generadora de momentos de la distribución binomial está dada por:
$$
\begin{equation}
m_x \left(t \right)=\left[1+p \left(e^t-1 \right) \right].
(\#eq:fgm-binomial)
\end{equation}
$$
:::

::: {#fgm-binomial .proof name="Función Generadora de Momentos de la Distribución Binomial"}
De la definiciones \@ref(def:distribucion-binomial) y \@ref(def:funcion-generadora-momentos), se obtiene

$$
\begin{align*}
m_x \left(t \right)=&  \sum_{x=0}^{n } e^{tx}\frac{n!}{x!\left ( n-x \right )!}p^{x}\left ( 1-p \right )^{n-x}\\
=&  \sum_{x=0}^{n } \frac{n!}{x!\left ( n-x \right )!}(e^{t}p)^{x}\left ( 1-p \right )^{n-x}.\\
\end{align*}
$$
Por el binomio de Newton, se sabe que la última sumatoria es la expansión de la expresión $\left[e^{t}p+ \left(1-p \right) \right]^n=\left[1+ p\left(e^t -1 \right) \right]^n$. En resumen,
$$
\begin{align*}
m_x \left(t \right)=\left[1+ p\left(e^t -1 \right) \right]^n.\\
\end{align*}
$$
:::

Del teorema \@ref(thm:funcion-generadora-momentos), la media de la distribucón binomial es:
$$
\begin{equation}
\frac{\mathrm{d}m_{x}\left ( t \right )}{\mathrm{d}t} \left|\begin{matrix}
 \\
t=0\\
\end{matrix}={\mu}^{'}_1=\mu \right.
\end{equation}
$$
La primera derivada de la función generadora de momentos es

$$
\frac{\mathrm{d}m_{x}\left ( t \right )}{\mathrm{d}t}=npe^t \left[1+ p\left(e^t -1 \right) \right]^{n-1}.
$$
Ahora, evaluando la primera derivada de la función generadora de momentos en $t=0$, se obtiene la media de la distribución binomial, como sigue:
$$
\begin{equation}
\frac{\mathrm{d}m_{x}\left ( t \right )}{\mathrm{d}t} \left|\begin{matrix}
 \\
t=0\\
\end{matrix}=\mu=npe^0 \left[1+ p\left(e^0 -1 \right) \right]^{n-1}=np. \right.
\end{equation}
$$
Note que este resultado es el mismo dado en el teorema \@ref(thm:media-binomial). Se deja al lector que halle la varianza de la distribución binomial usando el método de la función generadora de momentos. 


### Distribuciones Hipergeométrica {#distribucion-hipergeometrica}

::: {#distribucion-hipergeometrica .definition name="Distribución Hipergeométrica"}
Dada una población que consta de $m$ objetos que poseen una característica de interés y $n$ que no la poseen. Si se selecciona una muestra aleatoria sin reemplazo de tamaño $k$ de estos objetos. Entonces la variable aleatoria $X$ que representa el número objetos en la muestra que tienen la característica de interés tiene _distribución hipergeométrica_, y se escribe $X \sim H \left(m, n, k \right)$, si su función de probabilidad viene dada por:
$$
p\left ( x;m,n, k \right )=\begin{cases}
\frac{\binom{m}{x}\binom{n}{k-x}}{\binom{m+n}{k}} & \text{ si }  \mathrm{máx} \left\{0, k - n  \right\} \leq x \leq \mathrm{mín} \left\{k, m  \right\} \\
0 & \text{ en cualquier otro caso }.
(\#eq:funcion-probabilidad-hipergeometrica)
\end{cases}
$$
:::

Los parámetros de la distribución hipergeométrica $m$, $n$ y $k$ definen una familia de distribuciones con función de probabilidad determinada por la ecuación \@ref(eq:funcion-probabilidad-hipergeometrica). En la figura \@ref(fig:grafico-distribucion-hipergeometrica) se muestran las gráficas de la función de probabilidad hipergeométrica \@ref(eq:funcion-probabilidad-hipergeometrica) para distintas combinaciones de $m$, $n$ y $k$.

La función `dhyper(x, m, n, k, log = FALSE)` de la distribución base de `r colorize("R", "blue")` permite evaluar la función de probabilidad de la distribución hipergeométrica dada por la ecuación \@ref(eq:funcion-probabilidad-hipergeometrica).

```{r grafico-distribucion-hipergeometrica, fig.cap = "Gráfica de la función de probabilidad hipergeométrica para distintos valores de  $m$, $n$ y $k$", class.source = "watch-out"}
m1 <- 10
n1 <- 90
k1 <- 5
x1 <- max(0, k1 - n1):min(k1, m1)
px1 <- dhyper(x = x1, m = m1, n = n1, k = k1, log = FALSE)
m2 <- 10
n2 <- 90
k2 <- 10
x2 <- max(0, k2 - n2):min(k2, m2)
px2 <- dhyper(x = x2, m = m2, n = n2, k = k2, log = FALSE)
m3 <- 10
n3 <- 90
k3 <- 15
x3 <- max(0, k3 - n3):min(k3, m3)
px3 <- dhyper(x = x3, m = m3, n = n3, k = k3, log = FALSE)
plot_ly(alpha = 0.5) %>%
  add_segments(
    x = x1, y = ~ rep(x = 0, times = length(x1)),
    xend = x1, yend = ~px1,
    color = I("red"), showlegend = TRUE,
    name = TeX("m = 10, n = 90, k = 5")
  ) %>%
  add_markers(
    x = x1, y = ~px1,
    color = I("red"), showlegend = TRUE,
    name = TeX("m = 10, n = 90, k = 5")
  ) %>%
  add_segments(
    x = x2, y = ~ rep(x = 0, times = length(x2)),
    xend = ~x2, yend = ~px2,
    color = I("blue"), showlegend = TRUE,
    name = TeX("m = 10, n = 90, k = 10")
  ) %>%
  add_markers(
    x = ~x2, y = ~px2,
    color = I("blue"), showlegend = TRUE,
    name = TeX("m = 10, n = 90, k = 10")
  ) %>%
  add_segments(
    x = ~x3, y = ~ rep(x = 0, times = length(x3)),
    xend = ~x3, yend = ~px3,
    color = I("green"), showlegend = TRUE,
    name = TeX("m = 10, n = 90, k = 15")
  ) %>%
  add_markers(
    x = ~x3, y = ~px3,
    color = I("green"), showlegend = TRUE,
    name = TeX("m = 10, n = 90, k = 15")
  ) %>%
  layout(
    xaxis = list(
      title = TeX("x"),
      zeroline = F,
      showgrid = T,
      showline = T,
      linewidth = 1,
      linecolor = "black",
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("p \\left(x; m, n, k \\right)"),
      showgrid = T,
      showline = T,
      linewidth = 1,
      linecolor = "black",
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```

::: {.example #ejemplo-funcion-probabilidad-hipergeometrica name="Función de Probabilidad Hipergeométrica"}
Se tiene un lote de 100 lamparas, de las cuales el 5\% están defectuosas. Si se toma una muestra aleatoria sin reemplazo de 10 de estas lamparas. Determine la probabilidad de que dos estén defectuosas.


Dado que el lote de lamparas están particionadas en dos grupos, las defectuosas (característica de interés) y las no defectuosas. Además, la muestra se ha tomado del lote sin reemplazo. Si se define la variable $X$ como el número de artículos defectuosos encontrados en la muestra, por la definición \@ref(def:distribucion-hipergeometrica), $X$ tiene distribución hipergeométrica con parámetros $m = 100 \cdot0,05 = 5$, $n = 95$ y $k = 10$, es decir, $X \sim H\left(m = 5 , n = 95, k = 10 \right)$. Por lo tanto, de acuerdo con la ecuación \@ref(eq:funcion-probabilidad-hipergeometrica), la probabilidad de encontrar dos lamparas defectuosas en la muestra es: 

$$
P\left(X = 2 \right)=p\left ( x = 2;m = 100,n = 10, k =5 \right )=
\frac{\binom{5}{2}\binom{100-5}{10-2}}{\binom{100}{10}} \approx `r formato(dhyper(x = 2, m = 5, n = 95, k = 10, log = FALSE))`.
$$
En `r colorize("R", "blue")`, el resultado anterior se puede conseguir con el siguiente trozo de código.

```{r ejemplo-funcion-probabilidad-hipergeometrica}
dhyper(x = 2, m = 5, n = 95, k = 10, log = FALSE)
```

La figura \@ref(fig:funcion-probabilidad-hipergeometrica) muestra la gráfica de la función de probabilidad del número de lamparas defectuosas en una muestra de tamaño 10 $\left(X \right)$. La cual, como se sabe, tiene distribución hipergeométrica con parámetros $m = 5$, $n = 95$, $k = 10$. Es decir, $X \sim H \left(m = 5, n = 95, k = 10 \right)$. 

```{r funcion-probabilidad-hipergeometrica, fig.cap = "Gráfica de la función de probabilidad hipergeométrica para $m = 5$, $n = 95$ y $k = 5$", class.source = "watch-out"}
plot_ly(alpha = 0.5) %>%
  add_segments(
    x = 0:5, 
    y = ~rep(x = 0, times = length(0:5)),
    xend = 0:5, 
    yend = ~dhyper(
      x = 0:5, m = 5, n = 95, k = 10, log = FALSE
    ), 
    color = I("red"), 
    showlegend = TRUE,
    name = TeX("m = 5, n = 95, k = 10")
  ) %>%
  add_markers(
    x = 0:5, 
    y = ~dhyper(
      x = 0:5, m = 5, n = 95, k = 10, log = FALSE
    ), 
    color = I("red"), showlegend = TRUE,
    name = TeX("m = 5, n = 95, k = 10")
  ) %>%  
  layout(
    xaxis = list(
      title = TeX("x"), 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX(
        "p \\left(x; m = 5, n = 95, k =10 \\right)"
      ),
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```
:::


#### Función de Distribución Acumulativa de Probabilidad Hipergeométrica {#distribucion-acumulada-hipergeometrica}

La probabilidad de que en una muestra de tamaño $k$, la cual ha sido extraída sin remplazo de una población constituida por $m$ objetos que poseen una característica de interés y $n$ que no la poseen, a lo más $x$ objetos tengan la característica de interés representa la función de distribución acumulativa de una variable aleatoria con distribución hipergeométrica. Ésta función, de acuerdo con las definiciones  \@ref(def:funcion-acumulativa-probabilidad) y  \@ref(def:distribucion-hipergeometrica), se enuncia de la siguiente manera:

::: {#distribucion-acumulada-hipergeometrica .definition name="Función de Distribución Acumulativa de Probabilidad Hipergeométrica"}
Sea $X$ una variable aleatoria con distribución hipergeométrica. Entonces, la _función de distribución acumulativa de probabilidad hipergeométrica_ viene dada por:
$$
F\left ( x;n,p \right )=\begin{cases}
0 & \text{ si } x < \mathrm{máx} \left\{0, k - n  \right\}\\
 \sum_{t=\mathrm{máx} \left\{0, k - n  \right\}
 }^{x } \frac{\binom{m}{t}\binom{n}{k-t}}{\binom{m+n}{k}} & \text{ si }  \mathrm{máx} \left\{0, k - n  \right\} \leq x \leq \mathrm{mín} \left\{k, m  \right\}\\
1 & \text{ si } x > \mathrm{mín} \left\{k, m  \right\}.
(\#eq:funcion-acumulativa-hipergeometrica)
\end{cases}
$$
:::

La figura \@ref(fig:grafico-acumulativa-hipergeometrica) muestra la función de distribución acumulativa de probabilidad para una variable hipergeométrica para distintos valores de los parámetros $m$, $n$ y $k$.

La función `phyper(q, m, n, k, lower.tail = TRUE, log.p = FALSE)` de la distribución base de `r colorize("R", "blue")` permite evaluar la función de distribución acumulativa de probabilidad hipergeométrica dada por la ecuación \@ref(eq:funcion-acumulativa-hipergeometrica).


```{r grafico-acumulativa-hipergeometrica, fig.cap = "Gráfica de la función de distribución acumulativa de probabilidad hipergeométrica para $m = 10$ y $n = 90$ y $k = 5, 10, 15$", class.source = "watch-out"}
plot_ly(alpha = 0.5) %>%
  add_segments(
    x = ~c(first(x1) -3, x1), 
    y = ~phyper(
      c(first(x1) -3, x1), m = m1, n = n1, k = k1
    ),
    xend = ~c(x1, last(x1) + 3), 
    yend = ~phyper(
      c(first(x1) -3, x1), m = m1, n = n1, k = k1
    ), 
    color = I("red"),
    name = TeX("m = 10, n = 90, k = 5"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x1, 
    y = ~phyper(x1, m = m1, n = n1, k = k1), 
    color = I("red"),
    name = TeX("m = 10, n = 90, k = 5"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x1, 
    y = ~phyper(
      c(first(x1) -3, x1[-last(x1)]), m = m1, n = n1, k = k1
    ), 
    color = I("red"),
    marker = list(symbol = "circle-open"),
    name = TeX("m = 10, n = 90, k = 5"),
    showlegend = TRUE
  )  %>%
  add_segments(
    x = ~c(first(x2) -3, x2), 
    y = ~phyper(
      c(first(x2) -3, x2), m = m2, n = n2, k = k2
    ),
    xend = ~c(x2, last(x2) + 3), 
    yend = ~phyper(
      c(first(x2) -3, x2), m = m2, n = n2, k = k2
    ), 
    color = I("blue"),
    name = TeX("m = 10, n = 90, k = 10"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x2, 
    y = ~phyper(x2, m = m2, n = n2, k = k2), 
    color = I("blue"),
    name = TeX("m = 10, n = 90, k = 10"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x2, 
    y = ~phyper(
      c(first(x2) -3, x2[-last(x1)]), m = m2, n = n2, k = k2
    ), 
    color = I("blue"),
    marker = list(symbol = "circle-open"),
    name = TeX("m = 10, n = 90, k = 10"),
    showlegend = TRUE
  )  %>%
  add_segments(
    x = ~c(first(x3) -3, x3), 
    y = ~phyper(
      c(first(x3) -3, x3), m = m3, n = n3, k = k3
    ),
    xend = ~c(x3, last(x3) + 3), 
    yend = ~phyper(
      c(first(x3) -3, x3), m = m3, n = n3, k = k3
    ), 
    color = I("green"),
    name = TeX("m = 10, n = 90, k = 15"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x3, 
    y = ~phyper(x3, m = m3, n = n3, k = k3), 
    color = I("green"),
    name = TeX("m = 10, n = 90, k = 15"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~x3, 
    y = ~phyper(
     c(first(x3) -3, x3[-last(x3)]), m = m3, n = n3, k = k3
    ), 
    color = I("green"),
    marker = list(symbol = "circle-open"),
    name = TeX("m = 10, n = 90, k = 15"),
    showlegend = TRUE
  )  %>%
  layout(
    xaxis = list(
      title = TeX("x"), 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("F \\left(x; m, n, k \\right)"),
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```

::: {.example #ejemplo-distribucion-acumulada-hipergeometrica name="Función de Distribución Acumulativa de Probabilidad Hipergeométrica"}
Suponga en el ejemplo \@ref(exm:ejemplo-funcion-probabilidad-hipergeometrica) que se desea determinar la probabilidad de que en una muestra aparezcan menos de dos lamparas defectuosas.

La probabilidad de que en la muestra aparezcan menos de dos lamparas defectuosas es:

$$
\begin{align*}
P \left(X < 2 \right) =& P \left(X \leq 1
\right)=   F \left( x = 1;m = 5,n = 95, k = 10 \right)\\ =& \sum_{t=0
 }^{x } \frac{\binom{5}{t}\binom{95}{5-t}}{\binom{5+95}{10}}
= \frac{\binom{5}{0}\binom{95}{5}}{\binom{100}{10}}+ \frac{\binom{5}{1}\binom{95}{4}}{\binom{100}{10}}\\ \approx &  `r formato(phyper(q = 1, m = 5, n = 95, k = 10, lower.tail = TRUE, log.p = FALSE))`.
\end{align*}
$$

El siguiente script de `r colorize("R", "blue")` permite obtener el resultado anterior.

```{r ejemplo-distribucion-acumulada-hipergeometrica}
phyper(
  q = 1, m = 5, n = 95, k = 10, lower.tail = TRUE, log.p = FALSE
)
```
:::

La figura \@ref(fig:grafico-acumulativa-hipergeometrica2) muestra la gráfica de la función de distribución acumulativa del número de lamparas defectuosas en una muestra de tamaño 10 ($X$). La cual, como se sabe, tiene distribución hipergeométrica con parámetros $m = 5$, $n = 95$, $k = 10$. Es decir, $X \sim H \left(m = 5, n = 95, k = 10 \right)$. 

```{r grafico-acumulativa-hipergeometrica2, fig.cap = "Gráfica de la función de distribución acumulativa de probabilidad hipergeométrica para $m = 5$, $n = 95$ y $k = 10$", class.source = "watch-out"}
plot_ly(alpha = 0.5) %>%
  add_segments(
    x = ~c(-3, 0:5), 
    y = ~phyper(c(-3, 0:5), m = 5, n = 95, k = 10),
    xend = ~c(0:5, 8), 
    yend = ~phyper(c(-3, 0:5), m = 5, n = 95, k = 10), 
    color = I("red"),
    name = TeX("m = 5, n = 95, k = 10"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~0:5, 
    y = ~phyper(0:5, m = 5, n = 95, k = 10), 
    color = I("red"),
    name = TeX("m = 5, n = 95, k = 10"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~c(0:5), 
    y = ~phyper(c(-3, 0:4), m = 5, n = 95, k = 10), 
    color = I("black"),
    marker = list(symbol = "circle-open"),
    name = TeX("m = 5, n = 95, k = 10"),
    showlegend = TRUE
  )  %>%
  layout(
    xaxis = list(
      title = TeX("x"), 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX(
        "F \\left(x; m = 5, n = 95, k = 10  \\right)"
      ),
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```

La tabla \@ref(tab:distribucion-hipergeometrica) muestra la función de probabilidad y la función de distribución acumulativa de probabilidad de una variable hipergeométrica con parámetros $m = 5$, $n = 95$ y $k = 10$.

```{r distribucion-hipergeometrica, class.source="watch-out", class.source="watch-out", class.output = "bg-warning"}
da_ej2 <- data.frame(
  x = 0:5,
  px = dhyper(x = 0:5, m = 5, n = 95, k = 10, log = FALSE),
  Fx = phyper(
    q = 0:5, m = 5, n = 95, k = 10, lower.tail = TRUE, 
    log.p = FALSE
  )
) 
knitr::kable(
  da_ej2,
  booktabs = TRUE,
  row.names = TRUE,
  digits = 4,
  col.names = c(
    "$X_i$", 
    "$p\\left(x_i \\right)$", 
    "$F\\left(x_i \\right)$"
  ),
  align = c("ccc"),
  format.args = list(decimal.mark = ",", big.mark = "."),
  caption = "\\label{tab2:distribucion-acumulada2}Función de probabilidad y función de distribución acumulativa de $X \\sim H \\left(m = 5, n = 95, k= 10 \\right)$",
  escape = FALSE
) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = FALSE,
    fixed_thead = T
  ) %>%
  kable_classic_2() %>% 
  scroll_box(width = "100%", height = "400px")
```
<br>

#### Media de la Distribución Hipergeométrica {#media-hipergeometrica}

La media, promedio o esperanza matemática de la distribución hipergeométrica es el número de objetos con la característica de interés, que se espera, aparezcan en una muestra de tamaño $k$, la cual ha sido extraída de una población que contiene $m$ objetos que poseen la característica de interés mientras que el resto $n$ no posee tal característica. De manera formal, esto se expresa de la siguiente manera:

::: {#media-hipergeometrica .theorem name="Media de la Distribución Hipergeoétrica"}
Sea $X$ una variable aleatoria con distribución hipergeométrica. Entonces, la _media_ de $X$ viene dada por:
$$
\begin{equation}
E \left(X \right)= \mu = \frac{mk}{m+n}.
(\#eq:media-hipergeometrica)
\end{equation}
$$
:::

::: {#media-hipergeometrica .proof name="Media de la Distribución Hipergeométrica"}
Note que en la función de probabilidad de la distribución hipergeométrica, dada por la ecuación \@ref(eq:funcion-probabilidad-hipergeometrica), los valores mínimos y máximos del recorrido de la variable dependen de los parámetros $m$, $n$ y $k$. En tal sentido se hará una demostración parcial del teorema suponiendo que $n > k$ y $m > k$. Como consecuencia de estas suposiciones la función de probabilidad hipergeométrica estaría dada de la siguiente manera:

$$
p\left ( x;m,n, k \right )=\begin{cases}
\frac{\binom{m}{x}\binom{n}{k-x}}{\binom{m+n}{k}} & \text{ si } x= 0, 1, 2, \dotsc, k \\
0 & \text{ en cualquier otro caso }.
(\#eq:funcion-probabilidad-hipergeometrica2)
\end{cases}
$$
Luego, por las definición de esperanza matemática \@ref(def:esperanza) y la función de probabilidad  hipergeométrica, que en ete caso se reduce a la ecuación \@ref(eq:funcion-probabilidad-hipergeometrica2), la esperanza de una variable $X$ con distribución hipergeométrica, bajo las condiciones dadas se obtiene como sigue.

$$
\begin{align*}
E \left(X \right) =&  \sum_{x=0}^{k } x\frac{\binom{m}{x}\binom{n}{k-x}}{\binom{m+n}{k}}
= \sum_{x=1}^{k } x \frac{\frac{m!}{x!\left ( m-x \right )!}\binom{n}{k-x}}{\binom{m+n}{k}}\\
=& m\sum_{x=1}^{k }  \frac{\frac{(m-1)!}{(x-1)!\left ( m-x \right )!}\binom{n}{k-x}}{\binom{m+n}{k}}
= m\sum_{x=1}^{k }  \frac{\binom{m-1}{x-1}\binom{n}{k-x}}{\binom{m+n}{k}}.\\
\end{align*}
$$
Como puede demostrarse que:
$$
\binom{m+n}{k}=\frac{m+n}{k}\binom{m+n-1}{k-1}.
$$
Entonces,
$$
\begin{align*}
E \left(X \right) =& \frac{m}{\frac{m+n}{k}}\sum_{x=1}^{k }  \frac{\binom{m-1}{x-1}\binom{n}{k-x}}{\binom{m+n-1}{k-1}}.\\
\end{align*}
$$
Si $r=k-1$, $s=m-1$ y $y=x-1$, entonces:
$$
\begin{align*}
E \left(X \right) =& \frac{mk}{m+n}\sum_{y=0}^{r }  \frac{\binom{s}{y}\binom{n}{r-y}}{\binom{s+n}{r}}.\\
\end{align*}
$$
La suma es igual dado dado que es la suma de una función de probabilidad hipergeométrica con parámetros $s$, $n$ y $r$. Por lo que quea demostrado que,
$$
\begin{align*}
E \left(X \right) =& \frac{mk}{m+n}.\\
\end{align*}
$$
Esta demostración se ha realizado ajo las restricción de los parámetros expuesta al principio, se deja como ejercicio al estudiante demostrar para los demás casos.
:::

::: {.example #ejemplo-media-distribucion-hipergeometrical name="Media de la Distribución Binomial"}
Con respecto al el ejemplo \@ref(exm:ejemplo-funcion-probabilidad-hipergeometrica), determine el número de lamparas defectuosas que se esperaría encontrar en una muestra de de 10 de estas lamparas.

De acuerdo con el teorema \@ref(thm:media-hipergeometrica), se esperaría encontrar
$$
\begin{align*}
E \left(X \right) =& \frac{mk}{m+n}=\frac{5 \cdot 10}{5+95}=0,5.\\
\end{align*}
$$
Ahora, si se toma una muestra de 60 lamparas ($k=60$) del lote, se esperaría encontrar 
$$
\begin{align*}
E \left(X \right) =& \frac{mk}{m+n}=\frac{5 \cdot 60}{5+95}=3.\\
\end{align*}
$$
lamparas defectuosos en la muestra.
:::


#### Varianza de la Distribución Hipergeométrica {#varianza-hipergoemetrica}

La varianza de una variable aleatoria es una medida absoluta de la dispersión de esta. En el caso de que la variable aleatoria sea hipergeométrica, la medida de esa dispersión se expresa en siguiente teorema: 

::: {#varianza-hipergeometrica .theorem name="Varianza de la Distribución Hipergeométrica"}
Sea $X$ una variable aleatoria con distribución hipergeométrica. Entonces, la _varianza_ de $X$ viene dada por:
$$
\begin{equation}
V \left(X \right)=\sigma^2 = \frac{mkn\left(m+n-k\right)}{\left(m+n \right)^2\left(m+n-1 \right) }.
(\#eq:varianza-hipergeometrica)
\end{equation}
$$
:::

::: {#varianza-binomial .proof name="varianza de la Distribución Hipergeométrica"}
La demostración de este teorema, al igual que en el teorema de la media de la distribución hipergeométrica \@ref(thm:media-hipergeometrica), se hará asumiendo que $n > k$ y $m > k$. La demostración en los otros casos se deja como ejercicio al lector.

De la ecución \@ref(eq:varianza2) se sabe que $V \left(X \right) = E \left(X^2 \right) - \mu^2$. Como $\mu=\frac{mk}{m+n}$, solo faltaría calcular $E \left(X^2 \right)$. Pero calcular este parámetro usando el teorema \@ref(thm:esperanza-transformacion) y la función de probabilidad, que para este caso está dada por la ecuación \@ref(eq:funcion-probabilidad-hipergeometrica2) implica encontrar la convergencia de la siguiente expresión

$$
\begin{align*}
E \left(X^2 \right) =&  \sum_{x=0}^{k } x^2\frac{\binom{m}{x}\binom{n}{k-x}}{\binom{m+n}{k}},\\
\end{align*}
$$
lo cual es sumamente complicado, por decir lo menos. En lugar de este camino, se elegirá un método alterno. La alternativa es escribir $x^2$ como:

$$
x^2= x \left(x-1 \right)+x;
$$
de esta manera, por los teoremas \@ref(thm:esperanza-transformacion) y \@ref(thm:esperanza-suma-transformaciones), se tiene:

$$
\begin{equation}
E \left(X^2 \right)= E \left[X \left(X-1 \right) \right]+E \left(X \right).
(\#eq:varianza-alterna-binomial)
\end{equation}
$$
Dado que $E \left(X \right)$ ya se ha determinado, faltaría determinar $E \left[x \left(x-1 \right) \right]$, que según el teorema \@ref(thm:esperanza-transformacion), es:


$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =&  \sum_{x=0}^{k } x \left(x-1 \right)\frac{\binom{m}{x}\binom{n}{k-x}}{\binom{m+n}{k}}\\
=& \sum_{x=2}^{k } x \left(x-1 \right)\frac{\frac{m!}{x!\left ( m-x \right )!}\binom{n}{k-x}}{\binom{m+n}{k}}\\
=& \sum_{x=2}^{k } x \left(x-1 \right)\frac{\frac{m\left(m-1 \right)\left(m-2 \right)!}{x\left(x-1 \right)\left(x-2 \right)!\left ( m-x \right )!}\binom{n}{k-x}}{\binom{m+n}{k}}.\\
\end{align*}
$$
Por lo que, cancelando los factores $x\left(x-1 \right)$ , lo anterior se puede reescribir de la siguiente manera:
$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =& \sum_{x=2}^{k } \frac{\frac{m\left(m-1 \right)\left(m-2 \right)!}{\left(x-2 \right)!\left ( m-x \right )!}\binom{n}{k-x}}{\binom{m+n}{k}}.\\
\end{align*}
$$
Se puede demostrar de manera fácil que,
$$
\binom{m+n}{k}=\left( \frac{m+n}{k} \right)\left( \frac{m+n-1}{k-1} \right)\binom{m+n-2}{k-2}.
$$
En consecuencia,
$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =& \sum_{x=2}^{k }\frac{\frac{m\left(m-1 \right)\left(m-2 \right)!}{\left(x-2 \right)!\left ( m-x \right )!}\binom{n}{k-x}}{\left( \frac{m+n}{k} \right)\left( \frac{m+n-1}{k-1} \right)\binom{m+n-2}{k-2}}.\\
\end{align*}
$$
Luego, factorizando
$$
\frac{m\left(m-1 \right)}{\left( \frac{m+n}{k} \right)\left( \frac{m+n-1}{k-1} \right)},
$$
resulta
$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =& \frac{m\left(m-1 \right)}{\left( \frac{m+n}{k} \right)\left( \frac{m+n-1}{k-1} \right)}\sum_{x=2}^{k }\frac{\frac{\left(m-2 \right)!}{\left(x-2 \right)!\left ( m-x \right )!}\binom{n}{k-x}}{\binom{m+n-2}{k-2}}.\\
\end{align*}
$$
Si $r=k-2$, $s=m-2$ y $y=x-2$, entonces:
$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =& \frac{m\left(m-1 \right)}{\left( \frac{m+n}{k} \right)\left( \frac{m+n-1}{k-1} \right)}\sum_{y=0}^{r }\frac{\frac{s!}{y!\left ( s-y \right )!}\binom{n}{r-y}}{\binom{s+n}{r}}.\\
\end{align*}
$$
Como
$$
\binom{s}{y}=\frac{s!}{y! \left( s-y \right )!},
$$
Entonces,
$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =& \frac{m\left(m-1 \right)}{\left( \frac{m+n}{k} \right)\left( \frac{m+n-1}{k-1} \right)}\sum_{y=0}^{r }\frac{\binom{s}{y}\binom{n}{r-y}}{\binom{s+n}{r}}.\\
\end{align*}
$$

Pero, 
$$
p \left(y; s, n, r\right)= \frac{\binom{s}{y}\binom{n}{r-y}}{\binom{s+n}{r}}
$$ 
es la función de probabilidad de una variable aleatoria hipergeométrica $Y$ con parámetros $s$, $n$ y $r$; de esta manera $\sum_{y=0}^{r }p\left(y; s, n, r \right)=1$. En consecuencia, 
$$
\begin{align*}
E \left[X \left(X-1 \right) \right] = \frac{m\left(m-1 \right)}{\left( \frac{m+n}{k} \right)\left( \frac{m+n-1}{k-1} \right)}
=\frac{mk\left(m-1 \right)\left(k-1 \right)}{\left(m+n \right)\left(m+n-1 \right)}\\
\end{align*}
$$
De la ecuación \@ref(eq:varianza-alterna-binomial)
$$
E \left(X^2 \right)=  \frac{mk\left(m-1 \right)\left(k-1 \right)}{\left(m+n \right)\left(m+n-1 \right)}+\frac{mk}{m+n}.
$$
De esta manera, la varianza de una variable aleatoria binomial, según la ecuación \@ref(eq:varianza2) es:
$$
\begin{align*}
V(X)=&\frac{mk\left(m-1 \right)\left(k-1 \right)}{\left(m+n \right)\left(m+n-1 \right)}+\frac{mk}{m+n}-\left(\frac{mk}{m+n} \right)^2\\
=&\frac{mk\left(m+n \right)\left(m-1 \right)\left(k-1 \right)+mk\left(m+n \right)\left(m+n-1 \right)-m^2k^2\left(m+n-1 \right)}{\left(m+n \right)^2\left(m+n-1 \right)}\\
=&\frac{km^2n+kmn^2-k^2mn}{\left(m+n \right)^2\left(m+n-1 \right)}
=\frac{kmn\left(m+n-k \right)}{\left(m+n \right)^2\left(m+n-1 \right)}\\
\end{align*}
$$
:::

::: {.example #ejemplo-varianza-binomial name="Varianza de la Distribución Hipergeométrica"}
Con respecto al ejemplo \@ref(exm:ejemplo-funcion-probabilidad-binomial), determine la varianza del número de lamparas defectuosas.

De acuerdo con el teorema \@ref(thm:varianza-hipergeometrica), la varianza de $X$ es:

$$
\begin{align*}
V(X)=&\frac{kmn\left(m+n-k \right)}{\left(m+n \right)^2\left(m+n-1 \right)}=\frac{10 \cdot 5 \cdot 95\left(5+95-10 \right)}{\left(5+95 \right)^2\left(5+95-1 \right)}\\
=&\frac{171}{392} \approx0,4362.
\end{align*}
$$
:::

Otra forma de obtener la media y la varianza es a través de la función generadora de momentos de la distribución hipergeométrica, pero dado las dificultades que implica la derivación de esta función para la distribución en cuestión, no se considerará en este libro.


### Distribució de Poisson {#distribuciones-poisson}

La distribución de Poisson debe su nombre a Simeón Denis Poisson, probabilista francés del siglo XIX quien fue el primero en describirla. Es una distribución discreta de probabilidad muy útil ya que se aplica para describir la ocurrencia de fenómenos que ocurren a una tasa constante en el tiempo o en el espacio. La presentación formal de esta distribución se probabilidad se describe en el siguiente teorema.

::: {#distribucion-poisson .definition name="Distribución de Poisson"}
Sea $X$ una variable aleatoria que representa el número de eventos aleatorios independientes que ocurren a una rapidez constante $\lambda$ sobre el tiempo o el espacio. Se dice entonces que una variable $X$ tiene distribución de Poisson con función de probabilidad
$$
p\left ( x;\lambda \right )=\begin{cases}
\frac{e^{-\lambda}\lambda^x}{x!} & \text{ si } x= 0, 1, 2, \dotsc;\: \lambda>0 \\
0 & \text{ en cualquier otro caso }.
(\#eq:funcion-probabilidad-poisson)
\end{cases}
$$
:::
La función `dpois(x, lambda, log = FALSE)` de la distribución base de `r colorize("R", "blue")` permite evaluar la función de probabilidad de Poisson, dada en la ecuación \@ref(eq:funcion-probabilidad-poisson).   

El parámetro $\lambda$ define una familia de distribuciones de probabilidad con una función de probabilidad determinada por la ecuación \@ref(eq:funcion-probabilidad-poisson). En la figura \@ref(fig:grafico-distribucion-poisson) se proporcionan algunas gráficas de la función de probabilidad de Poisson, para distintos valores de $\lambda=1, 5, 10$:

```{r grafico-distribucion-poisson, fig.cap = "Gráfica de la función de probabilidad de Poisson para $\\lambda = 1, 5, 10$", class.source = "watch-out"}
plot_ly(alpha = 0.5) %>%
  add_segments(
    x = ~c(0:20), 
    y = ~rep(x = 0, times = 21),
    xend = ~c(0:20), 
    yend = ~dpois(x = 0:20, lambda = 1, log = FALSE), 
    color = I("red"), 
    showlegend = TRUE,
    name = TeX("\\lambda = 1")
  ) %>%
  add_markers(
    x = ~c(0:20), 
    y = ~dpois(x = 0:20, lambda = 1, log = FALSE), 
    color = I("red"), 
    showlegend = TRUE,
    name = TeX("\\lambda = 1")
  ) %>%
  add_segments(
    x = ~c(0:20), 
    y = ~rep(x = 0, times = 21),
    xend = ~c(0:20), 
    yend = ~dpois(x = 0:20, lambda = 5, log = FALSE), 
    color = I("blue"), 
    showlegend = TRUE,
    name = TeX("\\lambda = 5")
  ) %>%
  add_markers(
    x = ~c(0:20), 
    y = ~dpois(x = 0:20, lambda = 5, log = FALSE), 
    color = I("blue"), 
    showlegend = TRUE,
    name = TeX("\\lambda = 5")
  ) %>%
   add_segments(
    x = ~c(0:20), 
    y = ~rep(x = 0, times = 21),
    xend = ~c(0:20), 
    yend = ~dpois(x = 0:20, lambda = 10, log = FALSE), 
    color = I("green"), 
    showlegend = TRUE,
    name = TeX("\\lambda = 10")
  ) %>%
  add_markers(
    x = ~c(0:20), 
    y = ~dpois(x = 0:20, lambda = 10, log = FALSE), 
    color = I("green"), 
    showlegend = TRUE,
    name = TeX("\\lambda = 10")
  ) %>% 
  layout(
    xaxis = list(
      title = TeX("x"), 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("p \\left(x; \\lambda \\right)"),
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```

La distribución de Poisson es asimétrica negativa, es decir es muy raro que ocurran valores grandes de la variable, es decir, las probabilidades asociadas a estos eventos tiende a cero en la medida de que la variable tiende a infinito. Lo anterior mente expuesto se observa en la gráfica \@ref(fig:grafico-distribucion-poisson). También, se puede observar e esta gráfica que la distribución de Poisson tiende a ser simétrica en la medida que el parámetro $\lambda$ aumenta.


::: {.example #ejemplo-funcion-probabilidad-poisson name="Función de Probabilidad de Poison"}
después de una prueba de laboratorio muy rigorosa con cierto componente eléctrico, el fabricante determina que en promedio, sólo fallarán dos componentes antes de tener 1.000 horas de operación. Un comprador observa que son cinco los que fallan antes de las 1.000 horas. Si el número de componentes que fallan es una variable aleatoria de Poisson, ¿existe suficiente evidencia para dudar de la conclusión del fabricante?

La duda estadística puede apoyarse en términos de la probabilidad. Si un evento debe o no ocurrir bajo ciertas condiciones, su ocurrencia se decide en términos de la probabilidad del evento bajo esas condiciones. Si la probabilidad de ocurrencia es pequeña y el evento ocurre, entonces se puede preguntar, con justificación, por las condiciones. Al mismo tiempo debe tenerse en mente que un valor de probabilidad pequeño no impide la ocurrencia del evento, a menos que este valor sea cero. En dicho caso, se tiene que $\lambda = 2$. Se supone que la frecuencia con que ocurren las fallas es constante e igual a dos cada mil hora o un promedio de $1/500$ unidades por hora. La probabilidad de que fallen cinco componentes en mil horas es, según la ecuación \@ref(eq:funcion-probabilidad-poisson),

$$
P\left(X = 5 \right)=p\left ( x = 5;\lambda =2 \right )=\frac{e^{-2}\lambda^5}{5!}= \approx `r formato(dpois(x = 5, lambda = 2, log = FALSE))`.
$$
Dado que la probabilidad de que cinco componentes fallen en 1.000 horas es una probabilidad bastante pequeña, no se esperaría que esto ocurriera en la primera réplica del experimento, a menos que en realidad su probabilidad de ocurrencia fuera mucho mayor que la que se obtuvo, y esto solo es posible si la tasa de falla fuera mayor que la indicada. Dicho de otra manera, el resultado experimental obtenido aporta información para pensar que la tasa de falla es mayor de 2 por cada 1.000 horas.

En `r colorize("R", "blue")`, el cálculo anterior se puede conseguir con el siguinte bloque de código.

```{r ejemplo-funcion-probabilidad-poisson}
dpois(x = 5, lambda = 2, log = FALSE)
```

La figura \@ref(fig:funcion-probabilidad-poisson) muestra la gráfica de la función de probabilidad del número de unidades que fallan en un tiempo de 100 horas $\left(X \right)$. La cual, bajo las condiciones expuestas en el ejemplo, tiene distribución de Poisson con parámetros $\lambda = 2$. Es decir, $X \sim P \left(\lambda = 2\right)$. 

```{r funcion-probabilidad-poisson, fig.cap = "Gráfica de la función de probabilidad binomial para $n = 15$ y $p = 0,05$", class.source = "watch-out"}
plot_ly(alpha = 0.5) %>%
  add_segments(
    x = 0:10, 
    y = ~rep(x = 0, times = length(0:10)),
    xend = 0:10, 
    yend = ~dpois(x = 0:10, lambda = 2, log = FALSE), 
    color = I("red"), 
    showlegend = TRUE,
    name = TeX("\\lambda = 2")
  ) %>%
  add_markers(
    x = 0:10, 
    y = ~dpois(x = 0:10, lambda = 2, log = FALSE), 
    color = I("red"), 
    showlegend = TRUE,
    name = TeX("\\lambda = 2")
  ) %>%  
  layout(
    xaxis = list(
      title = TeX("x"), 
      zeroline = F, 
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("p \\left(x; \\lambda = 2 \\right)"),
      showgrid = T,
      showline = T, 
      linewidth = 1, 
      linecolor = 'black',
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```

:::


#### Función de Distribución Acumulativa de Probabilidad de Poisson {#distribucion-acumulada-poisson}

De acuerdo con las definiciones \@ref(def:funcion-acumulativa-probabilidad) y \@ref(def:distribucion-poisson) la función de distribución acumulativa de probabilidad de una variable aleatoria con distribución de Poisson se formaliza en el siguiente teorema:

::: {#distribucion-acumulada-binomial .definition name="Función de Distribución Acumulativa de Probabilidad Binomial"}
Sea $X$ una variable aleatoria con distribución de Poisson. Entonces, la _función de distribución acumulativa de probabilidad de poisson_ viene dada por:
$$
F\left ( x;\lambda \right )=\begin{cases}
0 & \text{ si } x < 0\\
 e^{-\lambda}\sum_{t=0}^{x }\frac{\lambda^t}{t!} & \text{ si } x= 0, 1, 2, \dotsc;\: \lambda>0
(\#eq:funcion-acumulativa-poisson)
\end{cases}
$$
:::
La función `ppois(q, lambda, lower.tail = TRUE, log.p = FALSE)` de la distribución base de `r colorize("R", "blue")` permite evaluar la función de distribución acumulativa de probabilidad de Poisson dada en la ecuación \@ref(eq:funcion-acumulativa-poisson).


La figura \@ref(fig:grafico-acumulativa-poisson) muestra la función de distribución acumulativa de probabilidad para una variable Poisson con parámetros $\lambda = 1, 5, 10$. 

```{r grafico-acumulativa-poisson, fig.cap = "Gráfica de la función de distribución acumulativa de probabilidad de Poisson para $\\lambda = 1, 5, 10$", class.source = "watch-out"}
x <- c(-3, 0:20, 23)
Fx1 <- ppois(
  q = x, lambda = 1, lower.tail = TRUE, log.p = FALSE
)
Fx2 <- ppois(
  q = x, lambda = 5, lower.tail = TRUE, log.p = FALSE
)
Fx3 <- ppois(
  q = x, lambda = 10, lower.tail = TRUE, log.p = FALSE
)
plot_ly(x = x, y = Fx1, alpha = 0.5) %>%
  add_segments(
    x = ~ x[-length(x)],
    y = ~ Fx1[-length(x)],
    xend = ~ x[-1],
    yend = ~ Fx1[-length(x)],
    color = I("red"),
    name = TeX("lambda = 1"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~ x[-c(1, length(x))],
    y = ~ Fx1[-c(1, length(x))],
    color = I("red"),
    name = TeX("lambda = 1"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~ x[-c(1, length(x))],
    y = ~ Fx1[-c(length(x) - 1, length(x))],
    color = I("red"),
    marker = list(symbol = "circle-open"),
    name = TeX("\\lambda = 1"),
    showlegend = TRUE
  ) %>%
  add_segments(
    x = ~ x[-length(x)],
    y = ~ Fx2[-length(x)],
    xend = ~ x[-1],
    yend = ~ Fx2[-length(x)],
    color = I("blue"),
    name = TeX("\\lambda = 5"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~ x[-c(1, length(x))],
    y = ~ Fx2[-c(1, length(x))],
    color = I("blue"),
    name = TeX("\\lambda = 5"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~ x[-c(1, length(x))],
    y = ~ Fx2[-c(length(x) - 1, length(x))],
    color = I("blue"),
    marker = list(symbol = "circle-open"),
    name = TeX("\\lambda = 5"),
    showlegend = TRUE
  ) %>%
  add_segments(
    x = ~ x[-length(x)],
    y = ~ Fx3[-length(x)],
    xend = ~ x[-1],
    yend = ~ Fx3[-length(x)],
    color = I("green"),
    name = TeX("\\lambda = 10"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~ x[-c(1, length(x))],
    y = ~ Fx3[-c(1, length(x))],
    color = I("green"),
    name = TeX("\\lambda = 10"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~ x[-c(1, length(x))],
    y = ~ Fx3[-c(length(x) - 1, length(x))],
    color = I("green"),
    marker = list(symbol = "circle-open"),
    name = TeX("\\lambda = 10"),
    showlegend = TRUE
  ) %>%
  layout(
    xaxis = list(
      title = TeX("x"),
      zeroline = F,
      showgrid = T,
      showline = T,
      linewidth = 1,
      linecolor = "black",
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("F \\left(x; \\lambda \\right)"),
      showgrid = T,
      showline = T,
      linewidth = 1,
      linecolor = "black",
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```

::: {.example #ejemplo-distribucion-acumulada-binomial name="Función de Distribución Acumulativa de Probabilidad de Poisson"}
Determine en el ejemplo \@ref(exm:ejemplo-funcion-probabilidad-poisson) la probabilidad de que por lo menos fallen cinco componentes en 1.000 horas. 

La probabilidad de que al menos cinco componentes fallen en 1.000 horas, según la función de distribución acumulativa de probabilidad de Poisson dada por la ecuación \@ref(eq:funcion-acumulativa-poisson) para $\lambda = 2$, es:

$$
\begin{align*}
P \left(X \geq 5 \right) =& 1 - P \left(X \leq 4
\right)=  1 - F \left( x = 4;\lambda =2 \right ) = 1 - e^{-\lambda}\sum_{t=0}^{4}\frac{2^t}{t!}\\
=&1 - e^{-2}\left[ \frac{2^0}{0!} + \frac{2^1}{1!} + \frac{2^2}{2!} + \frac{2^3}{3!} + \frac{2^4}{4!} \right] \\
=&1 - `r ppois(q = 4, lambda = 2, lower.tail = TRUE, log.p = FALSE)` \\
\approx &  `r 1- ppois(q = 4, lambda = 2, lower.tail = TRUE, log.p = FALSE)`.
\end{align*}
$$
En `r colorize("R", "blue")`, el resultado anterior se puede obtener con el siguiente script.

```{r ejemplo-distribucion-acumulada-poisson}
1 - ppois(q = 4, lambda = 2, lower.tail = TRUE, log.p = FALSE)
```
:::

La figura \@ref(fig:grafico-ejemplo-distribucion-acumulada-poisson) muestra la gráfica de la función de distribución acumulativa de probabilidad del número de componentes que fallan en 1.000 horas si la tasa de falla es de dos en ese intervalo de tiempo.

```{r grafico-ejemplo-distribucion-acumulada-poisson, fig.cap = "Gráfica de la función de distribución acumulativa de probabilidad de Poisson para $\\lambda = 2$", class.source = "watch-out"}
x <- c(-3, 0:10, 13)
Fx  <- ppois(
  q = x, lambda = 2, lower.tail = TRUE, log.p = FALSE
)
plot_ly(x = x, y = Fx1, alpha = 0.5) %>%
  add_segments(
    x = ~ x[-length(x)],
    y = ~ Fx[-length(x)],
    xend = ~ x[-1],
    yend = ~ Fx[-length(x)],
    color = I("red"),
    name = TeX("\\lambda = 2"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~ x[-c(1, length(x))],
    y = ~ Fx[-c(1, length(x))],
    color = I("red"),
    name = TeX("\\lambda = 2"),
    showlegend = TRUE
  ) %>%
  add_markers(
    x = ~ x[-c(1, length(x))],
    y = ~ Fx[-c(length(x) - 1, length(x))],
    color = I("red"),
    marker = list(symbol = "circle-open"),
    name = TeX("\\lambda = 2"),
    showlegend = TRUE
  ) %>%
  layout(
    xaxis = list(
      title = TeX("x"),
      zeroline = F,
      showgrid = T,
      showline = T,
      linewidth = 1,
      linecolor = "black",
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    yaxis = list(
      title = TeX("F \\left(x; \\lambda = 2 \\right)"),
      showgrid = T,
      showline = T,
      linewidth = 1,
      linecolor = "black",
      showticklabels = TRUE,
      tickwidth = 0.5
    ),
    showlegend = TRUE
  ) %>%
  config(locale = "es", mathjax = "cdn")
```

La tabla \@ref(tab:distribucion-acumulada4) muestra la función de probabilidad y la función de distribución acumulativa de probabilidad de una variable de Poisson con parámetro $\lambda = 2$.

```{r distribucion-acumulada3, class.source="watch-out", class.source = "watch-out"}
da_ej3 <- data.frame(
  x = 0:10,
  px = dpois(x = 0:10, lambda = 2, log = FALSE),
  Fx = ppois(
    q = 0:10, lambda = 2, lower.tail = TRUE, log.p = FALSE
  )
) 
knitr::kable(
  da_ej2,
  booktabs = TRUE,
  row.names = TRUE,
  digits = 4,
  col.names = c(
    "$X_i$", 
    "$p\\left(x_i \\right)$", 
    "$F\\left(x_i \\right)$"
  ),
  align = c("ccc"),
  format.args = list(decimal.mark = ",", big.mark = "."),
  caption = "\\label{tab2:distribucion-acumulada2}Función de probabilidad y función de distribución acumulativa de $X \\sim P \\left( \\lambda = 2 \\right)$",
  escape = FALSE
) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = FALSE,
    fixed_thead = T
  ) %>%
  kable_classic_2() %>% 
  scroll_box(width = "100%", height = "400px")
```
<br>

#### Media de la Distribución de Poisson {#media-poisson}

La media, promedio o esperanza matemática de la distribución de Poisson representa el número de éxitos que se espera ocurran en una unidad de muestreo, entendiendo que esta unidad de muestreo puede ser cualquier medida de espacio o tiempo. El siguiente teorema describe la media de la distribución de Poisson.

::: {#media-poisson .theorem name="Media de la Distribución poisson"}
Sea $X$ una variable aleatoria con distribución de Poisson. Entonces, la _media_ de $X$ viene dada por:
$$
\begin{equation}
E \left(X \right)= \mu = \lambda.
(\#eq:media-poisson)
\end{equation}
$$
:::

::: {#media-poisson .proof name="Media de la Distribución de Poisson"}
Por las definiciones \@ref(def:esperanza) y \@ref(def:distribucion-poisson) la esperanza de una variable $X$ con distribución de Poisson es

$$
\begin{align*}
E \left(X \right) =&  \sum_{x=0}^{\infty } x\frac{e^{-\lambda}\lambda^x}{x!}\\
=& \sum_{x=1}^{\infty } x\frac{e^{-\lambda}\lambda^x}{x \left(x-1 \right)!}\\
=& \sum_{x=1}^{\infty } \frac{e^{-\lambda}\lambda^x}{ \left(x-1 \right)!},\\
\end{align*}
$$
en donde se ha escrito la suma desde uno hasta $\infty$, dado que cuando $x=0$ el primer término es cero y se cancela la $x$ del numerador con la $x$ en $x!$. Luego, factorizando $\lambda$, se tiene:

$$
\begin{align*}
E \left(X \right) =&\lambda   \sum_{x=1}^{\infty } \frac{e^{-\lambda}\lambda^{x-1}}{ \left(x-1 \right)!},\\
\end{align*}
$$

Si $y=x-1$, entonces:

$$
\begin{align*}
E \left(X \right) =&\lambda \sum_{y=0}^{\infty } \frac{e^{-\lambda}\lambda^{y}}{ y!},\\
\end{align*}
$$

Pero $p \left(y; \lambda \right)= e^{-\lambda}\lambda^{y}/ y!$ es la función de probabilidad de una variable aleatoria binomial $Y$ con parámetro $\lambda$; de esta manera $\sum_{y=0}^{\infty}p\left(y; m, p \right)=1$, y la media de una variable aleatoria de Poisson es:
$$
\begin{equation}
E \left(X \right) = \lambda.
\end{equation}
$$
:::

::: {.example #ejemplo-media-distribucion-poisson name="Media de la Distribución de Poisson"}
Con respecto al el ejemplo \@ref(exm:ejemplo-funcion-probabilidad-poisson), determine el número de componentes que se esperaría fallen en un tiempo de 1.000 horas.

De acuerdo con el teorema \@ref(thm:media-poisson), el número de componentes que se esperaría fallen es
$$
\begin{equation}
E \left(X \right) = \lambda=2.
\end{equation}
$$
:::


#### Varianza de la Distribución de Poisson {#varianza-poisson}

La varianza de una variable aleatoria de Poisson $X$ viene dada por el siguiente teorema: 

::: {#varianza-poisson .theorem name="Varianza de la Distribución de Poisson"}
Sea $X$ una variable aleatoria con distribución de Poisson. Entonces, la _varianza_ de $X$ viene dada por:
$$
\begin{equation}
V \left(X \right)=\sigma^2 =\lambda.
(\#eq:varianza-poisson)
\end{equation}
$$
:::

::: {#varianza-poisson .proof name="Varianza de la Distribución de Poisson"}
De la ecuación \@ref(eq:varianza2) se sabe que $V \left(X \right) = E \left(X^2 \right) - \mu^2$. Como $\mu=\lambda$, solo faltaría calcular $E \left(X^2 \right)$. Pero calcular este parámetro usando el teorema \@ref(thm:esperanza-transformacion) y la definición \@ref(def:distribucion-poisson) implica encontrar la convergencia de la siguiente expresión

$$
E \left(X^2 \right) =  \sum_{x=0}^{\infty} x^2\frac{e^{-\lambda}\lambda^x}{x !},
$$
lo cual es imposible. En lugar de este camino, se elegirá un método alterno. La alternativa es escribir $x^2$ como:

$$
x^2= x \left(x-1 \right)+x;
$$
de esta manera, por los teoremas \@ref(thm:esperanza-transformacion) y \@ref(thm:esperanza-suma-transformaciones), se tiene:

$$
\begin{equation}
E \left(X^2 \right)= E \left[X \left(X-1 \right) \right]+E \left(X \right).
(\#eq:varianza-alterna-binomial)
\end{equation}
$$
Dado que $E \left(X \right)$ ya se ha determinado, faltaría determinar $E \left[x \left(x-1 \right) \right]$, que según el teorema \@ref(thm:esperanza-transformacion), es:


$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =&  \sum_{x=0}^{\infty} x \left(x-1 \right)\frac{e^{-\lambda}\lambda^x}{x !}\\
=& \sum_{x=2}^{n } x \left(x-1 \right)\frac{e^{-\lambda}\lambda^2\lambda^{x-2}}{x \left(x-1 \right)\left(x-2 \right) !}\\
=& e^{-\lambda}\lambda^2 \sum_{x=2}^{n } \frac{\lambda^{x-2}}{\left(x-2 \right) !}.\\
\end{align*}
$$
Note que en los pasos previos se escribió la suma a partir de dos porque los dos primeros términos son cero, se canceló $x \left(x-1 \right)$, y se factorizó $\lambda^2$. Ahora, sea $y=x-2$; entonces:

$$
\begin{align*}
E \left[X \left(X-1 \right) \right] =&\lambda^2 \sum_{y=0}^{\infty} \frac{e^{-\lambda}\lambda^{y}}{y !}.\\
\end{align*}
$$
Pero $p \left(y; \lambda \right)= e^{-\lambda}\lambda^{y}/ y!$ es la función de probabilidad de una variable aleatoria de Poisson $Y$ con parámetro $\lambda$; de esta manera $\sum_{y=0}^{\infty}p\left(y; m, p \right)=1$. Por lo tanto, 
$$
\begin{equation}
E \left[X \left(X-1 \right) \right] =\lambda^2.
\end{equation}
$$

De la ecuación \@ref(eq:varianza-alterna-binomial)
$$
E \left(X^2 \right)=  \lambda^2+\lambda.
$$

De esta manera, la varianza de una variable aleatoria de Poisson, según la ecuación \@ref(eq:varianza2), es:
$$
\begin{align*}
V(X)=& \lambda^2+\lambda-\lambda^2\\
=&\lambda.
\end{align*}
$$
:::

::: {.example #ejemplo-varianza-binomial name="Varianza de la Distribución de Poisson"}
Con respecto al ejemplo \@ref(exm:ejemplo-funcion-probabilidad-binomial), determine la varianza del número de componentes que fallan en dos horas.

De acuerdo con el teorema \@ref(thm:varianza-poisson), la varianza de $X$ es:

$$
V(X)=\lambda=2.
$$
:::


#### Función Genradora de Momentos de la Distribución de Poisson {#funcion-generadora-momentos-poisson}

La función generadora de momentos de la distribución de Poisson se indica en el siguiente teorea: 

::: {#fgm-poisson .theorem name="Función Generadora de Momentos de la Distribución de Poisson"}
La función generadora de momentos de la distribución de Poisson se indica en el siguiente teorema:
$$
\begin{equation}
m_x \left(t \right)=e^{\lambda\left(e^t -1\right)}.
(\#eq:fgm-poisson)
\end{equation}
$$
:::

::: {#fgm-binomial .proof name="Función Generadora de Momentos de la Distribución de Poisson"}
De la definiciones \@ref(def:distribucion-poisson) y \@ref(def:funcion-generadora-momentos), se obtiene

$$
\begin{align*}
m_x \left(t \right)=&  \sum_{x=0}^{\infty} e^{tx}\frac{e^{-\lambda}\lambda^x}{x !}\\
=& e^{-\lambda} \sum_{x=0}^{\infty} \frac{\left(\lambda e^t\right)^x}{x !}.\\
\end{align*}
$$
Por el teorema de Maclaurin, 
$$
\sum_{x=0}^{\infty} \frac{\left(\lambda e^t\right)^x}{x !}=e^{\lambda e^t}.
$$
Entonces,
$$
\begin{align*}
m_x \left(t \right)=& e^{-\lambda}e^{\lambda e^t}\\
=& e^{\left[\lambda \left(e^t-1\right) \right]}.\\
\end{align*}
$$
Del teorema \@ref(thm:funcion-generadora-momentos), la media de la distribución de Poisson es:
$$
\begin{equation}
\frac{\mathrm{d}m_{x}\left ( t \right )}{\mathrm{d}t} \left|\begin{matrix}
 \\
t=0\\
\end{matrix}={\mu}^{'}_1=\mu .\right.
\end{equation}
$$

Luego, la primera derivada de la función generadora de momentos de la distribución de Poisson evaluada en 0 determina la media 

$$
\frac{\mathrm{d}m_{x}\left ( t \right )}{\mathrm{d}t}=\lambda e^te^{\left[\lambda \left(e^t-1\right) \right]}.
$$
Ahora, evaluando la primera derivada de la función generadora de momentos en $t=0$, se obtiene la media de la distribución de Poisson, como sigue:
$$
\begin{equation}
\frac{\mathrm{d}m_{x}\left ( t \right )}{\mathrm{d}t} \left|\begin{matrix}
 \\
t=0\\
\end{matrix}=\mu=\lambda e^0e^{\left[\lambda \left(e^0-1\right) \right]}=\lambda. \right.
\end{equation}
$$
Note que este resultado es el mismo dado en el teorema \@ref(thm:media-poisson). Se deja como ejercicio al lector, hallar la varianza de la distribución de Poisson usando el método de la función generadora de momentos. 
